# Plan: Fix Issue #79 - Customized Bullets Using Wrong Context

## Problem Summary

When user clicks "Optimize Your Application" after job fit analysis, the generated bullets show:
- ❌ Job title from JD instead of job history
- ❌ Company from JD instead of job history
- ❌ Only ONE position instead of multiple

**Root Cause**: Ambiguous prompt makes AI think it should generate bullets FOR the JD position, not FROM the job history positions.

---

## Validation Coverage Summary (25 Validators)

This plan implements **25 JavaScript validators** covering **30+ guardrails** from PROJECT-INSTRUCTIONS.md and the `optimization-tools/shared/` modules.

**Like a Mini Resume Analyzer:** The validation layer runs the same quality checks as the Resume Analyzer, providing a brief summary report after generation.

### Validator Matrix

| # | Validator | Source | Priority | Auto-Correct? |
|---|-----------|--------|----------|---------------|
| 1 | `validateChronologyDepth()` | bo_bullet-generation-logic.md | Core | ✅ Yes |
| 2 | `validatePositionMetadata()` | Position cross-reference | Core | ✅ Yes |
| 3 | `validateChronologicalOrder()` | Sort order | Core | ✅ Yes |
| 4 | `validateBulletCounts()` | Bullet count rules | Core | ❌ Flag |
| 5 | `validateBulletFormat()` | Guardrail #8, verb cats | Core | ❌ Flag |
| 6 | `validateMetricTraceability()` | Guardrail #1 | Critical | ❌ Flag |
| 7 | `validateSummaryAbstraction()` | Guardrail #3 | Critical | ❌ Flag |
| 8 | `validateVerbDiversity()` | Guardrail #9 | Critical | ❌ Flag |
| 9 | `validateSummaryMetrics()` | Guardrail #13 | Critical | ❌ Flag |
| 10 | `validatePhraseRepetition()` | Guardrail #15 | Critical | ❌ Flag |
| 11 | `validateMetricPreservation()` | Guardrail #29 | Critical | ❌ Flag |
| 12 | `validateKeywordEvidence()` | Guardrail #32 | Critical | ⚠️ Warn |
| 13 | `validateNarrativeFit()` | Guardrail #33 | Critical | ⚠️ Warn |
| 14 | `validateLimitationEnforcement()` | Guardrail #5 | High | ❌ Flag |
| 15 | `validateSkillClassification()` | Guardrail #7 | High | ❌ Flag |
| 16 | `validateBudgetEnforcement()` | Guardrail #8 | High | ❌ Flag |
| 17 | `validateKeywordDensity()` | Guardrail #10 | High | ❌ Flag |
| 18 | `validateMetricPlausibility()` | Guardrail #11 | High | ⚠️ Warn |
| 19 | `validateScopeAttribution()` | Guardrail #17 | High | ⚠️ Warn |
| 20 | `validateEmDash()` | Guardrail #22 | High | ❌ Flag |
| **21** | **`validateVerbDistribution()`** | **shared_verb_taxonomy.md** | **Shared** | ⚠️ Warn |
| **22** | **`validateMetricsDensity()`** | **shared_core_principles.md (P1)** | **Shared** | ⚠️ Warn |
| **23** | **`validateKeywordEvidenceTier()`** | **shared_keyword_validation.md** | **Shared** | ⚠️ Warn |
| 24 | `validateRecencyWeighting()` | Guardrail #12 | Moderate | ⚠️ Warn |
| 25 | `validateAcronymExpansion()` | Guardrail #20 | Moderate | ⚠️ Warn |

### Shared Module Coverage

| Module | Validator | Rule Enforced |
|--------|-----------|---------------|
| `shared_verb_taxonomy.md` | #21 VerbDistribution | 5% threshold, 13-27% balanced range |
| `shared_core_principles.md` | #22 MetricsDensity | P1: 70-80% bullets with metrics |
| `shared_keyword_validation.md` | #23 KeywordEvidenceTier | Tier 1/2/3 evidence weighting |

### Bug Coverage

| Bug # | Description | Validator(s) |
|-------|-------------|--------------|
| 1 | Wrong job titles | #2: validatePositionMetadata |
| 2 | Not in chronological order | #3: validateChronologicalOrder |
| 3 | JD company contamination | #2: validatePositionMetadata |
| 4 | Missing companies | #2: validatePositionMetadata |
| 5 | Only 4 jobs (not all eligible) | #1: validateChronologyDepth |
| 6 | Some jobs only have 1 bullet | #4: validateBulletCounts |
| 7 | Guardrails not enforced | #5-22: All additional validators |

### Guardrails Not Applicable to WebGUI (13)

These are handled elsewhere or don't apply to bullet generation:
- #14: Quality Gate Failure Protocol (iteration logic)
- #16: Master Skills Inventory Protection
- #19: Fit Score Consistency
- #26: Output Structure Consistency
- #27: Input Type Detection
- #34: JD Keyword Visibility

---

## Fix: Update Generation Prompt

### File: `claude-artifacts/Should-I-Apply-webgui.jsx`

**Location**: Lines 667-734 (the `generationPrompt` variable in `generateCustomizedContent` function)

**Change**: Replace the entire prompt with explicit multi-position instructions.

### Current Prompt (WRONG):
```javascript
const generationPrompt = `You are a Resume Optimization expert. Generate customized resume bullets and a professional summary optimized for this specific job description.
...
{
  "customizedBullets": [
    {
      "position": "Position title from their experience",  // ← AMBIGUOUS
      "company": "Company name",                            // ← AMBIGUOUS
      ...
```

**Why It Fails**:
- "Position title from their experience" could mean job history OR the JD
- "Optimized for this specific job description" makes AI think it's generating bullets FOR that JD position
- No instruction to extract ALL positions from job history

### New Prompt (CORRECT):

```javascript
const generationPrompt = `You are a Resume Optimization expert. Generate customized resume bullets for positions in the candidate's job history that meet chronology depth criteria (NOT all historical positions).

${experienceContent}

JOB DESCRIPTION:
${jobDescription}

CRITICAL INSTRUCTIONS:

1. PARSE ALL POSITIONS from the job history above
   - Extract: position title, company, dates, existing bullets for EVERY position
   - DO NOT use the job description's position/company

2. APPLY CHRONOLOGY DEPTH FILTER (Guardrail: bo_bullet-generation-logic.md):

   Current Year: 2026

   INCLUDE positions that meet ANY of these criteria:

   a) **Recent/Current** (Years_Since_End ≤ 6 OR Job is "Present"):
      → INCLUDE and generate 3-5 bullets

   b) **Tenure Exception** (Years_Since_End > 6 AND Job_Duration ≥ 5 years):
      → INCLUDE and generate 2-3 bullets (Reason: "Relevant Career Chunk")

   EXCLUDE positions that meet:

   c) **Very Old, Short Tenure** (Years_Since_End > 6 AND Job_Duration < 5 years):
      → EXCLUDE (unless total resume < 2 pages, then summarize)

   Calculation: Years_Since_End = 2026 - Job_End_Year

3. FOR EACH INCLUDED POSITION (after filtering in step 2):
   - Generate optimized bullets using keywords from the JD
   - PRESERVE the original position title, company, and dates from JOB HISTORY
   - Do NOT substitute with the JD's position or company name
   - Apply bullet count from step 2 criteria (3-5 for recent, 2-3 for tenure exception)

4. BULLET OPTIMIZATION RULES:
   - Apply causal impact linking: [Action] + [Outcome] + [Metric]
   - Incorporate JD keywords naturally where evidence supports them
   - Character limit: ≤210 characters per bullet (hard limit for ATS)
   - Preserve all metrics from original bullets (Guardrail #29)
   - Verb category distribution: Aim for 13-27% per category (Built, Lead, Managed, Improved, Collaborate)

5. PORTFOLIO PROJECT LABELING (CRITICAL):
   - If a position is marked as "Independent" or "Portfolio Project" in job history:
     → Append "(Independent Project)" or "(Portfolio Project)" to the position title
     → Example: "Resume Optimizer (Independent Project) | technomensch/optimize-my-resume"
   - This prevents misrepresentation during background checks

6. KEYWORD EVIDENCE PRINCIPLE (Guardrail #32):
   - ONLY use keywords that have evidence in the candidate's job history
   - If a keyword from "USE" list lacks evidence, incorporate it LIGHTLY
   - Do NOT fabricate experience

7. PROFESSIONAL SUMMARY GUARDRAILS:

   Guardrail #3 (Summary Abstraction):
   - No sentence in summary can share >50% of its keywords with any single bullet
   - Must synthesize metrics across multiple roles (e.g., "Led projects across X and Y, achieving Z")
   - Start sentences with outcome (Why) rather than action (How) to differentiate from bullets

   Guardrail #13 (Metric Reconciliation):
   - Every metric in summary MUST be traceable to at least one bullet
   - Exception: Years of experience can be calculated from position dates

   Guardrail #15 (Phrase Repetition):
   - No 3+ word phrase should be repeated 3+ times across summary and all bullets
   - Ensure narrative variety throughout

KEYWORD PREFERENCES:
- USE: ${keywordsToUse.map(k => k.replace(/^Custom: /, '')).join(', ')}
- IGNORE: ${keywordsToIgnore.map(k => k.replace(/^Custom: /, '')).join(', ')}

OUTPUT FORMAT (CRITICAL):

Return JSON with this exact structure:

{
  "customizedBullets": [
    // ONE OBJECT PER HISTORICAL POSITION
    {
      "position": "EXACT position title from job history",
      "company": "EXACT company name from job history",
      "dates": "EXACT dates from job history",
      "bullets": [
        {
          "text": "Optimized bullet with JD keywords integrated",
          "verbCategory": "Built|Lead|Managed|Improved|Collaborate",
          "keywordsUsed": ["keyword1", "keyword2"],
          "charCount": 150,
          "hasMetric": true,
          "originalBullet": "Original bullet text from job history"
        }
      ]
    },
    // REPEAT for Position 1, Position 2, etc.
  ],
  "professionalSummary": {
    "text": "3-4 sentence summary optimized for JD (80-120 words, 2+ metrics, 2-3 hard skills)",
    "keywordsIntegrated": ["keyword1", "keyword2"],
    "metricsIncluded": ["6+ years", "20+ stakeholders"],
    "guardrailsApplied": {
      "g3_abstraction": "No sentence shares >50% keywords with any bullet; synthesizes across roles",
      "g13_metricReconciliation": "All metrics traceable to bullets (except years calculated from dates)",
      "g15_phraseRepetition": "No 3+ word phrase repeated 3+ times across summary and bullets"
    }
  },
  "keywordCoverageReport": {
    "successfullyIncorporated": [
      { "keyword": "Python", "location": "Position 0, Bullet 2" }
    ],
    "skippedNotEvidenced": [
      { "keyword": "Kubernetes", "reason": "No evidence in job history" }
    ]
  },
  "optimizationNotes": "Summary of what was optimized per position",
  "narrativeVerification": {
    "summary": "Quality assessment",
    "topRequirementsMet": ["Skill 1", "Skill 2"],
    "narrativeGaps": ["Missing requirement"],
    "roleLevelAlignment": "Aligned|Mismatch",
    "score": 85
  }
}

EXAMPLE OUTPUT STRUCTURE:

If job history has 3 positions, return:
- customizedBullets[0] = Position 0 optimized bullets (with Position 0's title/company/dates)
- customizedBullets[1] = Position 1 optimized bullets (with Position 1's title/company/dates)
- customizedBullets[2] = Position 2 optimized bullets (with Position 2's title/company/dates)

Each position object MUST use the EXACT title, company, and dates from the job history.
DO NOT use the JD's position or company name.
`;
```

---

## Additional Change: Add Clarifying Comment

**Location**: Line 655-665

**Before experienceContent preparation, add**:

```javascript
// Prepare experience content (same as original analysis)
// NOTE: The AI will PARSE this job history to extract ALL positions,
// then FILTER by chronology depth logic (recent ≤6yr, tenure exception >6yr + ≥5yr tenure).
// It must generate optimized bullets for EACH historical position meeting criteria,
// NOT create bullets for the JD position.
// Guardrails: #3, #13, #15 (summary), #29 (metrics), #32 (evidence), #33 (narrative fit),
//             chronology_depth_logic, portfolio_employment_labeling, verb distribution
let experienceContent = '';
```

---

## Apply Same Fix to Local Version

### File: `src/components/Should-I-Apply-local.jsx`

Apply the **exact same changes**:
1. Replace generation prompt (same location, same function)
2. Add clarifying comment before experienceContent

---

## Verification Test Cases

### Test Case 1: Multiple Positions

**Input**:
- Job history: 3 positions (Engineer at Acme, Senior Engineer at TechCo, Lead Engineer at StartupX)
- JD: Staff Engineer at BigCorp

**Expected Output**:
```json
{
  "customizedBullets": [
    { "position": "Engineer", "company": "Acme", ... },
    { "position": "Senior Engineer", "company": "TechCo", ... },
    { "position": "Lead Engineer", "company": "StartupX", ... }
  ]
}
```

**NOT**: Position = "Staff Engineer", Company = "BigCorp"

### Test Case 2: Chronology Depth

- Position 0 (2022-Present): Should get 3-5 bullets
- Position 1 (2019-2022): Should get 3 bullets
- Position 2 (2012-2017, 5yr tenure): Should get 2-3 bullets

All 3 should be included.

### Test Case 3: Keyword Evidence

- USE: ["Python", "AWS", "Kubernetes"]
- Job history: Has Python and AWS, but NOT Kubernetes

**Expected**:
- Python and AWS incorporated
- Kubernetes in `skippedNotEvidenced` section

---

## Post-Generation Validation Layer (NEW - Addresses Testing Bugs)

### Problem

Testing with local model revealed **7 critical bugs** that the prompt alone cannot prevent:
1. ❌ Wrong job titles (not from job history)
2. ❌ Not in chronological order
3. ❌ First job company matches JD company (original bug persists!)
4. ❌ Missing companies on some jobs
5. ❌ Only 4 jobs instead of all within chronology window
6. ❌ Some jobs only have one bullet
7. ❌ Guardrails didn't validate these errors

**Root Cause:** No validation layer between LLM response and display. Code directly renders whatever LLM returns (lines 797-811 parsing, lines 2164-2168 display).

---

### Bug-to-Validator Mapping

| Bug # | Bug Description | Validator Function | How It Fixes |
|-------|----------------|-------------------|--------------|
| **1** | Wrong job titles | `validatePositionMetadata()` | Compares LLM position title to job history, **auto-replaces** with correct title from history |
| **2** | Not in chronological order | `validateChronologicalOrder()` | Extracts end year from dates, **auto-sorts** positions newest-first (Present = 9999) |
| **3** | JD company contamination | `validatePositionMetadata()` | Detects if `bullet.company === jobDescription.company`, **auto-replaces** with correct company from history, flags as CRITICAL |
| **4** | Missing companies | `validatePositionMetadata()` | If company field is missing/wrong, **auto-fills** from matching job history entry |
| **5** | Only 4 jobs (not all eligible) | `validateChronologyDepth()` | Calculates which positions meet criteria (≤6 years OR ≥5 year tenure), **auto-adds missing** positions, **auto-removes** ineligible ones |
| **6** | Some jobs only have 1 bullet | `validateBulletCounts()` | Checks `bullet.bullets.length` against expected range (3-5 or 2-3), **flags as CRITICAL** if count = 1 |
| **7** | Guardrails not enforced | `validateBulletFormat()` | Checks character limit (≤210) and verb categories, **flags violations** for all guardrails |

**Key:** 
- ✅ **Auto-corrects** = Validator fixes the issue automatically before display
- ⚠️ **Flags** = Validator detects issue, logs error, alerts user (cannot auto-fix)

---

## Missing Implementation Details

### 1. How to Handle `jobHistory` Array

**Problem**: Validators reference a `jobHistory` array, but the current code only has `jobHistorySource.content` (raw string).

**Solution**: We don't need to parse the raw string ourselves. The LLM already parses it and returns `customizedBullets` with position data. For validators:

```javascript
// Extract job history from LLM's parsed output
function extractJobHistoryFromLLMOutput(customizedBullets) {
  return customizedBullets.map(pos => ({
    position: pos.position,
    company: pos.company,
    dates: pos.dates,
    bullets: pos.bullets.map(b => b.text)
  }));
}

// Use in validation:
const jobHistory = extractJobHistoryFromLLMOutput(parsedContent.customizedBullets);
```

### 2. Helper Function: `determineExperienceLevel()`

```javascript
function determineExperienceLevel(jobHistory) {
  if (!jobHistory || jobHistory.length === 0) return 'entry';

  // Calculate total years of experience from all positions
  const CURRENT_YEAR = 2026;
  let totalYears = 0;

  jobHistory.forEach(job => {
    const endYear = job.dates.includes('Present') || job.dates.includes('present')
      ? CURRENT_YEAR
      : parseInt(job.dates.match(/\d{4}$/)?.[0] || CURRENT_YEAR);
    const startYear = parseInt(job.dates.match(/^\d{4}/)?.[0] || endYear);
    totalYears += (endYear - startYear);
  });

  if (totalYears <= 2) return 'entry';
  if (totalYears <= 5) return 'mid';
  if (totalYears <= 10) return 'senior';
  return 'principal';
}
```

### 3. Helper Function: `autoCorrectPositions()`

```javascript
function autoCorrectPositions(customizedBullets, eligiblePositions, jobHistory) {
  // Auto-correct position metadata to match job history
  const corrected = customizedBullets.map(bullet => {
    const matchingJob = jobHistory.find(job =>
      job.position.toLowerCase().includes(bullet.position.toLowerCase()) ||
      bullet.position.toLowerCase().includes(job.position.toLowerCase())
    );

    if (matchingJob) {
      return {
        ...bullet,
        position: matchingJob.position, // Replace with exact title from history
        company: matchingJob.company,   // Replace with exact company from history
        dates: matchingJob.dates         // Replace with exact dates from history
      };
    }
    return bullet;
  });

  return corrected;
}
```

### 4. Integration with Existing `OllamaService.generate()` Call

**Location**: `Should-I-Apply-local.jsx` lines 787-824

**Current Code**:
```javascript
const result = await OllamaService.generate(selectedModel, generationPrompt, {
  temperature: 0.3,
  max_tokens: 4000
});

// Parse response
let responseText = result.text.trim();
responseText = responseText.replace(/```json\s*/g, '').replace(/```\s*/g, '');

const jsonStart = responseText.indexOf('{');
const jsonEnd = responseText.lastIndexOf('}');

if (jsonStart === -1 || jsonEnd === -1) {
  throw new Error('No JSON found in response');
}

const jsonString = responseText.substring(jsonStart, jsonEnd + 1);
const parsedContent = JSON.parse(jsonString);

setGeneratedContent(parsedContent); // ← INSERT VALIDATION HERE
```

**New Code** (with validation loop):
```javascript
// Replace the direct OllamaService.generate call with:
const loopResult = await generateWithValidationLoop(
  selectedModel,
  generationPrompt, // The full base generation prompt
  jobHistorySource,
  { title: jobDescription.title, company: jobDescription.company },
  keywordsToUse,
  honestLimitations || [],
  {
    temperature: 0.3,
    max_tokens: 4000
  }
);

// Use the validated and auto-corrected content
setGeneratedContent(loopResult.content);

// Log the validation summary
console.log('Validation Report:', loopResult.validationResult.summary);
console.log('Generation completed in', loopResult.attempts, 'attempt(s)');
```

### 5. Regeneration Loop Helper Functions

```javascript
// Wrapper for OllamaService.generate with parsing
async function callLLM(model, prompt, options) {
  const result = await OllamaService.generate(model, prompt, options);

  if (!result.success) {
    throw new Error(`LLM call failed: ${result.error}`);
  }

  return result.text;
}

// Extract JSON from LLM response
function parseJSONResponse(responseText) {
  let cleaned = responseText.trim();
  cleaned = cleaned.replace(/```json\s*/g, '').replace(/```\s*/g, '');

  const jsonStart = cleaned.indexOf('{');
  const jsonEnd = cleaned.lastIndexOf('}');

  if (jsonStart === -1 || jsonEnd === -1) {
    throw new Error('No JSON found in response');
  }

  const jsonString = cleaned.substring(jsonStart, jsonEnd + 1);
  return JSON.parse(jsonString);
}

// Build generation prompt with validation feedback
function buildGenerationPrompt(
  basePrompt,
  validationErrors = [],
  attempt = 1
) {
  if (attempt === 1) {
    return basePrompt; // First attempt, use original prompt
  }

  // Subsequent attempts: add error context
  const errorContext = validationErrors
    .filter(e => e.requiresRegeneration)
    .map(e => `- ${e.message}`)
    .join('\n');

  return `${basePrompt}

IMPORTANT: Previous attempt had these issues - MUST FIX:
${errorContext}

Please regenerate the content addressing ALL of the above issues.`;
}
```

---

### Solution: Hard-Coded JavaScript Validators

Instead of relying on prompt language, implement **JavaScript validation functions** that enforce rules from `/optimization-tools/` modules.

---

### Validation Function 1: `validateChronologyDepth()`

**Source:** `optimization-tools/bullet-optimizer/bo_bullet-generation-logic.md` (lines 53-100)

**Purpose:** Ensure all chronology-eligible positions are included, no extras.

```javascript
/**
 * Validates that LLM response includes all positions meeting chronology depth criteria
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} jobHistory - Original job history positions
 * @returns {Object} { valid: boolean, errors: Array, correctedBullets: Array }
 */
function validateChronologyDepth(customizedBullets, jobHistory) {
  const CURRENT_YEAR = 2026;
  const RECENCY_THRESHOLD = 6;
  const TENURE_THRESHOLD = 5;
  
  const errors = [];
  const eligiblePositions = [];
  
  // Step 1: Calculate which positions SHOULD be included
  jobHistory.forEach((job, idx) => {
    const endYear = job.dates.includes('Present') 
      ? CURRENT_YEAR 
      : parseInt(job.dates.split('-')[1]);
    const startYear = parseInt(job.dates.split('-')[0]);
    const yearsSinceEnd = CURRENT_YEAR - endYear;
    const jobDuration = endYear - startYear;
    
    // Apply chronology depth logic from bo_bullet-generation-logic.md
    if (yearsSinceEnd <= RECENCY_THRESHOLD || job.dates.includes('Present')) {
      eligiblePositions.push({ ...job, index: idx, reason: 'Recent/Current', bulletCount: '3-5' });
    } else if (yearsSinceEnd > RECENCY_THRESHOLD && jobDuration >= TENURE_THRESHOLD) {
      eligiblePositions.push({ ...job, index: idx, reason: 'Tenure Exception', bulletCount: '2-3' });
    }
  });
  
  // Step 2: Validate LLM included all eligible positions
  const llmPositionTitles = customizedBullets.map(p => p.position.toLowerCase().trim());
  const missingPositions = eligiblePositions.filter(ep => 
    !llmPositionTitles.includes(ep.position.toLowerCase().trim())
  );
  
  if (missingPositions.length > 0) {
    errors.push({
      type: 'MISSING_POSITIONS',
      message: `Missing ${missingPositions.length} chronology-eligible position(s)`,
      positions: missingPositions.map(p => p.position)
    });
  }
  
  // Step 3: Validate LLM didn't include ineligible positions
  const extraPositions = customizedBullets.filter(cb => {
    const matchingJob = jobHistory.find(jh => 
      jh.position.toLowerCase().trim() === cb.position.toLowerCase().trim()
    );
    if (!matchingJob) return true; // Position not in job history at all
    
    const isEligible = eligiblePositions.some(ep => 
      ep.position.toLowerCase().trim() === cb.position.toLowerCase().trim()
    );
    return !isEligible;
  });
  
  if (extraPositions.length > 0) {
    errors.push({
      type: 'EXTRA_POSITIONS',
      message: `Included ${extraPositions.length} ineligible position(s)`,
      positions: extraPositions.map(p => p.position)
    });
  }
  
  return {
    valid: errors.length === 0,
    errors,
    eligiblePositions,
    correctedBullets: errors.length > 0 ? autoCorrectPositions(customizedBullets, eligiblePositions, jobHistory) : customizedBullets
  };
}
```

---

### Validation Function 2: `validatePositionMetadata()`

**Source:** Job history cross-reference

**Purpose:** Ensure position titles, companies, and dates match job history exactly (not JD).

```javascript
/**
 * Validates that position metadata matches job history, not JD
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} jobHistory - Original job history positions
 * @param {Object} jobDescription - JD object with title/company
 * @returns {Object} { valid: boolean, errors: Array, correctedBullets: Array }
 */
function validatePositionMetadata(customizedBullets, jobHistory, jobDescription) {
  const errors = [];
  const correctedBullets = [];
  
  customizedBullets.forEach((bullet, idx) => {
    const matchingJob = jobHistory.find(jh => 
      jh.position.toLowerCase().includes(bullet.position.toLowerCase()) ||
      bullet.position.toLowerCase().includes(jh.position.toLowerCase())
    );
    
    if (!matchingJob) {
      errors.push({
        type: 'POSITION_NOT_IN_HISTORY',
        index: idx,
        llmPosition: bullet.position,
        message: `Position "${bullet.position}" not found in job history`
      });
      return;
    }
    
    const correctedBullet = { ...bullet };
    let metadataChanged = false;
    
    // Validate position title
    if (bullet.position !== matchingJob.position) {
      errors.push({
        type: 'WRONG_POSITION_TITLE',
        index: idx,
        llmValue: bullet.position,
        correctValue: matchingJob.position,
        message: `Position title mismatch`
      });
      correctedBullet.position = matchingJob.position;
      metadataChanged = true;
    }
    
    // Validate company
    if (bullet.company !== matchingJob.company) {
      // Check if LLM used JD company (critical bug)
      const usedJDCompany = bullet.company === jobDescription.company;
      errors.push({
        type: usedJDCompany ? 'USED_JD_COMPANY' : 'WRONG_COMPANY',
        index: idx,
        llmValue: bullet.company,
        correctValue: matchingJob.company,
        severity: usedJDCompany ? 'CRITICAL' : 'HIGH',
        message: usedJDCompany 
          ? `Used JD company "${bullet.company}" instead of history company "${matchingJob.company}"`
          : `Company mismatch`
      });
      correctedBullet.company = matchingJob.company;
      metadataChanged = true;
    }
    
    // Validate dates
    if (bullet.dates !== matchingJob.dates) {
      errors.push({
        type: 'WRONG_DATES',
        index: idx,
        llmValue: bullet.dates,
        correctValue: matchingJob.dates,
        message: `Dates mismatch`
      });
      correctedBullet.dates = matchingJob.dates;
      metadataChanged = true;
    }
    
    correctedBullets.push(correctedBullet);
  });
  
  return {
    valid: errors.length === 0,
    errors,
    correctedBullets
  };
}
```

---

### Validation Function 3: `validateChronologicalOrder()`

**Purpose:** Ensure positions are in reverse chronological order (newest first).

```javascript
/**
 * Validates and enforces reverse chronological order
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array, correctedBullets: Array }
 */
function validateChronologicalOrder(customizedBullets) {
  const errors = [];
  
  // Extract end years for sorting
  const bulletsWithYears = customizedBullets.map((bullet, idx) => {
    const endYear = bullet.dates.includes('Present') 
      ? 9999 // Present jobs sort first
      : parseInt(bullet.dates.split('-')[1]);
    return { ...bullet, endYear, originalIndex: idx };
  });
  
  // Check if already sorted
  let isSorted = true;
  for (let i = 0; i < bulletsWithYears.length - 1; i++) {
    if (bulletsWithYears[i].endYear < bulletsWithYears[i + 1].endYear) {
      isSorted = false;
      errors.push({
        type: 'WRONG_ORDER',
        message: `Position ${i} (${bulletsWithYears[i].position}, ended ${bulletsWithYears[i].endYear}) comes before position ${i+1} (${bulletsWithYears[i+1].position}, ended ${bulletsWithYears[i+1].endYear})`
      });
    }
  }
  
  // Sort by end year descending (newest first)
  const sortedBullets = bulletsWithYears
    .sort((a, b) => b.endYear - a.endYear)
    .map(({ endYear, originalIndex, ...bullet }) => bullet);
  
  return {
    valid: isSorted,
    errors,
    correctedBullets: sortedBullets
  };
}
```

---

### Validation Function 4: `validateBulletCounts()`

**Source:** `optimization-tools/bullet-optimizer/bo_bullet-generation-logic.md` (lines 70-76)

**Purpose:** Ensure bullet counts match chronology depth rules (3-5 for recent, 2-3 for tenure exception).

```javascript
/**
 * Validates bullet counts per position match chronology depth rules
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} eligiblePositions - From validateChronologyDepth()
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateBulletCounts(customizedBullets, eligiblePositions) {
  const errors = [];
  
  customizedBullets.forEach((bullet, idx) => {
    const eligible = eligiblePositions.find(ep => 
      ep.position.toLowerCase().trim() === bullet.position.toLowerCase().trim()
    );
    
    if (!eligible) return; // Already caught by chronology depth validator
    
    const bulletCount = bullet.bullets.length;
    const expectedRange = eligible.bulletCount; // "3-5" or "2-3"
    const [min, max] = expectedRange.split('-').map(Number);
    
    if (bulletCount < min || bulletCount > max) {
      errors.push({
        type: 'WRONG_BULLET_COUNT',
        position: bullet.position,
        actual: bulletCount,
        expected: expectedRange,
        reason: eligible.reason,
        severity: bulletCount === 1 ? 'CRITICAL' : 'HIGH',
        message: `Position "${bullet.position}" has ${bulletCount} bullet(s), expected ${expectedRange} (${eligible.reason})`
      });
    }
  });
  
  return {
    valid: errors.length === 0,
    errors
  };
}
```

---

### Validation Function 5: `validateBulletFormat()`

**Source:** `core/format-rules.md` and `core/verb-categories.md`

**Purpose:** Validate character limits and verb categories.

```javascript
/**
 * Validates bullet formatting rules
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateBulletFormat(customizedBullets) {
  const errors = [];
  const CHAR_LIMIT = 210;
  const VALID_CATEGORIES = ['Built', 'Lead', 'Managed', 'Improved', 'Collaborate'];

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      // Character limit validation (hard limit from format-rules.md)
      if (bullet.text.length > CHAR_LIMIT) {
        errors.push({
          type: 'CHAR_LIMIT_EXCEEDED',
          position: position.position,
          bulletIndex: bulletIdx,
          actual: bullet.text.length,
          limit: CHAR_LIMIT,
          severity: 'CRITICAL',
          message: `Bullet exceeds ${CHAR_LIMIT} char limit: ${bullet.text.substring(0, 50)}...`
        });
      }

      // Verb category validation
      if (!VALID_CATEGORIES.includes(bullet.verbCategory)) {
        errors.push({
          type: 'INVALID_VERB_CATEGORY',
          position: position.position,
          bulletIndex: bulletIdx,
          actual: bullet.verbCategory,
          valid: VALID_CATEGORIES,
          message: `Invalid verb category "${bullet.verbCategory}"`
        });
      }
    });
  });

  return {
    valid: errors.length === 0,
    errors
  };
}
```

---

## Additional Validators (From Missing Guardrails Analysis)

The following validators implement guardrails from `PROJECT-INSTRUCTIONS.md` that were not covered by the initial 5 validators.

---

### CRITICAL PRIORITY VALIDATORS

---

### Validation Function 6: `validateMetricTraceability()` (Guardrail #1)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #1

**Purpose:** Ensure metrics in each position come from that position's job history, not other positions.

**Example Bug:**
- Position 1 bullet: "Reduced costs by 40%"
- But "40%" only appears in Position 3 job history
- **Validator catches:** Metric from wrong position

```javascript
/**
 * Validates that metrics in each position trace to that position's original bullets
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} jobHistory - Original job history with bullets
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateMetricTraceability(customizedBullets, jobHistory) {
  const errors = [];

  // Extract metrics (numbers, percentages, $amounts) from text
  const extractMetrics = (text) => {
    const patterns = [
      /\d+%/g,                    // Percentages
      /\$[\d,]+[KMB]?/gi,        // Dollar amounts
      /\d+\+?/g,                  // Numbers with optional +
      /\d+x/gi                    // Multipliers
    ];
    const metrics = [];
    patterns.forEach(pattern => {
      const matches = text.match(pattern) || [];
      metrics.push(...matches);
    });
    return [...new Set(metrics)];
  };

  customizedBullets.forEach((position, posIdx) => {
    // Find matching job history position
    const historyPosition = jobHistory.find(jh =>
      jh.position.toLowerCase().trim() === position.position.toLowerCase().trim()
    );

    if (!historyPosition) return; // Already caught by metadata validator

    // Extract metrics from original bullets
    const originalMetrics = historyPosition.bullets
      .flatMap(b => extractMetrics(b))
      .map(m => m.toLowerCase());

    // Check each optimized bullet's metrics
    position.bullets.forEach((bullet, bulletIdx) => {
      const bulletMetrics = extractMetrics(bullet.text);

      bulletMetrics.forEach(metric => {
        const metricLower = metric.toLowerCase();
        // Check if metric exists in original position
        if (!originalMetrics.some(om => om === metricLower || metricLower.includes(om) || om.includes(metricLower))) {
          // Check if metric exists in OTHER positions (wrong source)
          const otherPositionHasMetric = jobHistory.some((jh, jhIdx) => {
            if (jh.position === historyPosition.position) return false;
            const otherMetrics = jh.bullets.flatMap(b => extractMetrics(b)).map(m => m.toLowerCase());
            return otherMetrics.some(om => om === metricLower);
          });

          if (otherPositionHasMetric) {
            errors.push({
              type: 'METRIC_WRONG_POSITION',
              position: position.position,
              bulletIndex: bulletIdx,
              metric: metric,
              severity: 'HIGH',
              message: `Metric "${metric}" in "${position.position}" appears to be from a different position`
            });
          }
        }
      });
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 7: `validateSummaryAbstraction()` (Guardrail #3)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #3

**Purpose:** Ensure summary doesn't echo bullets (no >50% keyword overlap).

**Example Bug:**
- Bullet: "Built scalable API infrastructure for microservices"
- Summary: "Built scalable API infrastructure for microservices across teams"
- **Validator catches:** 85% keyword overlap

```javascript
/**
 * Validates that professional summary doesn't share >50% keywords with any single bullet
 * @param {Object} professionalSummary - LLM response summary object
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateSummaryAbstraction(professionalSummary, customizedBullets) {
  const errors = [];

  if (!professionalSummary || !professionalSummary.text) {
    return { valid: true, errors: [] };
  }

  const stopWords = new Set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'was', 'are', 'were', 'been', 'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'that', 'which', 'who', 'whom', 'this', 'these', 'those', 'it', 'its', 'as', 'from', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'between', 'under', 'over']);

  const extractKeywords = (text) => {
    return text.toLowerCase()
      .replace(/[^\w\s]/g, '')
      .split(/\s+/)
      .filter(word => word.length > 2 && !stopWords.has(word));
  };

  const summarySentences = professionalSummary.text.split(/[.!?]+/).filter(s => s.trim());

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      const bulletKeywords = extractKeywords(bullet.text);

      summarySentences.forEach((sentence, sentIdx) => {
        const sentenceKeywords = extractKeywords(sentence);
        if (sentenceKeywords.length === 0) return;

        const overlap = sentenceKeywords.filter(k => bulletKeywords.includes(k));
        const overlapPercentage = overlap.length / sentenceKeywords.length;

        if (overlapPercentage > 0.50) {
          errors.push({
            type: 'SUMMARY_ECHOES_BULLET',
            sentenceIndex: sentIdx,
            position: position.position,
            bulletIndex: bulletIdx,
            overlapPercentage: Math.round(overlapPercentage * 100),
            overlappingKeywords: overlap,
            severity: 'HIGH',
            message: `Summary sentence ${sentIdx + 1} shares ${Math.round(overlapPercentage * 100)}% keywords with bullet`
          });
        }
      });
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 8: `validateVerbDiversity()` (Guardrail #9)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #9, `core/verb-categories.md`

**Purpose:** No verb category used twice in same position.

**Example Bug:**
- Position 1 has 4 bullets: Built, Built, Built, Managed
- **Validator catches:** "Built" used 3 times

```javascript
/**
 * Validates verb category diversity within each position
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateVerbDiversity(customizedBullets) {
  const errors = [];

  customizedBullets.forEach((position, posIdx) => {
    const verbCounts = {};

    position.bullets.forEach((bullet, bulletIdx) => {
      const category = bullet.verbCategory;
      if (!category) return;

      if (!verbCounts[category]) {
        verbCounts[category] = [];
      }
      verbCounts[category].push(bulletIdx);
    });

    Object.entries(verbCounts).forEach(([category, indices]) => {
      if (indices.length > 1) {
        errors.push({
          type: 'VERB_CATEGORY_REPEATED',
          position: position.position,
          category: category,
          bulletIndices: indices,
          count: indices.length,
          severity: 'MEDIUM',
          message: `Position "${position.position}" uses verb category "${category}" ${indices.length} times`
        });
      }
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 9: `validateSummaryMetrics()` (Guardrail #13)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #13

**Purpose:** Every summary metric must trace to at least one bullet.

**Example Bug:**
- Summary: "Led teams of 50+ engineers"
- No bullet mentions "50+ engineers"
- **Validator catches:** Unsupported summary claim

```javascript
/**
 * Validates that every metric in professional summary traces to a bullet
 * @param {Object} professionalSummary - LLM response summary object
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateSummaryMetrics(professionalSummary, customizedBullets) {
  const errors = [];

  if (!professionalSummary || !professionalSummary.text) {
    return { valid: true, errors: [] };
  }

  const extractMetrics = (text) => {
    const patterns = [
      /\d+%/g,
      /\$[\d,]+[KMB]?/gi,
      /\d+\+?\s*(years?|yrs?)/gi,
      /\d+\+?\s*(teams?|engineers?|stakeholders?|members?)/gi,
      /\d+x/gi,
      /\b\d{2,}\b/g
    ];
    const metrics = [];
    patterns.forEach(pattern => {
      const matches = text.match(pattern) || [];
      metrics.push(...matches);
    });
    return [...new Set(metrics)];
  };

  const summaryMetrics = extractMetrics(professionalSummary.text);
  const allBulletTexts = customizedBullets.flatMap(pos => pos.bullets.map(b => b.text)).join(' ');

  summaryMetrics.forEach(metric => {
    // Exception: Years can be calculated from dates
    if (/\d+\+?\s*(years?|yrs?)/i.test(metric)) return;

    const metricNumber = metric.match(/\d+/)?.[0];
    if (metricNumber && !allBulletTexts.includes(metricNumber)) {
      errors.push({
        type: 'SUMMARY_METRIC_NOT_TRACEABLE',
        metric: metric,
        severity: 'HIGH',
        message: `Summary metric "${metric}" not found in any bullet (Guardrail #13)`
      });
    }
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 10: `validatePhraseRepetition()` (Guardrail #15)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #15

**Purpose:** No 3+ word phrase should be repeated 3+ times.

**Example Bug:**
- Phrase "across multiple teams" appears in 5 bullets
- **Validator catches:** Excessive repetition

```javascript
/**
 * Validates no phrase is repeated excessively across all content
 * @param {Object} professionalSummary - LLM response summary object
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validatePhraseRepetition(professionalSummary, customizedBullets) {
  const errors = [];

  const allTexts = [];
  if (professionalSummary?.text) allTexts.push(professionalSummary.text);
  customizedBullets.forEach(pos => pos.bullets.forEach(b => allTexts.push(b.text)));

  const combinedText = allTexts.join(' ').toLowerCase();

  const extractNGrams = (text, n) => {
    const words = text.replace(/[^\w\s]/g, '').split(/\s+/).filter(w => w.length > 2);
    const ngrams = {};
    for (let i = 0; i <= words.length - n; i++) {
      const phrase = words.slice(i, i + n).join(' ');
      if (phrase.length > 8) ngrams[phrase] = (ngrams[phrase] || 0) + 1;
    }
    return ngrams;
  };

  [3, 4, 5].forEach(n => {
    const ngrams = extractNGrams(combinedText, n);
    Object.entries(ngrams).forEach(([phrase, count]) => {
      if (count >= 3) {
        errors.push({
          type: 'PHRASE_REPEATED',
          phrase: phrase,
          count: count,
          severity: 'MEDIUM',
          message: `Phrase "${phrase}" repeated ${count} times (Guardrail #15)`
        });
      }
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 11: `validateMetricPreservation()` (Guardrail #29)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #29

**Purpose:** Don't lose metrics during optimization.

**Example Bug:**
- Original: "Managed 20 API calls across 6 systems"
- Optimized: "Managed API calls to ensure alignment"
- **Validator catches:** Lost metrics {20, 6}

```javascript
/**
 * Validates that metrics from original bullets are preserved
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} jobHistory - Original job history with bullets
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateMetricPreservation(customizedBullets, jobHistory) {
  const errors = [];

  const extractMetrics = (text) => {
    const patterns = [/\d+%/g, /\$[\d,]+[KMB]?/gi, /\d+x/gi, /\b\d{2,}\b/g];
    const metrics = [];
    patterns.forEach(pattern => {
      const matches = text.match(pattern) || [];
      metrics.push(...matches.map(m => m.toLowerCase()));
    });
    return [...new Set(metrics)];
  };

  customizedBullets.forEach((position, posIdx) => {
    const historyPosition = jobHistory.find(jh =>
      jh.position.toLowerCase().trim() === position.position.toLowerCase().trim()
    );
    if (!historyPosition) return;

    const originalMetrics = historyPosition.bullets.flatMap(b => extractMetrics(b));
    const optimizedMetrics = position.bullets.flatMap(b => extractMetrics(b.text));

    const lostMetrics = originalMetrics.filter(om =>
      !optimizedMetrics.some(optM => optM === om || optM.includes(om) || om.includes(optM))
    );

    if (lostMetrics.length > 0) {
      errors.push({
        type: 'METRICS_LOST',
        position: position.position,
        lostMetrics: lostMetrics,
        severity: 'HIGH',
        message: `Position "${position.position}" lost metrics: ${lostMetrics.join(', ')}`
      });
    }
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 12: `validateKeywordEvidence()` (Guardrail #32)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #32, `bo_keyword_handling.md`

**Purpose:** Warn if keyword lacks job history evidence.

**Example Bug:**
- USE keyword: "Kubernetes"
- Job history: No mention of Kubernetes
- **Validator catches:** Unevidenced keyword, flags warning

```javascript
/**
 * Validates that USE keywords have evidence in job history
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} jobHistory - Original job history
 * @param {Array} useKeywords - Keywords marked for use
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateKeywordEvidence(customizedBullets, jobHistory, useKeywords) {
  const errors = [];
  const warnings = [];

  const allHistoryText = jobHistory.flatMap(jh => jh.bullets).join(' ').toLowerCase();
  const allOptimizedText = customizedBullets.flatMap(pos => pos.bullets.map(b => b.text)).join(' ').toLowerCase();

  useKeywords.forEach(keyword => {
    const keywordLower = keyword.toLowerCase().replace(/^custom:\s*/i, '');
    if (allOptimizedText.includes(keywordLower) && !allHistoryText.includes(keywordLower)) {
      warnings.push({
        type: 'KEYWORD_NO_EVIDENCE',
        keyword: keyword,
        severity: 'WARNING',
        message: `Keyword "${keyword}" used but has no evidence in job history (Guardrail #32)`
      });
    }
  });

  return { valid: true, errors, warnings };
}
```

---

### Validation Function 13: `validateNarrativeFit()` (Guardrail #33)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #33

**Purpose:** Ensure top 3 JD requirements are addressed by bullets.

**Example Bug:**
- JD top requirements: Python, AWS, Team Leadership
- Bullets cover: Python, AWS (missing Team Leadership)
- **Validator catches:** Narrative gap

```javascript
/**
 * Validates that top JD requirements are addressed in bullets
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Object} narrativeVerification - LLM's self-reported verification
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateNarrativeFit(customizedBullets, narrativeVerification) {
  const errors = [];
  const warnings = [];

  if (narrativeVerification?.topRequirementsMet) {
    const metCount = narrativeVerification.topRequirementsMet.length;
    if (metCount < 3) {
      warnings.push({
        type: 'NARRATIVE_GAP',
        metCount: metCount,
        gaps: narrativeVerification.narrativeGaps || [],
        severity: 'WARNING',
        message: `Only ${metCount} of top 3 JD requirements addressed (Guardrail #33)`
      });
    }
  }

  if (narrativeVerification?.narrativeGaps?.length > 0) {
    narrativeVerification.narrativeGaps.forEach(gap => {
      warnings.push({
        type: 'NARRATIVE_GAP_ITEM',
        gap: gap,
        severity: 'WARNING',
        message: `Narrative gap: "${gap}" not addressed`
      });
    });
  }

  if (narrativeVerification?.roleLevelAlignment === 'Mismatch') {
    warnings.push({
      type: 'ROLE_LEVEL_MISMATCH',
      severity: 'WARNING',
      message: 'Role level mismatch between candidate experience and JD'
    });
  }

  return { valid: true, errors, warnings };
}
```

---

### HIGH PRIORITY VALIDATORS

---

### Validation Function 14: `validateLimitationEnforcement()` (Guardrail #5)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #5

**Purpose:** Don't claim skills in honest_limitations.

**Example Bug:**
- Limitation: "No Python experience"
- Bullet: "Expert Python developer"
- **Validator catches:** Skill claimed that's in limitations

```javascript
/**
 * Validates that bullets don't claim skills in honest_limitations
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} honestLimitations - Array of limitation strings
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateLimitationEnforcement(customizedBullets, honestLimitations) {
  const errors = [];

  if (!honestLimitations || honestLimitations.length === 0) {
    return { valid: true, errors: [] };
  }

  // Extract skills/keywords from limitations
  const limitationKeywords = honestLimitations.flatMap(limit => {
    // Extract potential skill names
    const matches = limit.match(/(?:no|limited|lacking|without)\s+(\w+(?:\s+\w+)?)/gi) || [];
    return matches.map(m => m.replace(/^(no|limited|lacking|without)\s+/i, '').toLowerCase());
  });

  const allBulletText = customizedBullets
    .flatMap(pos => pos.bullets.map(b => b.text))
    .join(' ')
    .toLowerCase();

  limitationKeywords.forEach(keyword => {
    if (allBulletText.includes(keyword)) {
      errors.push({
        type: 'LIMITATION_VIOLATED',
        keyword: keyword,
        severity: 'CRITICAL',
        message: `Claimed skill "${keyword}" but it's listed in honest_limitations (Guardrail #5)`
      });
    }
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 15: `validateSkillClassification()` (Guardrail #7)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #7

**Purpose:** Skill can't be in both hard & soft skills.

**Example Bug:**
- Hard skills: ["Leadership", "Python"]
- Soft skills: ["Leadership", "Communication"]
- **Validator catches:** "Leadership" in both lists

```javascript
/**
 * Validates that skills aren't classified as both hard and soft
 * @param {Object} generatedContent - Full LLM response
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateSkillClassification(generatedContent) {
  const errors = [];

  // Check if skill sections exist
  const hardSkills = generatedContent.hardSkills || generatedContent.technicalSkills || [];
  const softSkills = generatedContent.softSkills || [];

  const hardSkillsLower = hardSkills.map(s => s.toLowerCase().trim());
  const softSkillsLower = softSkills.map(s => s.toLowerCase().trim());

  const overlap = hardSkillsLower.filter(s => softSkillsLower.includes(s));

  overlap.forEach(skill => {
    errors.push({
      type: 'SKILL_DUAL_CLASSIFICATION',
      skill: skill,
      severity: 'MEDIUM',
      message: `Skill "${skill}" classified as both hard and soft skill (Guardrail #7)`
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 16: `validateBudgetEnforcement()` (Guardrail #8)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #8

**Purpose:** 100-210 char per bullet, 350-500 total words.

```javascript
/**
 * Validates character and word budget constraints
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Object} professionalSummary - LLM response summary
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateBudgetEnforcement(customizedBullets, professionalSummary) {
  const errors = [];
  const MIN_CHAR = 100;
  const MAX_CHAR = 210;
  const MIN_WORDS = 350;
  const MAX_WORDS = 500;

  // Check each bullet
  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      const charCount = bullet.text.length;
      if (charCount < MIN_CHAR) {
        errors.push({
          type: 'BULLET_TOO_SHORT',
          position: position.position,
          bulletIndex: bulletIdx,
          actual: charCount,
          minimum: MIN_CHAR,
          severity: 'MEDIUM',
          message: `Bullet has ${charCount} chars (min ${MIN_CHAR})`
        });
      }
      // MAX_CHAR already checked by validateBulletFormat
    });
  });

  // Check total word count
  const allBulletWords = customizedBullets
    .flatMap(pos => pos.bullets.map(b => b.text))
    .join(' ')
    .split(/\s+/)
    .filter(w => w.length > 0);

  const summaryWords = professionalSummary?.text
    ? professionalSummary.text.split(/\s+/).filter(w => w.length > 0)
    : [];

  const totalWords = allBulletWords.length + summaryWords.length;

  if (totalWords < MIN_WORDS) {
    errors.push({
      type: 'TOTAL_WORDS_TOO_FEW',
      actual: totalWords,
      minimum: MIN_WORDS,
      severity: 'MEDIUM',
      message: `Total word count ${totalWords} (min ${MIN_WORDS})`
    });
  }

  if (totalWords > MAX_WORDS) {
    errors.push({
      type: 'TOTAL_WORDS_TOO_MANY',
      actual: totalWords,
      maximum: MAX_WORDS,
      severity: 'MEDIUM',
      message: `Total word count ${totalWords} (max ${MAX_WORDS})`
    });
  }

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 17: `validateKeywordDensity()` (Guardrail #10)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #10

**Purpose:** Max 3 JD keywords per bullet, no keyword >2x.

**Example Bug:**
- Bullet: "Python Python Python development with Python APIs"
- **Validator catches:** "Python" used 4 times in one bullet

```javascript
/**
 * Validates keyword density constraints
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} useKeywords - Keywords marked for use
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateKeywordDensity(customizedBullets, useKeywords) {
  const errors = [];
  const MAX_KEYWORDS_PER_BULLET = 3;
  const MAX_KEYWORD_REPEATS = 2;

  const keywordsLower = useKeywords.map(k => k.toLowerCase().replace(/^custom:\s*/i, ''));

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      const bulletLower = bullet.text.toLowerCase();
      let keywordCount = 0;
      const keywordCounts = {};

      keywordsLower.forEach(keyword => {
        const regex = new RegExp(`\\b${keyword.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\\b`, 'gi');
        const matches = bulletLower.match(regex) || [];
        if (matches.length > 0) {
          keywordCount++;
          keywordCounts[keyword] = matches.length;
        }
      });

      // Check max keywords per bullet
      if (keywordCount > MAX_KEYWORDS_PER_BULLET) {
        errors.push({
          type: 'TOO_MANY_KEYWORDS',
          position: position.position,
          bulletIndex: bulletIdx,
          actual: keywordCount,
          maximum: MAX_KEYWORDS_PER_BULLET,
          severity: 'MEDIUM',
          message: `Bullet has ${keywordCount} keywords (max ${MAX_KEYWORDS_PER_BULLET})`
        });
      }

      // Check keyword repeats
      Object.entries(keywordCounts).forEach(([keyword, count]) => {
        if (count > MAX_KEYWORD_REPEATS) {
          errors.push({
            type: 'KEYWORD_REPEATED',
            position: position.position,
            bulletIndex: bulletIdx,
            keyword: keyword,
            count: count,
            maximum: MAX_KEYWORD_REPEATS,
            severity: 'MEDIUM',
            message: `Keyword "${keyword}" used ${count} times in one bullet`
          });
        }
      });
    });
  });

  return { valid: errors.length === 0, errors };
}
```

---

### Validation Function 18: `validateMetricPlausibility()` (Guardrail #11)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #11

**Purpose:** Percentages 0-100%, time savings valid.

**Example Bug:**
- Bullet: "Improved efficiency by 150%"
- **Validator catches:** Percentage > 100%

```javascript
/**
 * Validates that metrics are plausible
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateMetricPlausibility(customizedBullets) {
  const errors = [];
  const warnings = [];

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      // Check percentages > 100
      const highPercentages = bullet.text.match(/\b(\d{3,})\s*%/g) || [];
      highPercentages.forEach(match => {
        const value = parseInt(match);
        if (value > 100 && !bullet.text.toLowerCase().includes('growth') && !bullet.text.toLowerCase().includes('increase')) {
          warnings.push({
            type: 'HIGH_PERCENTAGE',
            position: position.position,
            bulletIndex: bulletIdx,
            value: match,
            severity: 'WARNING',
            message: `Percentage ${match} may be implausible (>100%)`
          });
        }
      });

      // Check for impossible time savings (>100%)
      const timeSavings = bullet.text.match(/reduced.*?by\s+(\d+)\s*%/gi) || [];
      timeSavings.forEach(match => {
        const value = parseInt(match.match(/\d+/)[0]);
        if (value > 100) {
          errors.push({
            type: 'IMPOSSIBLE_TIME_SAVINGS',
            position: position.position,
            bulletIndex: bulletIdx,
            value: value,
            severity: 'HIGH',
            message: `Time savings of ${value}% is impossible (max 100%)`
          });
        }
      });

      // Check for implausibly large numbers
      const largeNumbers = bullet.text.match(/\b(\d{7,})\b/g) || []; // 7+ digit numbers
      largeNumbers.forEach(num => {
        if (!bullet.text.includes('$') && !bullet.text.toLowerCase().includes('revenue')) {
          warnings.push({
            type: 'LARGE_NUMBER',
            position: position.position,
            bulletIndex: bulletIdx,
            value: num,
            severity: 'WARNING',
            message: `Large number ${num} may need verification`
          });
        }
      });
    });
  });

  return { valid: errors.length === 0, errors, warnings };
}
```

---

### Validation Function 19: `validateScopeAttribution()` (Guardrail #17)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #17

**Purpose:** Achievements match user's scope.

**Example Bug:**
- Junior developer claiming "company-wide transformation"
- **Validator catches:** Scope mismatch

```javascript
/**
 * Validates that achievements match candidate's scope/level
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Object} candidateProfile - Profile with experience level
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateScopeAttribution(customizedBullets, candidateProfile) {
  const errors = [];
  const warnings = [];

  // High-scope phrases that typically require senior roles
  const seniorScopePhrases = [
    'company-wide', 'enterprise-wide', 'organization-wide',
    'global', 'international', 'multinational',
    'C-suite', 'executive', 'board',
    'millions', 'billion',
    'hundreds of employees', '1000+ employees'
  ];

  // Determine candidate level from profile or positions
  const isJunior = candidateProfile?.experienceLevel === 'junior' ||
    candidateProfile?.yearsExperience < 3;

  if (!isJunior) {
    return { valid: true, errors: [], warnings: [] };
  }

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      const bulletLower = bullet.text.toLowerCase();

      seniorScopePhrases.forEach(phrase => {
        if (bulletLower.includes(phrase.toLowerCase())) {
          warnings.push({
            type: 'SCOPE_MISMATCH',
            position: position.position,
            bulletIndex: bulletIdx,
            phrase: phrase,
            severity: 'WARNING',
            message: `Phrase "${phrase}" may be too senior for candidate level (Guardrail #17)`
          });
        }
      });
    });
  });

  return { valid: true, errors, warnings };
}
```

---

### Validation Function 20: `validateEmDash()` (Guardrail #22)

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #22

**Purpose:** No em-dash characters (—) which can break ATS parsing.

```javascript
/**
 * Validates no em-dash characters that could break ATS
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Object} professionalSummary - LLM response summary
 * @returns {Object} { valid: boolean, errors: Array }
 */
function validateEmDash(customizedBullets, professionalSummary) {
  const errors = [];

  const checkForEmDash = (text, location) => {
    if (text.includes('—') || text.includes('–')) {
      errors.push({
        type: 'EM_DASH_FOUND',
        location: location,
        severity: 'MEDIUM',
        message: `Em-dash/en-dash found in ${location} - may break ATS (Guardrail #22)`
      });
    }
  };

  customizedBullets.forEach((position, posIdx) => {
    position.bullets.forEach((bullet, bulletIdx) => {
      checkForEmDash(bullet.text, `${position.position} bullet ${bulletIdx + 1}`);
    });
  });

  if (professionalSummary?.text) {
    checkForEmDash(professionalSummary.text, 'Professional Summary');
  }

  return { valid: errors.length === 0, errors };
}
```

---

### SHARED MODULE VALIDATORS (From optimization-tools/shared/)

These validators enforce rules from the shared modules that ALL optimization tools must follow.

---

### Validation Function 21: `validateVerbDistribution()` (shared_verb_taxonomy.md)

**Source:** `optimization-tools/shared/shared_verb_taxonomy.md` (Verb Distribution Threshold Rule)

**Purpose:** Flag any verb category representing <5% of total bullets.

**Rule:** Any action verb category <5% = TWEAK flag. Target: 13-27% per category.

```javascript
/**
 * Validates verb category distribution across all bullets
 * Source: shared_verb_taxonomy.md - Verb Distribution Threshold Rule
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, warnings: Array, distribution: Object }
 */
function validateVerbDistribution(customizedBullets) {
  const warnings = [];
  const VALID_CATEGORIES = ['Built', 'Lead', 'Managed', 'Improved', 'Collaborate'];
  const THRESHOLD_PERCENT = 5;
  const BALANCED_MIN = 13;
  const BALANCED_MAX = 27;

  // Count bullets per category
  const categoryCounts = {};
  VALID_CATEGORIES.forEach(cat => categoryCounts[cat] = 0);

  let totalBullets = 0;
  customizedBullets.forEach(position => {
    position.bullets.forEach(bullet => {
      totalBullets++;
      const cat = bullet.verbCategory;
      if (cat && categoryCounts.hasOwnProperty(cat)) {
        categoryCounts[cat]++;
      }
    });
  });

  // Calculate percentages and flag imbalances
  const distribution = {};
  VALID_CATEGORIES.forEach(cat => {
    const count = categoryCounts[cat];
    const percent = totalBullets > 0 ? (count / totalBullets) * 100 : 0;
    let status;

    if (percent >= 28) {
      status = 'Over-Represented';
      warnings.push({
        type: 'VERB_OVER_REPRESENTED',
        category: cat,
        percent: Math.round(percent),
        severity: 'WARNING',
        message: `"${cat}" over-represented (${Math.round(percent)}%) - diversify`
      });
    } else if (percent >= BALANCED_MIN && percent <= BALANCED_MAX) {
      status = 'Well Balanced';
    } else if (percent >= THRESHOLD_PERCENT) {
      status = 'Under-Represented';
      warnings.push({
        type: 'VERB_UNDER_REPRESENTED',
        category: cat,
        percent: Math.round(percent),
        severity: 'WARNING',
        message: `"${cat}" under-represented (${Math.round(percent)}%) - add more`
      });
    } else {
      status = 'Critical Gap';
      warnings.push({
        type: 'VERB_CRITICAL_GAP',
        category: cat,
        percent: Math.round(percent),
        severity: 'WARNING',
        message: `"${cat}" critical gap (${Math.round(percent)}%) - missing verb category`
      });
    }

    distribution[cat] = { count, percent: Math.round(percent), status };
  });

  return { valid: true, errors: [], warnings, distribution };
}
```

---

### Validation Function 22: `validateMetricsDensity()` (shared_core_principles.md - P1)

**Source:** `optimization-tools/shared/shared_core_principles.md` (Principle 1: Quantified Impact)

**Purpose:** Ensure 70-80% of bullets contain metrics.

**Rule:** Target 70-80% of bullets with quantified impact (%, $, numbers, time).

```javascript
/**
 * Validates that 70-80% of bullets contain metrics
 * Source: shared_core_principles.md - Principle 1: Quantified Impact
 * @param {Array} customizedBullets - LLM response bullets array
 * @returns {Object} { valid: boolean, warnings: Array, metricsReport: Object }
 */
function validateMetricsDensity(customizedBullets) {
  const warnings = [];
  const TARGET_MIN = 70;
  const TARGET_MAX = 80;

  const metricPattern = /\d+%|\$[\d,]+[KMB]?|\d+x|\b\d{2,}\b|\d+\+?\s*(hours?|days?|weeks?|months?|years?)/gi;

  let totalBullets = 0;
  let bulletsWithMetrics = 0;

  customizedBullets.forEach(position => {
    position.bullets.forEach(bullet => {
      totalBullets++;
      // Reset lastIndex for global regex
      metricPattern.lastIndex = 0;
      if (metricPattern.test(bullet.text)) {
        bulletsWithMetrics++;
      }
    });
  });

  const percent = totalBullets > 0 ? (bulletsWithMetrics / totalBullets) * 100 : 0;
  const metricsReport = {
    total: totalBullets,
    withMetrics: bulletsWithMetrics,
    withoutMetrics: totalBullets - bulletsWithMetrics,
    percent: Math.round(percent),
    target: `${TARGET_MIN}-${TARGET_MAX}%`,
    status: percent >= TARGET_MIN ? 'On Target' : 'Below Target'
  };

  if (percent < TARGET_MIN) {
    warnings.push({
      type: 'METRICS_DENSITY_LOW',
      actual: Math.round(percent),
      target: TARGET_MIN,
      severity: 'WARNING',
      message: `Only ${Math.round(percent)}% of bullets have metrics (target: ${TARGET_MIN}-${TARGET_MAX}%)`
    });
  }

  return { valid: true, errors: [], warnings, metricsReport };
}
```

---

### Validation Function 23: `validateKeywordEvidenceTier()` (shared_keyword_validation.md)

**Source:** `optimization-tools/shared/shared_keyword_validation.md` (Evidence Tiers)

**Purpose:** Distinguish between hands-on work vs. documentation-only evidence.

**Rule:** "Documented X" ≠ "Built X". Check verb context for evidence tier.

**Evidence Tiers:**
- **Tier 1 (100%):** Built, Developed, Implemented, Deployed, Managed, Operated
- **Tier 2 (50%):** Tested, Assisted, Participated, Configured under guidance
- **Tier 3 (0%):** Documented, Wrote, Researched, Interviewed, Gathered requirements

```javascript
/**
 * Validates keyword evidence tier (hands-on vs. documentation)
 * Source: shared_keyword_validation.md - Evidence Tiers
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Array} useKeywords - Keywords marked for use
 * @returns {Object} { valid: boolean, warnings: Array, evidenceReport: Object }
 */
function validateKeywordEvidenceTier(customizedBullets, useKeywords) {
  const warnings = [];

  // Tier 1: Direct evidence verbs (100% weight)
  const TIER1_VERBS = ['built', 'developed', 'implemented', 'deployed', 'configured',
    'managed', 'administered', 'operated', 'maintained', 'engineered', 'architected',
    'debugged', 'troubleshot', 'resolved', 'migrated', 'upgraded', 'scaled', 'optimized'];

  // Tier 3: Documentation-only verbs (0% weight)
  const TIER3_VERBS = ['documented', 'wrote', 'researched', 'evaluated', 'assessed',
    'analyzed', 'interviewed', 'gathered', 'trained', 'observed', 'shadowed'];

  const evidenceReport = { tier1: [], tier2: [], tier3: [], notEvidenced: [] };

  const allBulletText = customizedBullets
    .flatMap(pos => pos.bullets.map(b => b.text.toLowerCase()))
    .join(' ');

  useKeywords.forEach(keyword => {
    const keywordLower = keyword.toLowerCase().replace(/^custom:\s*/i, '');

    if (!allBulletText.includes(keywordLower)) {
      evidenceReport.notEvidenced.push(keyword);
      return;
    }

    // Find evidence tier based on surrounding verbs
    let evidenceTier = 2; // Default to Tier 2

    customizedBullets.forEach(position => {
      position.bullets.forEach(bullet => {
        if (bullet.text.toLowerCase().includes(keywordLower)) {
          const bulletLower = bullet.text.toLowerCase();
          const firstWord = bulletLower.split(/\s+/)[0];

          if (TIER3_VERBS.some(v => firstWord.startsWith(v))) {
            evidenceTier = 3;
          } else if (TIER1_VERBS.some(v => firstWord.startsWith(v))) {
            evidenceTier = 1;
          }
        }
      });
    });

    if (evidenceTier === 3) {
      warnings.push({
        type: 'KEYWORD_DOCUMENTATION_ONLY',
        keyword: keyword,
        tier: 3,
        severity: 'WARNING',
        message: `"${keyword}" has documentation-only evidence (Tier 3: 0% weight)`
      });
      evidenceReport.tier3.push(keyword);
    } else if (evidenceTier === 2) {
      evidenceReport.tier2.push(keyword);
    } else {
      evidenceReport.tier1.push(keyword);
    }
  });

  return { valid: true, errors: [], warnings, evidenceReport };
}
```

---

### MODERATE PRIORITY VALIDATORS

---

### Validation Function 24: `validateRecencyWeighting()` (Guardrail #12) - MODERATE

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #12

**Purpose:** Position 1 gets 3+ bullets, 2+ metrics.

```javascript
/**
 * Validates that most recent position gets appropriate emphasis
 * @param {Array} customizedBullets - LLM response bullets array (should be sorted)
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateRecencyWeighting(customizedBullets) {
  const errors = [];
  const warnings = [];

  if (customizedBullets.length === 0) {
    return { valid: true, errors: [], warnings: [] };
  }

  const mostRecent = customizedBullets[0]; // Assumes already sorted

  // Check bullet count
  if (mostRecent.bullets.length < 3) {
    warnings.push({
      type: 'RECENT_POSITION_FEW_BULLETS',
      position: mostRecent.position,
      actual: mostRecent.bullets.length,
      minimum: 3,
      severity: 'WARNING',
      message: `Most recent position has ${mostRecent.bullets.length} bullets (recommend 3+)`
    });
  }

  // Check metric count
  const metricPattern = /\d+%|\$[\d,]+|\d+x|\b\d{2,}\b/g;
  const metricCount = mostRecent.bullets
    .map(b => (b.text.match(metricPattern) || []).length)
    .reduce((a, b) => a + b, 0);

  if (metricCount < 2) {
    warnings.push({
      type: 'RECENT_POSITION_FEW_METRICS',
      position: mostRecent.position,
      actual: metricCount,
      minimum: 2,
      severity: 'WARNING',
      message: `Most recent position has ${metricCount} metrics (recommend 2+)`
    });
  }

  return { valid: true, errors, warnings };
}
```

---

### Validation Function 25: `validateAcronymExpansion()` (Guardrail #20) - MODERATE

**Source:** `PROJECT-INSTRUCTIONS.md` Guardrail #20

**Purpose:** Spell out acronyms on first use.

**Example Bug:**
- "Used ML for NLP tasks"
- **Validator catches:** ML and NLP not expanded on first use

```javascript
/**
 * Validates that acronyms are expanded on first use
 * @param {Array} customizedBullets - LLM response bullets array
 * @param {Object} professionalSummary - LLM response summary
 * @returns {Object} { valid: boolean, errors: Array, warnings: Array }
 */
function validateAcronymExpansion(customizedBullets, professionalSummary) {
  const errors = [];
  const warnings = [];

  // Common technical acronyms that should be expanded
  const commonAcronyms = {
    'ML': 'Machine Learning',
    'AI': 'Artificial Intelligence',
    'NLP': 'Natural Language Processing',
    'API': 'Application Programming Interface',
    'CI': 'Continuous Integration',
    'CD': 'Continuous Deployment',
    'AWS': 'Amazon Web Services',
    'GCP': 'Google Cloud Platform',
    'K8s': 'Kubernetes',
    'ETL': 'Extract Transform Load',
    'SQL': 'Structured Query Language',
    'KPI': 'Key Performance Indicator',
    'ROI': 'Return on Investment',
    'SaaS': 'Software as a Service',
    'REST': 'Representational State Transfer'
  };

  // Combine all text in order
  const allTexts = [];
  if (professionalSummary?.text) allTexts.push(professionalSummary.text);
  customizedBullets.forEach(pos => pos.bullets.forEach(b => allTexts.push(b.text)));

  const combinedText = allTexts.join(' ');
  const seenAcronyms = new Set();

  Object.entries(commonAcronyms).forEach(([acronym, expansion]) => {
    const acronymRegex = new RegExp(`\\b${acronym}\\b`, 'g');
    const expansionLower = expansion.toLowerCase();

    if (acronymRegex.test(combinedText)) {
      // Check if expansion appears before or with first acronym use
      const firstAcronymIndex = combinedText.search(acronymRegex);
      const expansionIndex = combinedText.toLowerCase().indexOf(expansionLower);

      if (expansionIndex === -1 || expansionIndex > firstAcronymIndex) {
        warnings.push({
          type: 'ACRONYM_NOT_EXPANDED',
          acronym: acronym,
          expansion: expansion,
          severity: 'LOW',
          message: `Acronym "${acronym}" not expanded on first use (Guardrail #20)`
        });
      }
    }
  });

  return { valid: true, errors, warnings };
}
```

---

### Master Validation Function (All 25 Validators)

**Location:** Add after line 811 in `Should-I-Apply-local.jsx` (and webgui.jsx)

**Total Validators:** 25 (covering 30+ guardrails from PROJECT-INSTRUCTIONS.md + shared modules)

| Priority | Count | Validators |
|----------|-------|------------|
| **Core (Bug Fixes)** | 5 | 1-5: ChronologyDepth, PositionMetadata, ChronologicalOrder, BulletCounts, BulletFormat |
| **Critical** | 8 | 6-13: MetricTraceability, SummaryAbstraction, VerbDiversity, SummaryMetrics, PhraseRepetition, MetricPreservation, KeywordEvidence, NarrativeFit |
| **High** | 7 | 14-20: LimitationEnforcement, SkillClassification, BudgetEnforcement, KeywordDensity, MetricPlausibility, ScopeAttribution, EmDash |
| **Shared Modules** | 3 | 21-23: VerbDistribution, MetricsDensity, KeywordEvidenceTier |
| **Moderate** | 2 | 24-25: RecencyWeighting, AcronymExpansion |

```javascript
/**
 * Master validation pipeline - runs all 25 validators in sequence
 * Returns a summary report similar to Resume Analyzer output
 * @param {Object} parsedContent - LLM response after JSON parsing
 * @param {Array} jobHistory - Original job history
 * @param {Object} jobDescription - JD with title/company
 * @param {Array} useKeywords - Keywords marked for use
 * @param {Array} honestLimitations - User's honest limitations
 * @param {Object} candidateProfile - Profile with experience level
 * @returns {Object} { valid, errors, warnings, summary, reports, correctedContent }
 */
function validateAndCorrectLLMResponse(
  parsedContent,
  jobHistory,
  jobDescription,
  useKeywords = [],
  honestLimitations = [],
  candidateProfile = {}
) {
  const allErrors = [];
  const allWarnings = [];
  let correctedBullets = parsedContent.customizedBullets;

  // ═══════════════════════════════════════════════════════════════
  // CORE VALIDATORS (Fix 7 Original Bugs)
  // ═══════════════════════════════════════════════════════════════

  // Validator 1: Chronology Depth (Bug #5: Missing positions)
  const chronologyResult = validateChronologyDepth(correctedBullets, jobHistory);
  if (!chronologyResult.valid) {
    allErrors.push(...chronologyResult.errors);
    correctedBullets = chronologyResult.correctedBullets;
  }

  // Validator 2: Position Metadata (Bugs #1, #3, #4: Wrong titles/companies)
  const metadataResult = validatePositionMetadata(correctedBullets, jobHistory, jobDescription);
  if (!metadataResult.valid) {
    allErrors.push(...metadataResult.errors);
    correctedBullets = metadataResult.correctedBullets;
  }

  // Validator 3: Chronological Order (Bug #2: Wrong order)
  const orderResult = validateChronologicalOrder(correctedBullets);
  if (!orderResult.valid) {
    allErrors.push(...orderResult.errors);
    correctedBullets = orderResult.correctedBullets;
  }

  // Validator 4: Bullet Counts (Bug #6: Wrong bullet count)
  const bulletCountResult = validateBulletCounts(correctedBullets, chronologyResult.eligiblePositions);
  if (!bulletCountResult.valid) {
    allErrors.push(...bulletCountResult.errors);
  }

  // Validator 5: Bullet Format (Bug #7: Guardrail enforcement)
  const formatResult = validateBulletFormat(correctedBullets);
  if (!formatResult.valid) {
    allErrors.push(...formatResult.errors);
  }

  // ═══════════════════════════════════════════════════════════════
  // CRITICAL PRIORITY VALIDATORS (Guardrails #1, #3, #9, #13, #15, #29, #32, #33)
  // ═══════════════════════════════════════════════════════════════

  // Validator 6: Metric Traceability (Guardrail #1)
  const traceabilityResult = validateMetricTraceability(correctedBullets, jobHistory);
  if (!traceabilityResult.valid) {
    allErrors.push(...traceabilityResult.errors);
  }

  // Validator 7: Summary Abstraction (Guardrail #3)
  const abstractionResult = validateSummaryAbstraction(parsedContent.professionalSummary, correctedBullets);
  if (!abstractionResult.valid) {
    allErrors.push(...abstractionResult.errors);
  }

  // Validator 8: Verb Diversity (Guardrail #9)
  const verbResult = validateVerbDiversity(correctedBullets);
  if (!verbResult.valid) {
    allErrors.push(...verbResult.errors);
  }

  // Validator 9: Summary Metrics (Guardrail #13)
  const summaryMetricsResult = validateSummaryMetrics(parsedContent.professionalSummary, correctedBullets);
  if (!summaryMetricsResult.valid) {
    allErrors.push(...summaryMetricsResult.errors);
  }

  // Validator 10: Phrase Repetition (Guardrail #15)
  const phraseResult = validatePhraseRepetition(parsedContent.professionalSummary, correctedBullets);
  if (!phraseResult.valid) {
    allErrors.push(...phraseResult.errors);
  }

  // Validator 11: Metric Preservation (Guardrail #29)
  const preservationResult = validateMetricPreservation(correctedBullets, jobHistory);
  if (!preservationResult.valid) {
    allErrors.push(...preservationResult.errors);
  }

  // Validator 12: Keyword Evidence (Guardrail #32)
  const evidenceResult = validateKeywordEvidence(correctedBullets, jobHistory, useKeywords);
  if (evidenceResult.warnings) {
    allWarnings.push(...evidenceResult.warnings);
  }

  // Validator 13: Narrative Fit (Guardrail #33)
  const narrativeResult = validateNarrativeFit(correctedBullets, parsedContent.narrativeVerification);
  if (narrativeResult.warnings) {
    allWarnings.push(...narrativeResult.warnings);
  }

  // ═══════════════════════════════════════════════════════════════
  // HIGH PRIORITY VALIDATORS (Guardrails #5, #7, #8, #10, #11, #17, #22)
  // ═══════════════════════════════════════════════════════════════

  // Validator 14: Limitation Enforcement (Guardrail #5)
  const limitationResult = validateLimitationEnforcement(correctedBullets, honestLimitations);
  if (!limitationResult.valid) {
    allErrors.push(...limitationResult.errors);
  }

  // Validator 15: Skill Classification (Guardrail #7)
  const skillResult = validateSkillClassification(parsedContent);
  if (!skillResult.valid) {
    allErrors.push(...skillResult.errors);
  }

  // Validator 16: Budget Enforcement (Guardrail #8)
  const budgetResult = validateBudgetEnforcement(correctedBullets, parsedContent.professionalSummary);
  if (!budgetResult.valid) {
    allErrors.push(...budgetResult.errors);
  }

  // Validator 17: Keyword Density (Guardrail #10)
  const densityResult = validateKeywordDensity(correctedBullets, useKeywords);
  if (!densityResult.valid) {
    allErrors.push(...densityResult.errors);
  }

  // Validator 18: Metric Plausibility (Guardrail #11)
  const plausibilityResult = validateMetricPlausibility(correctedBullets);
  if (!plausibilityResult.valid) {
    allErrors.push(...plausibilityResult.errors);
  }
  if (plausibilityResult.warnings) {
    allWarnings.push(...plausibilityResult.warnings);
  }

  // Validator 19: Scope Attribution (Guardrail #17)
  const scopeResult = validateScopeAttribution(correctedBullets, candidateProfile);
  if (scopeResult.warnings) {
    allWarnings.push(...scopeResult.warnings);
  }

  // Validator 20: Em-Dash (Guardrail #22)
  const emDashResult = validateEmDash(correctedBullets, parsedContent.professionalSummary);
  if (!emDashResult.valid) {
    allErrors.push(...emDashResult.errors);
  }

  // ═══════════════════════════════════════════════════════════════
  // SHARED MODULE VALIDATORS (optimization-tools/shared/)
  // ═══════════════════════════════════════════════════════════════

  // Validator 21: Verb Distribution (shared_verb_taxonomy.md)
  const verbDistResult = validateVerbDistribution(correctedBullets);
  if (verbDistResult.warnings) {
    allWarnings.push(...verbDistResult.warnings);
  }

  // Validator 22: Metrics Density (shared_core_principles.md - P1)
  const metricsDensityResult = validateMetricsDensity(correctedBullets);
  if (metricsDensityResult.warnings) {
    allWarnings.push(...metricsDensityResult.warnings);
  }

  // Validator 23: Keyword Evidence Tier (shared_keyword_validation.md)
  const evidenceTierResult = validateKeywordEvidenceTier(correctedBullets, useKeywords);
  if (evidenceTierResult.warnings) {
    allWarnings.push(...evidenceTierResult.warnings);
  }

  // ═══════════════════════════════════════════════════════════════
  // MODERATE PRIORITY VALIDATORS (Guardrails #12, #20)
  // ═══════════════════════════════════════════════════════════════

  // Validator 24: Recency Weighting (Guardrail #12)
  const recencyResult = validateRecencyWeighting(correctedBullets);
  if (recencyResult.warnings) {
    allWarnings.push(...recencyResult.warnings);
  }

  // Validator 25: Acronym Expansion (Guardrail #20)
  const acronymResult = validateAcronymExpansion(correctedBullets, parsedContent.professionalSummary);
  if (acronymResult.warnings) {
    allWarnings.push(...acronymResult.warnings);
  }

  // ═══════════════════════════════════════════════════════════════
  // VALIDATION SUMMARY
  // ═══════════════════════════════════════════════════════════════

  // Categorize errors by severity
  const criticalErrors = allErrors.filter(e => e.severity === 'CRITICAL');
  const highErrors = allErrors.filter(e => e.severity === 'HIGH');
  const mediumErrors = allErrors.filter(e => e.severity === 'MEDIUM');

  // Log validation results
  if (allErrors.length > 0 || allWarnings.length > 0) {
    console.warn('LLM Response Validation Summary:', {
      totalErrors: allErrors.length,
      criticalErrors: criticalErrors.length,
      highErrors: highErrors.length,
      mediumErrors: mediumErrors.length,
      totalWarnings: allWarnings.length
    });

    console.warn('Errors:', allErrors);
    console.warn('Warnings:', allWarnings);

    // Show user-friendly warning for critical errors
    if (criticalErrors.length > 0) {
      alert(`⚠️ ${criticalErrors.length} critical validation error(s) detected. Some issues were auto-corrected. Check console for details.`);
    }
  }

  // ═══════════════════════════════════════════════════════════════
  // VALIDATION SUMMARY REPORT (Like Resume Analyzer Output)
  // ═══════════════════════════════════════════════════════════════

  return {
    valid: allErrors.length === 0,
    errors: allErrors,
    warnings: allWarnings,
    summary: {
      totalValidators: 25,
      errorsFound: allErrors.length,
      warningsFound: allWarnings.length,
      criticalCount: criticalErrors.length,
      highCount: highErrors.length,
      mediumCount: mediumErrors.length,
      autoCorrected: ['chronologicalOrder', 'positionMetadata', 'chronologyDepth']
    },
    // Reports from shared module validators (like Resume Analyzer)
    reports: {
      verbDistribution: verbDistResult.distribution,      // Verb category balance
      metricsDensity: metricsDensityResult.metricsReport, // 70-80% target
      keywordEvidence: evidenceTierResult.evidenceReport  // Tier 1/2/3 breakdown
    },
    correctedContent: {
      ...parsedContent,
      customizedBullets: correctedBullets
    }
  };
}
```

---

## Regeneration Loop Architecture

### Why a Loop?

Validation alone flags issues but doesn't fix them. A **regeneration loop**:
1. **Validates** generated bullets against 25 guardrails
2. **Auto-corrects** what it can (metadata, order)
3. **Regenerates** bullets that fail guardrails (requires LLM)
4. **Notifies user** of progress: "Found issues, regenerating..."
5. **Loops 2-3 times** max before displaying final result

### What Can Be Auto-Corrected vs. Needs Regeneration?

| Issue Type | Auto-Correct? | Needs Regeneration? |
|------------|---------------|---------------------|
| Wrong position title/company/dates | ✅ Yes | No |
| Wrong chronological order | ✅ Yes | No |
| Missing positions | ✅ Yes (skeleton) | ✅ Yes (bullets) |
| Wrong bullet count (1 instead of 3-5) | No | ✅ Yes |
| Verb category repeated in position | No | ✅ Yes |
| Summary echoes bullet (>50%) | No | ✅ Yes |
| Phrase repeated 3+ times | No | ✅ Yes |
| Metrics lost during optimization | No | ✅ Yes |
| Low metrics density (<70%) | No | ✅ Yes |
| Character limit exceeded | No | ✅ Yes |

### Loop Flow Diagram

```
┌─────────────────────────────────────────────────────────────┐
│                    GENERATION LOOP                          │
│                    Max Attempts: 3                          │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│ STEP 1: Generate bullets (LLM call)                         │
│         UI: "Generating optimized bullets..."               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│ STEP 2: Parse JSON + Run 25 validators                      │
│         UI: "Validating against guardrails..."              │
│         - Auto-correct: metadata, order                     │
│         - Flag: errors requiring regeneration               │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
                ┌───────────────────────┐
                │ Regeneration errors?  │
                └───────────┬───────────┘
                            │
         ┌──────────────────┴──────────────────┐
         │                                     │
         ▼                                     ▼
    ┌─────────┐                           ┌─────────┐
    │   YES   │                           │   NO    │
    └────┬────┘                           └────┬────┘
         │                                     │
         ▼                                     │
┌─────────────────────┐                        │
│ attempt < 3?        │                        │
└──────────┬──────────┘                        │
           │                                   │
   ┌───────┴───────┐                           │
   │               │                           │
   ▼               ▼                           │
┌─────┐       ┌─────┐                          │
│ YES │       │ NO  │                          │
└──┬──┘       └──┬──┘                          │
   │             │                             │
   ▼             │                             │
┌──────────────────────────┐                   │
│ UI: "Found 3 issues.     │                   │
│ Regenerating (2/3)..."   │                   │
└──────────────────────────┘                   │
   │                                           │
   ▼                                           │
┌──────────────────────────┐                   │
│ Add error context to     │                   │
│ prompt for next attempt  │                   │
└──────────────────────────┘                   │
   │                                           │
   └──────────────► LOOP BACK TO STEP 1        │
                                               │
           ┌───────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────┐
│ STEP 3: Display final results                               │
│         - Show corrected content                            │
│         - Show validation summary + reports                 │
│         - Show remaining warnings (if any)                  │
└─────────────────────────────────────────────────────────────┘
```

### User Feedback Messages

| State | UI Message |
|-------|------------|
| Initial generation | "Generating optimized bullets..." |
| Validation | "Validating against 25 guardrails..." |
| Errors found (attempt 1) | "Found 3 issues. Regenerating (attempt 2/3)..." |
| Errors found (attempt 2) | "Still 2 issues. Regenerating (attempt 3/3)..." |
| Max attempts reached | "Validation complete. 1 warning remains - please review." |
| Success | "✅ All guardrails passed!" |

### Error Classification: `requiresRegeneration`

Add flag to each error type:

```javascript
// In each validator, add requiresRegeneration flag
errors.push({
  type: 'WRONG_BULLET_COUNT',
  message: `Position has 1 bullet, expected 3-5`,
  requiresRegeneration: true,  // ← LLM must fix this
  severity: 'CRITICAL'
});

// vs auto-correctable
errors.push({
  type: 'WRONG_ORDER',
  message: `Positions not in chronological order`,
  requiresRegeneration: false,  // ← JS can fix this
  severity: 'MEDIUM'
});
```

| Error Type | requiresRegeneration | Why |
|------------|----------------------|-----|
| WRONG_BULLET_COUNT | ✅ true | Need LLM to generate more bullets |
| VERB_CATEGORY_REPEATED | ✅ true | Need LLM to use different verbs |
| SUMMARY_ECHOES_BULLET | ✅ true | Need LLM to rewrite summary |
| PHRASE_REPEATED | ✅ true | Need LLM to vary language |
| METRICS_LOST | ✅ true | Need LLM to preserve metrics |
| METRICS_DENSITY_LOW | ✅ true | Need LLM to add metrics |
| CHAR_LIMIT_EXCEEDED | ✅ true | Need LLM to shorten |
| WRONG_POSITION_TITLE | ❌ false | Auto-corrected by JS |
| WRONG_COMPANY | ❌ false | Auto-corrected by JS |
| WRONG_ORDER | ❌ false | Auto-corrected by JS |

### Regeneration Prompt Context

When looping, append error context:

```javascript
function buildRegenerationContext(errors) {
  const regenErrors = errors.filter(e => e.requiresRegeneration);

  return `

VALIDATION ERRORS FROM PREVIOUS ATTEMPT (MUST FIX):

${regenErrors.map((e, i) => `${i + 1}. [${e.type}] ${e.message}`).join('\n')}

INSTRUCTIONS FOR THIS REGENERATION:
- Fix ALL errors listed above
- Preserve everything else that was correct
- Do not introduce new errors

REGENERATE WITH THESE CORRECTIONS:
`;
}
```

### Implementation: `generateWithValidationLoop()`

```javascript
/**
 * Generates bullets with validation loop (max 3 attempts)
 * Auto-corrects what it can, regenerates for guardrail failures
 */
async function generateWithValidationLoop(
  selectedModel,
  baseGenerationPrompt,
  jobHistorySource,
  jobDescription,
  keywordsToUse,
  honestLimitations,
  ollmaOptions = { temperature: 0.3, max_tokens: 4000 }
) {
  const MAX_ATTEMPTS = 3;
  let attempt = 0;
  let validationResult = null;
  let parsedContent = null;

  // Extract job history from jobHistorySource for validation
  // (Will be populated after first LLM response)
  let jobHistory = [];

  while (attempt < MAX_ATTEMPTS) {
    attempt++;

    try {
      // Build prompt with error context for regenerations
      let prompt = baseGenerationPrompt;
      if (attempt > 1 && validationResult?.errors?.length > 0) {
        const regenErrors = validationResult.errors.filter(e => e.requiresRegeneration);
        const errorMessages = regenErrors
          .map(e => `- ${e.message}`)
          .join('\n');

        prompt = `${baseGenerationPrompt}

CRITICAL: Previous attempt had these validation failures - MUST FIX ALL:
${errorMessages}

Please regenerate the entire response addressing every issue above.`;
      }

      // Generate via LLM
      const response = await callLLM(selectedModel, prompt, ollmaOptions);
      parsedContent = parseJSONResponse(response);

      // Extract job history from LLM output for validators
      jobHistory = extractJobHistoryFromLLMOutput(parsedContent.customizedBullets);

      // Validate (25 validators)
      validationResult = validateAndCorrectLLMResponse(
        parsedContent,
        jobHistory,
        jobDescription,
        keywordsToUse,
        honestLimitations,
        { experienceLevel: determineExperienceLevel(jobHistory) }
      );

      // Check if we need to regenerate
      const regenErrors = validationResult.errors.filter(e => e.requiresRegeneration);

      if (regenErrors.length === 0) {
        // Success! All regeneration-requiring errors fixed
        break;
      }

    } catch (err) {
      console.error(`Generation attempt ${attempt} failed:`, err);
      if (attempt >= MAX_ATTEMPTS) {
        throw new Error(`Failed to generate valid content after ${MAX_ATTEMPTS} attempts: ${err.message}`);
      }
      // Continue to next attempt
      continue;
    }
  }

  return {
    content: validationResult.correctedContent,
    validationResult,
    attempts: attempt,
    success: validationResult.errors.filter(e => e.requiresRegeneration).length === 0
  };
}
```

---

### Integration Point in `generateCustomizedContent()` Function

**Location**: Lines 787-824 in `Should-I-Apply-local.jsx`

**Current Code**:
```javascript
const result = await OllamaService.generate(selectedModel, generationPrompt, {
  temperature: 0.3,
  max_tokens: 4000
});

if (!result.success) {
  setSummaryError(`Failed to generate content: ${result.error}`);
  return;
}

// Parse the response
let responseText = result.text.trim();
responseText = responseText.replace(/```json\s*/g, '').replace(/```\s*/g, '');

const jsonStart = responseText.indexOf('{');
const jsonEnd = responseText.lastIndexOf('}');

if (jsonStart === -1 || jsonEnd === -1) {
  throw new Error('No JSON found in response');
}

const jsonString = responseText.substring(jsonStart, jsonEnd + 1);
const parsedContent = JSON.parse(jsonString);

setGeneratedContent(parsedContent); // ❌ NO VALIDATION
```

**Updated Code** (with validation loop):
```javascript
try {
  // Call regeneration loop with all parameters needed for validation
  const loopResult = await generateWithValidationLoop(
    selectedModel,
    generationPrompt,           // The full generation prompt (built earlier in function)
    jobHistorySource,           // Raw job history for context
    { title: jobDescription, company: jobDescription }, // Wait - get these from analysisResult!
    keywordsToUse,              // Keywords to incorporate
    honestLimitations || [],    // Honest limitations (from UI)
    {
      temperature: 0.3,
      max_tokens: 4000
    }
  );

  // ✅ Use the validated and auto-corrected content
  setGeneratedContent(loopResult.content);

  // Log validation summary
  console.log('Validation Report:', {
    attempts: loopResult.attempts,
    success: loopResult.success,
    summary: loopResult.validationResult.summary,
    totalValidators: 25,
    errorCount: loopResult.validationResult.errors.length,
    warningCount: loopResult.validationResult.warnings.length
  });

  // Auto-expand customized section
  const newExpanded = new Set(expandedSections);
  newExpanded.add('customized');
  setExpandedSections(newExpanded);

} catch (err) {
  console.error('Generation error:', err);
  setSummaryError(`Failed to generate content: ${err.message}`);
} finally {
  setGeneratingSummary(false);
}
```

**NOTE**: The second parameter in `generateWithValidationLoop` call should use `analysisResult.positionSummary` to get the JD title/company from the analysis, not from `jobDescription` directly.

---

### Benefits of Hard-Coded Validation (22 Validators)

#### Core Validators (Fix 7 Original Bugs)

| Bug | Prompt-Based (❌ Failed) | Hard-Coded JS (✅ Fixed) |
|-----|-------------------------|-------------------------|
| #1: Wrong job titles | LLM ignores instruction | `validatePositionMetadata()` auto-corrects |
| #2: Not chronological | LLM doesn't sort | `validateChronologicalOrder()` auto-sorts |
| #3: JD company contamination | LLM misinterprets context | `validatePositionMetadata()` detects and fixes |
| #4: Missing companies | LLM omits field | `validatePositionMetadata()` fills from history |
| #5: Wrong position count | LLM filters incorrectly | `validateChronologyDepth()` enforces rules |
| #6: Wrong bullet count | LLM ignores 3-5/2-3 rule | `validateBulletCounts()` flags violations |
| #7: No guardrail enforcement | LLM skips checks | All 22 validators run automatically |

#### Critical Priority Validators (Prevent Additional Bugs)

| Guardrail | What It Prevents | Validator |
|-----------|------------------|-----------|
| #1: Metric Traceability | Using metrics from wrong position | `validateMetricTraceability()` |
| #3: Summary Abstraction | Summary echoing bullets verbatim | `validateSummaryAbstraction()` |
| #9: Verb Diversity | Same verb category repeated | `validateVerbDiversity()` |
| #13: Summary Metrics | Unsupported claims in summary | `validateSummaryMetrics()` |
| #15: Phrase Repetition | Repetitive phrases (3+ times) | `validatePhraseRepetition()` |
| #29: Metric Preservation | Lost metrics during optimization | `validateMetricPreservation()` |
| #32: Keyword Evidence | Using keywords without evidence | `validateKeywordEvidence()` |
| #33: Narrative Fit | Missing top JD requirements | `validateNarrativeFit()` |

#### High Priority Validators

| Guardrail | What It Prevents | Validator |
|-----------|------------------|-----------|
| #5: Limitation Enforcement | Claiming skills in limitations | `validateLimitationEnforcement()` |
| #7: Skill Classification | Skill in both hard/soft lists | `validateSkillClassification()` |
| #8: Budget Enforcement | Bullets too short/too long | `validateBudgetEnforcement()` |
| #10: Keyword Density | Keyword stuffing | `validateKeywordDensity()` |
| #11: Metric Plausibility | Implausible percentages (>100%) | `validateMetricPlausibility()` |
| #17: Scope Attribution | Junior claiming senior scope | `validateScopeAttribution()` |
| #22: Em-Dash | ATS-breaking characters | `validateEmDash()` |

#### Moderate Priority Validators

| Guardrail | What It Prevents | Validator |
|-----------|------------------|-----------|
| #12: Recency Weighting | Most recent position underemphasized | `validateRecencyWeighting()` |
| #20: Acronym Expansion | Unexpanded acronyms | `validateAcronymExpansion()` |

---

## Implementation Steps

### Step 0: Git Branch Setup (Following start-issue-tracking workflow)

```bash
# Create feature branch for issue
git checkout -b fix/issue-79-gui-customized-bullets-wrong-context

# Verify branch created
git branch
```

### Step 1: Create Issue Tracking Documentation

Create `/docs/issues/issue-79/` directory with standardized files:

#### File 1: `issue-79-document-v1.0.0.md`

```markdown
# Issue #79: GUI Customized Bullets Using Wrong Context

**Status:** 🔴 IN PROGRESS
**Type:** 🐛 Bug
**Priority:** High
**Created:** 2026-01-22
**GitHub Issue:** #79

---

## Context

- **Tool/Component:** Should-I-Apply WebGUI
- **Version:** v1.2.0
- **Target Version:** v1.2.1

---

## Problem Description

After job fit analysis, clicking "Optimize Your Application" generates bullets with:
- Job title from JD (not job history)
- Company from JD (not job history)
- Only 1 position (not all positions)

## Root Cause

Ambiguous prompt in `generateCustomizedContent()` (line 667-734):
- Says "optimize for this specific job description"
- No explicit instruction to extract ALL positions from job history
- AI interprets "position from their experience" as the JD position

## Solution

Rewrite generation prompt to explicitly:
1. Instruct: "PARSE ALL POSITIONS from job history"
2. Clarify: "DO NOT use the job description's position/company"
3. Add example showing multi-position output structure

---

## Affected Files

**Code Changes:**
- `claude-artifacts/Should-I-Apply-webgui.jsx` (lines 655-734)
- `src/components/Should-I-Apply-local.jsx` (same lines)

**Module References:**
- `optimization-tools/bullet-optimizer/bo_bullet-generation-logic.md` (chronology depth)
- `optimization-tools/bullet-optimizer/bo_evidence-matching.md` (position extraction)
- `optimization-tools/bullet-optimizer/bo_keyword_handling.md` (evidence validation)

---

## Related

- GitHub: https://github.com/technomensch/optimize-my-resume/issues/79
- Screenshot: [User-provided screenshot in GitHub issue]
```

#### File 2: `solution-approach.md`

```markdown
# Solution Approach: Issue #79

## Diagnosis

The prompt in `generateCustomizedContent()` is ambiguous:
- Tells AI to "optimize for this specific job description"
- Schema says "position title from their experience" (unclear if this means job history or JD)
- No explicit instruction to parse ALL positions from job history

Result: AI thinks it should generate bullets FOR the JD position, not FROM the job history positions.

## Solution Design

### Prompt Rewrite Strategy

Replace generation prompt (lines 667-734) with explicit multi-position instructions:

1. **Opening Statement**: "Generate customized resume bullets for ALL positions in the candidate's job history"
2. **Critical Instruction 1**: "PARSE ALL POSITIONS from the job history above"
3. **Critical Instruction 2**: "DO NOT use the job description's position/company"
4. **Position Loop Instruction**: "FOR EACH POSITION in the job history..."
5. **Output Schema Clarification**: Add comments "ONE OBJECT PER HISTORICAL POSITION"
6. **Concrete Example**: Show 3-position input → 3-position output

### Additional Changes

- Add clarifying comment before `experienceContent` preparation (line 655)
- Maintain keyword evidence validation (existing functionality)
- Enforce chronology depth logic from bo_bullet-generation-logic.md (make explicit as filter)
- Add missing guardrails:
  - Guardrail #3: Professional Summary Abstraction
  - Guardrail #13: Summary-to-Bullets Metric Reconciliation
  - Guardrail #15: Phrase Repetition Enforcement
  - portfolio_employment_labeling rule (CRITICAL priority)
  - Verb category distribution targets (13-27% per category)

### Shadow Sync Considerations

- JSX artifacts are self-contained (don't reference external modules directly)
- This is a prompt fix within JSX, no module references need updating
- If later extracted to module: Would go to `optimization-tools/bullet-optimizer/bo_multi-position-generation.md`

## Implementation Plan

1. Update Should-I-Apply-webgui.jsx prompt
2. Add clarifying comment
3. Update Should-I-Apply-local.jsx (same changes)
4. Test with 3-position job history
```

#### File 3: `implementation-log.md`

```markdown
# Implementation Log: Issue #79

## 2026-01-22: Issue Analysis Complete

- Identified root cause: ambiguous prompt interpretation
- Reviewed module references (bo_bullet-generation-logic, bo_evidence-matching, bo_keyword_handling)
- Created issue tracking documentation

## Implementation Plan

1. Rewrite generation prompt (lines 667-734)
2. Add clarifying comments (line 655)
3. Apply to both webgui.jsx and local.jsx
4. Test with multi-position job history

## Changes Made

[To be filled during implementation]

## Testing Results

[To be filled after implementation]
```

#### File 4: `test-cases.md`

```markdown
# Test Cases: Issue #79

## Test Case 1: Multiple Positions

**Input**:
- Job history: 3 positions
  - Position 0: Software Engineer at Acme Corp (2020-2022)
  - Position 1: Senior Engineer at TechCo (2022-2024)
  - Position 2: Lead Engineer at StartupX (2024-Present)
- JD: Staff Engineer at BigCorp

**Expected Output**:
```json
{
  "customizedBullets": [
    { "position": "Software Engineer", "company": "Acme Corp", "dates": "2020-2022", ... },
    { "position": "Senior Engineer", "company": "TechCo", "dates": "2022-2024", ... },
    { "position": "Lead Engineer", "company": "StartupX", "dates": "2024-Present", ... }
  ]
}
```

**Bug Output (Before Fix)**:
```json
{
  "customizedBullets": [
    { "position": "Staff Engineer", "company": "BigCorp", ... }  // ❌ WRONG
  ]
}
```

## Test Case 2: Chronology Depth Logic

**Input**:
- Position 0: 2022-Present (recent, should get 3-5 bullets)
- Position 1: 2019-2022 (within 6 years, should get 3 bullets)
- Position 2: 2012-2017 (old but 5yr tenure, should get 2-3 bullets)

**Expected**: All 3 positions included with appropriate bullet counts

## Test Case 3: Keyword Evidence Check

**Input**:
- USE keywords: ["Python", "AWS", "Kubernetes"]
- Job history: Mentions Python and AWS, but NOT Kubernetes

**Expected**:
- Python and AWS incorporated naturally
- Kubernetes marked in `skippedNotEvidenced` report
- Coverage report: 2 successfully incorporated, 1 skipped
```

---

### Step 2: Shadow-Sync Verification

Run `enforce-shadow-sync` checks:

#### Check 1: Files Changed
```bash
git status
# Should show: claude-artifacts/Should-I-Apply-webgui.jsx
#              src/components/Should-I-Apply-local.jsx
```

#### Check 2: Module References
- JSX artifacts are self-contained (no module imports)
- Prompt references modules conceptually (bo_*, ng_*, jfa_*)
- No changes needed to optimization-tools/ modules
- No changes needed to PROJECT-INSTRUCTIONS.md or Project-GUI-Instructions.md

#### Check 3: Terminology Consistency
- Search for any variations of "customizedBullets" structure
- Verify both JSX files use identical prompt wording
- Check if Should-I-Apply uses same schema as ng_summary-generation.md

#### Check 4: Interface Consistency
- Verify display logic (lines ~2100+) handles multiple position objects
- Check that UI iterates through ALL positions in customizedBullets array

**Shadow Sync Result**: ✅ NO SYNC REQUIRED
- Changes are isolated to JSX artifacts (not modular components)
- No module extraction needed
- No terminology changes

---

### Step 3: Apply Code Changes

#### File 1: `claude-artifacts/Should-I-Apply-webgui.jsx`

**Change 1** (line 655): Add clarifying comment

**Change 2** (lines 667-734): Replace generation prompt with new version (see plan above)

#### File 2: `src/components/Should-I-Apply-local.jsx`

**Apply identical changes** to maintain consistency

---

### Step 4: Testing

Run test cases from `test-cases.md`

---

### Step 5: Git Integration & GitHub Issue Creation

Following start-issue-tracking workflow:

#### 5.1: Initial Commit (Issue Documentation)

```bash
# Stage issue documentation
git add docs/issues/issue-79/

# Commit with conventional format
git commit -m "docs(issue-79): create issue tracking for GUI customized bullets wrong context

Issue #79: GUI Customized Bullets Using Wrong Context
Type: Bug
Priority: High

Problem:
After job fit analysis, clicking 'Optimize Your Application' generates bullets with JD title/company instead of job history title/company, and only 1 position instead of all positions.

Root Cause:
Ambiguous prompt in generateCustomizedContent() makes AI think it should generate bullets FOR the JD position, not FROM the job history positions.

Files Created:
- docs/issues/issue-79/issue-79-document-v1.0.0.md
- docs/issues/issue-79/solution-approach.md
- docs/issues/issue-79/implementation-log.md
- docs/issues/issue-79/test-cases.md

Next Steps:
- Update generation prompt with explicit multi-position instructions
- Add missing guardrails (#3, #13, #15, portfolio_employment_labeling)
- Make chronology depth logic prominent as filter
- Apply to both webgui.jsx and local.jsx

Status: Active

Co-Authored-By: Claude Haiku 4.5 <noreply@anthropic.com>
"
```

#### 5.2: Update Existing GitHub Issue #79

Issue #79 already exists. Update it with detailed solution approach:

```bash
# Update GitHub issue #79 with solution-approach.md content
gh issue edit 79 --body-file docs/issues/issue-79/solution-approach.md

# Add labels if not already present
gh issue edit 79 --add-label bug,high-priority
```

#### 5.4: Update Should-I-Apply Issue Tracker

Update `docs/issues/issue-tracker-should-i-apply.md` with new issue:

Add to "Open Issues" section:

```markdown
### Issue #79: GUI Customized Bullets Using Wrong Context

**Status:** 🔴 ACTIVE
**Type:** 🐛 Bug
**Priority:** High
**Created:** 2026-01-22
**GitHub Issue:** #79

**Problem Description:**
After job fit analysis, clicking "Optimize Your Application" generates bullets with:
- Job title from JD instead of job history
- Company from JD instead of job history
- Only 1 position instead of all positions

**Root Cause:**
Ambiguous prompt in `generateCustomizedContent()` (line 667-734). AI interprets instruction as generating bullets FOR the JD position, not FROM the job history positions.

**Current Behavior:**
```json
{
  "customizedBullets": [
    { "position": "Staff Engineer", "company": "BigCorp" }  // ❌ From JD
  ]
}
```

**Expected Behavior:**
```json
{
  "customizedBullets": [
    { "position": "Engineer", "company": "Acme" },          // ✅ From job history
    { "position": "Senior Engineer", "company": "TechCo" }, // ✅ From job history
    { "position": "Lead Engineer", "company": "StartupX" }  // ✅ From job history
  ]
}
```

**Affected Files:**
| File | Changes |
|------|---------|
| `Should-I-Apply-webgui.jsx` | Lines 655-734: Rewrite generation prompt with explicit multi-position instructions |
| `Should-I-Apply-local.jsx` | Same changes as webgui.jsx |

**Solution Implemented:**
- Rewrite opening statement to clarify "positions that meet chronology depth criteria"
- Make chronology depth logic step 2 (FILTER before generation)
- Add explicit instructions: "PARSE ALL POSITIONS", "DO NOT use JD's position/company"
- Add missing guardrails: #3, #13, #15, portfolio_employment_labeling, verb distribution
- Update character limit to ≤210 chars (ATS compliance)

**Module References:**
- `optimization-tools/bullet-optimizer/bo_bullet-generation-logic.md` (chronology_depth_logic)
- `optimization-tools/narrative-generator/ng_summary-generation.md` (Guardrails #3, #13, #15, #33)
- `optimization-tools/bullet-optimizer/bo_keyword_handling.md` (Guardrail #32)
- `core/format-rules.md` (character limits)
- `core/verb-categories.md` (distribution targets)

**Workaround:**
None - users must manually correct position titles and companies in generated output.

**Documentation:** [docs/issues/issue-79/](docs/issues/issue-79/)

---
```

#### 5.5: Push Branch to Remote

```bash
# Push branch
git push -u origin fix/issue-79-gui-customized-bullets-wrong-context
```

---

### Step 6: Apply Code Changes

[Previous Step 3 content moves here]

---

### Step 7: Testing

[Previous Step 4 content moves here]

---

### Step 8: Final Documentation Updates

1. Update implementation-log.md with changes made
2. Commit code changes with reference to issue
3. When verified, move docs/issues/issue-79/ to docs/issues/Closed/issue-79/

---

## Critical Files to Create/Modify

**Issue Tracking (Step 1):**
1. `docs/issues/issue-79/issue-79-document-v1.0.0.md`
2. `docs/issues/issue-79/solution-approach.md`
3. `docs/issues/issue-79/implementation-log.md`
4. `docs/issues/issue-79/test-cases.md`

**Code Changes (Step 3):**
1. `claude-artifacts/Should-I-Apply-webgui.jsx` (lines 655-734)
2. `src/components/Should-I-Apply-local.jsx` (same lines)

---

## Success Criteria

✅ Generated bullets include ALL positions from job history (not just one)
✅ Each position uses EXACT title/company/dates from job history (not from JD)
✅ Chronology depth logic applied (recent = more bullets)
✅ Keyword evidence check prevents fabrication
✅ Both webgui.jsx and local.jsx fixed consistently

---

## What Changed Summary

**Before**:
- AI interprets "position from their experience" as the JD position
- Generates 1 position with JD's title/company

**After**:
- Explicit: "PARSE ALL POSITIONS from job history"
- Explicit: "DO NOT use the job description's position/company"
- Example showing multi-position output structure
- AI generates N positions from job history, each with correct metadata

**Lines Changed**: ~70 lines (full prompt replacement + comment)
**Complexity**: Low (prompt engineering only, no logic changes)
