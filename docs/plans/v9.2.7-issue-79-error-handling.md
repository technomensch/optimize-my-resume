# Plan: v9.2.7 Improved Error Handling + ENH-001 Model Regeneration

**Issue:** #79 - Better error diagnostics + model switching
**Enhancement:** ENH-001 - Model Selection for Bullet Regeneration
**Status:** Ready for Planning
**Created:** 2026-01-25

---

## Problem Summary

### Issue 1: Silent Failures in Analysis
**Error:** `No JSON found in response` at `runAnalysis():468`
- LLM call failing or returning non-JSON
- User sees generic error message
- No indication of root cause (connection, model unavailable, etc.)

### Issue 2: No Way to Recover from Generation Failure
- If bullets fail, user must restart entire flow
- No way to switch models without re-uploading

---

## Solution Overview

### Part A: Error Handling Improvements (v9.2.7 core)

**1. Better Analysis Error Messages** (should-I-apply-local.jsx:460-490)
- Log actual LLM response for debugging
- Check for connection errors specifically
- Provide actionable error messages:
  - "Ollama not running" vs "Invalid JSON from model"
  - "Model not found" vs "Timeout"

**2. Better Bullet Generation Error Messages** (generation-helpers.js)
- Log why regeneration failed
- Show which validation errors persisted
- Display attempt count/model info

**3. Error Recovery UI**
- Show error details (not just empty state)
- Suggest troubleshooting steps
- Offer model switching as recovery option

### Part B: ENH-001 Implementation

**Model Selection UI in "Optimize Your Application" Section:**
- Dropdown showing available models
- "Regenerate" button to retry with new model
- Preserves analysis data (fit score, keywords)
- Only regenerates bullets/summary

---

## Implementation Tasks

### Phase 1: Error Handling (v9.2.7.a)

#### Task 1a: Enhanced Analysis Error Logging
**File:** `src/components/Should-I-Apply-local.jsx` (lines 460-490)

Add:
```javascript
// Log full response for debugging
console.log('LLM Response:', result.text);

// Check for connection/availability errors
if (!result.text || result.text.length < 10) {
    throw new Error(`Ollama response too short. Check if Ollama is running and model "${selectedModel}" is available.`);
}

// Better error message with actual response snippet
const analysisText = result.text.trim();
if (!analysisText.includes('{')) {
    throw new Error(`LLM returned non-JSON response. Model: ${selectedModel}. First 200 chars: ${analysisText.substring(0, 200)}`);
}
```

#### Task 1b: Enhanced Generation Error Messages
**File:** `src/validators/bullet-generation/generation-helpers.js`

Add to error logging:
```javascript
console.log('Generation Attempt', attempt, '/', maxAttempts);
console.log('Model:', model);
console.log('Errors:', validationResult.errors.filter(e => e.requiresRegeneration));
```

#### Task 1c: UI Error Display
**File:** `src/components/Should-I-Apply-local.jsx`

Add error message component after generation failure:
```javascript
{error && (
  <div className="p-4 mb-4 bg-red-900/30 border border-red-600 rounded text-red-300">
    <p className="font-bold">Generation Failed</p>
    <p className="text-sm mt-1">{error}</p>
    <p className="text-xs mt-2 text-red-400">
      Try: 1) Different model 2) Simplify job description 3) Check Ollama logs
    </p>
  </div>
)}
```

### Phase 2: ENH-001 Implementation (v9.2.7.b)

#### Task 2a: Add Generation Model State
**File:** `src/components/Should-I-Apply-local.jsx`

```javascript
const [generationModel, setGenerationModel] = useState('');
const [lastGenerationResult, setLastGenerationResult] = useState(null);
```

#### Task 2b: Create Regeneration Function
**File:** `src/components/Should-I-Apply-local.jsx`

Extract bullet generation into reusable function:
```javascript
const regenerateBullets = async (modelToUse) => {
  setGenerating(true);
  try {
    const loopResult = await generateWithValidationLoop(
      modelToUse,
      baseGenerationPrompt,
      jobHistoryData,
      maxAttempts
    );
    setGeneratedContent(loopResult.content);
    setLastGenerationResult({
      success: loopResult.success,
      attempts: loopResult.attempts,
      model: modelToUse
    });
  } catch (err) {
    setError(`Regeneration failed: ${err.message}`);
  } finally {
    setGenerating(false);
  }
};
```

#### Task 2c: Add Model Selector UI
**File:** `src/components/Should-I-Apply-local.jsx`

Add to "Optimize Your Application" section (after generation completes):
```javascript
{generatedContent && (
  <div className="flex items-center gap-4 mb-4 p-3 bg-slate-800 rounded-lg">
    <label className="text-sm text-slate-400">Model:</label>
    <select
      value={generationModel}
      onChange={(e) => setGenerationModel(e.target.value)}
      className="bg-slate-700 text-white rounded px-3 py-1.5 text-sm"
      disabled={generating}
    >
      {availableModels.map(m => (
        <option key={m} value={m}>{m}</option>
      ))}
    </select>

    <button
      onClick={() => regenerateBullets(generationModel)}
      disabled={generating}
      className="flex items-center gap-2 px-4 py-1.5 bg-blue-600 hover:bg-blue-700
                 disabled:bg-slate-600 rounded text-sm font-medium"
    >
      {generating ? <>↻ Regenerating...</> : <>↻ Regenerate</>}
    </button>

    {lastGenerationResult && !lastGenerationResult.success && (
      <span className="text-amber-400 text-sm">
        ⚠️ Attempt {lastGenerationResult.attempts}/3 failed - try different model
      </span>
    )}
  </div>
)}
```

#### Task 2d: Mirror Changes to WebGUI
**File:** `claude-artifacts/Should-I-Apply-webgui.jsx`

Apply identical changes for consistency

---

## Files to Modify

| File | Change | Lines |
|------|--------|-------|
| `Should-I-Apply-local.jsx` | Error logging + ENH-001 UI | 460-490, +state, +regenerate fn, +UI |
| `Should-I-Apply-webgui.jsx` | Same changes | Mirror |
| `generation-helpers.js` | Better error logging | ~50-80 |

---

## Acceptance Criteria

- [ ] Analysis failures show specific error (not generic)
- [ ] LLM response logged to console
- [ ] Ollama connection errors identified
- [ ] Generation model dropdown appears after first generation
- [ ] User can switch models and regenerate without re-analyzing
- [ ] Error messages guide user to solutions
- [ ] Works in both local and webgui

---

## Verification

1. Test with Ollama down → see "Ollama not running" message
2. Test with wrong model → see "Model not available" message
3. Test generation failure → see model dropdown
4. Switch to different model → bullets regenerate
5. Check console → LLM response logged

---

## Commit Message

```bash
git commit -m "feat(v9.2.7): improve error handling + add model regeneration (ENH-001)

Issue #79 + ENH-001: Better diagnostics and model switching

Error Handling:
- Log full LLM response for debugging
- Better error messages for connection/model issues
- Show actionable error suggestions in UI

ENH-001 Implementation:
- Add model selector dropdown in Optimize section
- Add 'Regenerate' button to retry with different model
- Preserve analysis data across regenerations
- Track generation attempts and model used

Files:
- Should-I-Apply-local.jsx: Add error display + model UI
- Should-I-Apply-webgui.jsx: Mirror changes
- generation-helpers.js: Enhanced logging

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Next Steps

1. Review plan
2. Implement Phase 1 (error handling) first
3. Test with Ollama disconnected
4. Implement Phase 2 (ENH-001)
5. Test model switching
