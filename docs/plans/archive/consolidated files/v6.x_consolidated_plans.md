
# --- FILE: docs/plans/v6.0.1-foundation.md ---


# v6.0.1 Foundation - Schema & Core Infrastructure

**Version:** 6.0.1 (Part 1 of 4)
**Branch:** `v6.0.1-foundation`
**Token Budget:** 53,000 tokens (within 200K limit)
**Status:** Ready for Implementation

---

## Overview

This is the first phase of the v6.0 complete workflow system. It establishes the foundational schemas and parsing logic that all other phases will build upon.

**Goal:** Create the core data structures and parsing modules without modifying existing modes.

**Strategy:** Build in isolation - all new files, no modifications to existing code. This allows safe testing and rollback.

---

## Scope

### ✅ Included in v6.0.1

1. **Job History Schema job history creation** - Complete 12-section schema with hard/soft skills separation
2. **Skills Categorization Module** - Hard vs soft skill classification with confidence scoring
3. **Standard JD Parser** - Full extraction schema from legacy system

### ❌ Not Included (Deferred to Later Phases)

- Mode modifications (v6.0.2)
- Entry point router (v6.0.3)
- Professional summary generation (v6.0.4)
- Integration with existing workflows (v6.0.2+)

---

## Files to Create (3 New Files)

### File 1: `/shared/schemas/job-history-job history creation-schema.json`

**Purpose:** JSON schema definition for job history creation with validation rules

**Size:** ~250 lines

**Content Structure:**
```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Job History Schema job history creation",
  "version": "2.0.0",
  "type": "object",
  "required": ["schema_version", "positions"],
  "properties": {
    "schema_version": {
      "type": "string",
      "const": "2.0.0"
    },
    "positions": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["job_title", "company", "dates"],
        "properties": {
          "job_title": {"type": "string"},
          "company": {"type": "string"},
          "dates": {"type": "string"},
          "professional_summary": {"type": "string"},
          "core_responsibilities": {
            "type": "array",
            "items": {"type": "string"}
          },
          "key_achievements": {
            "type": "array",
            "items": {"type": "string"}
          },
          "hard_skills_demonstrated": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Technical/measurable skills (Python, SQL, AWS, etc.)"
          },
          "soft_skills_demonstrated": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Interpersonal/behavioral skills (Leadership, Communication, etc.)"
          },
          "education": {
            "type": "string",
            "description": "Degree, institution, year"
          },
          "certifications": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Professional certifications"
          },
          "tools_technologies": {
            "type": "array",
            "items": {"type": "string"}
          },
          "impact_metrics": {
            "type": "array",
            "items": {"type": "string"}
          },
          "industry_domain": {"type": "string"},
          "team_scope": {"type": "string"}
        }
      }
    }
  }
}
```

**Key Features:**
- Semantic versioning (2.0.0)
- Hard/soft skills separation
- Education and certifications fields
- Validation rules for required fields

---

### File 2: `/shared/modules/skills-categorizer.md`

**Purpose:** Decision tree logic for classifying skills as hard or soft

**Size:** ~150 lines

**Content Structure:**
```xml
<skills_categorizer>
  <purpose>
    Classify each skill as HARD (technical/measurable) or SOFT (interpersonal/behavioral)
    with confidence scoring to flag ambiguous cases.
  </purpose>

  <categorization_decision_tree>
    <step_1_exact_match>
      Check against known skills database:

      HARD_SKILLS_DATABASE = [
        "Python", "Java", "JavaScript", "SQL", "C++", "Ruby", "PHP",
        "AWS", "Azure", "GCP", "Docker", "Kubernetes", "Terraform",
        "JIRA", "Confluence", "Tableau", "Salesforce", "SAP", "Excel",
        "HIPAA", "GDPR", "SOX", "ISO 27001", "Agile", "Scrum", "Six Sigma",
        "PMP", "CPA", "CFA", "AWS Solutions Architect", ...
      ]

      SOFT_SKILLS_DATABASE = [
        "Leadership", "Communication", "Teamwork", "Problem-solving",
        "Time management", "Adaptability", "Critical thinking",
        "Stakeholder management", "Conflict resolution", "Mentoring",
        "Delegation", "Active listening", "Empathy", ...
      ]

      IF skill in HARD_SKILLS_DATABASE:
        RETURN {category: "hard", confidence: "high"}
      ELSE IF skill in SOFT_SKILLS_DATABASE:
        RETURN {category: "soft", confidence: "high"}
      ELSE:
        CONTINUE to step_2_context_analysis
    </step_1_exact_match>

    <step_2_context_analysis>
      Check surrounding words in JD text:

      HARD_SKILL_CONTEXT = [
        "certification", "proficiency", "years experience",
        "proficient in", "expertise in", "knowledge of"
      ]

      SOFT_SKILL_CONTEXT = [
        "ability to", "demonstrated", "proven track record",
        "strong", "excellent", "effective"
      ]

      IF context matches HARD_SKILL_CONTEXT:
        RETURN {category: "hard", confidence: "medium"}
      ELSE IF context matches SOFT_SKILL_CONTEXT:
        RETURN {category: "soft", confidence: "medium"}
      ELSE:
        CONTINUE to step_3_linguistic_analysis
    </step_2_context_analysis>

    <step_3_linguistic_analysis>
      Analyze part of speech:

      IF skill is a noun (Python, SQL, Tableau):
        RETURN {category: "hard", confidence: "medium"}
      ELSE IF skill is an adjective/adverb (collaborative, efficiently):
        RETURN {category: "soft", confidence: "medium"}
      ELSE IF skill is a verb (communicate, lead, manage):
        Extract implied skill → categorize as soft
        RETURN {category: "soft", confidence: "low"}
    </step_3_linguistic_analysis>

    <step_4_default_fallback>
      When in doubt, default to HARD skill (safer for blocking gate logic)

      RETURN {category: "hard", confidence: "low", flag: "review_needed"}
    </step_4_default_fallback>
  </categorization_decision_tree>

  <validation_rules>
    <!-- Check for skills appearing in both hard and soft arrays -->
    <duplicate_check>
      IF skill appears in BOTH hard_skills and soft_skills:
        WARN "Ambiguous skill detected: {skill}"
        KEEP in hard_skills (safer default)
        REMOVE from soft_skills
    </duplicate_check>

    <!-- Flag low-confidence categorizations for human review -->
    <confidence_flag>
      IF confidence == "low":
        ADD to review_queue: {skill, category, reasoning}
    </confidence_flag>
  </validation_rules>

  <output_format>
    {
      "skill": "Data Analysis",
      "category": "hard",
      "confidence": "medium",
      "reasoning": "Paired with 'proficiency' and '3+ years experience'"
    }
  </output_format>
</skills_categorizer>
```

**Key Features (from Opus review):**
- Three-tier decision tree (exact match → context → linguistic)
- Confidence scoring (high/medium/low)
- Ambiguous skill detection
- Safe default (hard skills when uncertain)

---

### File 3: `/shared/modules/jd-processing.md`

**Purpose:** JD parsing with keyword extraction and inference

**Size:** ~250 lines

**Content Structure:**
```xml
<jd_parser_17_point>
  <purpose>
    Extract structured data from job description text using the legacy parsing schema.
    Handle both structured and conversational JD formats.
  </purpose>

  <schema_17_point>
    <!-- Company & Role Info (4 fields) -->
    <company type="string">Employer name</company>
    <job_title type="string">Role title</job_title>
    <location type="string">Physical location or "Remote"</location>
    <work_lifestyle type="enum">Remote | On-Site | Hybrid</work_lifestyle>

    <!-- Work Conditions (4 fields) -->
    <remote_restrictions type="string">State restrictions or "fake remote" indicators</remote_restrictions>
    <employee_type type="enum">Full-time | Part-time | Contract</employee_type>
    <travel_required type="string">Travel percentage or frequency</travel_required>
    <clearance type="string">Security clearance requirements</clearance>

    <!-- Compensation & Requirements (4 fields) -->
    <salary_range type="string">Compensation range</salary_range>
    <required_experience type="string">Years and type of experience</required_experience>
    <required_education type="string">Degree requirements</required_education>
    <job_responsibilities type="array">Core duties</job_responsibilities>

    <!-- Hard Skills (2 fields) -->
    <skills_needed type="array">REQUIRED hard skills</skills_needed>
    <skills_wanted type="array">PREFERRED hard skills</skills_wanted>

    <!-- Soft Skills (2 fields) -->
    <soft_skills_needed type="array">REQUIRED soft skills</soft_skills_needed>
    <soft_skills_wanted type="array">PREFERRED soft skills</soft_skills_wanted>

    <!-- Qualifications & Certifications (4 fields) -->
    <qualifications_needed type="array">Required qualifications</qualifications_needed>
    <qualifications_wanted type="array">Preferred qualifications</qualifications_wanted>
    <certifications_needed type="array">Required certifications</certifications_needed>
    <certifications_wanted type="array">Preferred certifications</certifications_wanted>
  </schema_17_point>

  <extraction_strategy>
    <structured_jd_parsing>
      <!-- For JDs with clear sections (Requirements, Qualifications, etc.) -->

      STEP 1: Identify section headers
      - "Requirements", "Qualifications", "Responsibilities", "Nice to Have"

      STEP 2: Extract from structured sections
      - skills_needed ← "Requirements" section
      - skills_wanted ← "Nice to Have" or "Preferred" section
      - job_responsibilities ← "Responsibilities" section

      STEP 3: Categorize skills using skills-categorizer.md
      - Run each skill through categorization logic
      - Separate into hard vs soft skill arrays

      STEP 4: Fill metadata fields
      - company ← Extract from header or signature
      - location ← Look for "Location:", "Based in", address patterns
      - work_lifestyle ← "Remote", "Hybrid", "On-site" keywords
    </structured_jd_parsing>

    <conversational_jd_parsing>
      <!-- For JDs without clear structure (narrative/conversational format) -->

      STEP 1: Keyword-based extraction
      - Scan full text for skill keywords (Python, SQL, Leadership, etc.)
      - Add to skills_needed if mentioned in requirements context

      STEP 2: Pattern matching
      - "X years of experience in [SKILL]" → skills_needed
      - "Bonus if you know [SKILL]" → skills_wanted
      - "Proficient in [TOOL]" → skills_needed

      STEP 3: Contextual inference
      - "We're looking for a Python developer" → skills_needed: ["Python"]
      - "Love working with AWS?" → skills_wanted: ["AWS"]

      STEP 4: Confidence flagging
      - Mark extraction as "low confidence"
      - Warn user: "JD format is non-standard. Results may be incomplete."
    </conversational_jd_parsing>

    <missing_fields_handling>
      <!-- Per Opus Decision 6: Null + Infer -->

      IF field not found:
        - salary_range → null (continue silently)
        - clearance → null (continue silently)
        - location → null (continue silently)
        - skills_needed → Infer from job_responsibilities text
        - certifications → null (continue silently)

      NO warnings about incomplete JDs - work with what's available
    </missing_fields_handling>
  </extraction_strategy>

  <hard_soft_skill_rules>
    <!-- Critical: Correct classification affects blocking gates -->

    <hard_skills>
      DEFINITION: Technical, measurable, teachable skills

      EXAMPLES:
      - Programming languages (Python, Java, JavaScript, SQL, C++, Ruby)
      - Cloud platforms (AWS, Azure, GCP)
      - Tools/frameworks (Docker, Kubernetes, React, Django, Tableau)
      - Domain knowledge (HIPAA, GDPR, Agile, Six Sigma, SEO)
      - Technical certifications (PMP, AWS Solutions Architect, CPA)

      WHEN IN DOUBT: If it can be tested or measured, it's HARD
    </hard_skills>

    <soft_skills>
      DEFINITION: Interpersonal, behavioral, personality traits

      EXAMPLES:
      - Communication (written, verbal, presentation, stakeholder management)
      - Leadership (team management, mentoring, coaching, delegation)
      - Collaboration (teamwork, cross-functional, conflict resolution)
      - Work style (time management, adaptability, problem-solving, critical thinking)

      WHEN IN DOUBT: If it describes how someone works with others, it's SOFT
    </soft_skills>

    <classification_instruction>
      You MUST categorize each skill correctly. Misclassification affects blocking logic.

      RULE: When uncertain → default to HARD skill (safer for blocking gate calculations)
    </classification_instruction>
  </hard_soft_skill_rules>

  <output_format>
    {
      "jd_parsed": {
        "company": "TechCorp Inc.",
        "job_title": "Senior Product Manager",
        "location": "Remote",
        "work_lifestyle": "Remote",
        "skills_needed": ["Python", "SQL", "AWS", "Agile"],
        "skills_wanted": ["Kubernetes", "Terraform"],
        "soft_skills_needed": ["Leadership", "Communication"],
        "soft_skills_wanted": ["Stakeholder management"],
        "remote_restrictions": "US only",
        "salary_range": "$120K-$160K",
        "required_experience": "5+ years in product management",
        "required_education": "Bachelor's degree",
        "certifications_wanted": ["PMP", "Certified Scrum Master"]
      },
      "extraction_confidence": "high",
      "extraction_method": "structured"
    }
  </output_format>
</jd_parser_17_point>
```

**Key Features (from Opus review):**
- Dual extraction strategy (structured vs conversational)
- Inference for missing skills sections
- Null handling for optional fields
- Hard/soft skill separation with classification rules

---

## Implementation Steps

### Step 1: Create Schema File
```bash
# Create schema directory if it doesn't exist
mkdir -p shared/schemas

# Create job-history-job history creation-schema.json
# Write complete JSON schema with validation rules
```

**Validation:**
- Schema is valid JSON
- All 12 sections defined
- Required fields marked
- Version is "2.0.0"

---

### Step 2: Create Skills Categorizer Module
```bash
# Create modules directory if it doesn't exist
mkdir -p shared/modules

# Create skills-categorizer.md
# Write decision tree logic with confidence scoring
```

**Validation:**
- Test with 20 sample skills (10 hard, 10 soft)
- Verify confidence scoring works
- Check ambiguous skill detection

---

### Step 3: Create JD Parser Module
```bash
# Create jd-processing.md in shared/modules/
# Write parsing extraction logic
```

**Validation:**
- Test with structured JD (all 17 fields present)
- Test with conversational JD (narrative format)
- Test with minimal JD (only job title and requirements)
- Verify hard/soft skill separation

---

## Testing Checklist

### Schema Validation Tests

- [ ] Schema validates valid job history creation job history
- [ ] Schema rejects invalid data (missing required fields)
- [ ] All 12 sections defined with correct types
- [ ] Version field is "2.0.0"

### Skills Categorizer Tests

- [ ] Exact match: "Python" → hard (high confidence)
- [ ] Exact match: "Leadership" → soft (high confidence)
- [ ] Context: "Proficiency in Data Analysis" → hard (medium confidence)
- [ ] Context: "Strong communication skills" → soft (medium confidence)
- [ ] Ambiguous: "Project Management" → hard (default, low confidence)
- [ ] Duplicate detection: Skill in both hard/soft arrays → keeps hard only
- [ ] Confidence flagging: Low confidence skills added to review queue

### JD Parser Tests

**Structured JD:**
- [ ] Extracts all 17 fields from well-formatted JD
- [ ] Separates skills into hard vs soft correctly
- [ ] Distinguishes "required" vs "preferred" (needed vs wanted)
- [ ] Handles missing optional fields (salary, clearance) with null

**Conversational JD:**
- [ ] Extracts skills from narrative text
- [ ] Infers skills from responsibilities when skills section missing
- [ ] Flags as "low confidence" extraction
- [ ] Still produces usable parsing output

**Edge Cases:**
- [ ] JD with no skills section → infers from responsibilities
- [ ] JD with mixed hard/soft in same list → categorizes correctly
- [ ] JD with ambiguous skills → defaults to hard, flags for review

---

## Dependencies

**Requires:**
- None (this phase is self-contained)

**Required by:**
- v6.0.2 (Mode 1 will use job-history schema)
- v6.0.2 (Mode 3 will use JD parser)
- v6.0.4 (Summary generator will use skills categorizer)

---

## Success Criteria

v6.0.1 is successful if:

1. ✅ Schema file validates correctly with JSON Schema validator
2. ✅ Skills categorizer achieves >95% accuracy on test set of 100 skills
3. ✅ JD parser extracts all 17 fields from 100% of structured JDs
4. ✅ JD parser extracts ≥12 fields from >80% of conversational JDs
5. ✅ Hard/soft skill separation is correct in >90% of cases
6. ✅ All tests pass without errors

---

## Issues & Mitigations

### Issue 1: Hard/Soft Skill Ambiguity (from Opus review)

**Problem:** Skills like "Agile" could be hard (methodology certification) or soft (agile mindset).

**Mitigation:**
- Context analysis in decision tree
- Confidence scoring to flag ambiguous cases
- Default to hard skill when uncertain (safer for blocking gates)

### Issue 2: Conversational JD Extraction Incomplete

**Problem:** Narrative JDs might not have all 17 fields extractable.

**Mitigation:**
- Inference from responsibilities text
- Keyword-based fallback extraction
- Clear confidence flagging ("low confidence" warning)
- Allow nulls for optional fields (salary, clearance, location)

---

## Next Steps

**After v6.0.1 Completes:**

1. **Git Workflow:**
   ```bash
   git checkout -b v6.0.1-foundation
   git add shared/schemas/ shared/modules/
   git commit -m "feat(v6.0.1): add job history job history creation schema, skills categorizer, and JD parser"
   git push origin v6.0.1-foundation
   ```

2. **Proceed to v6.0.2:**
   - Integrate schema into Mode 1 (job history generation)
   - Integrate JD parser into Mode 3 (gap analysis)
   - See `/docs/plans/v6.0.2-core-integration.md`

---

**Plan Created:** 2025-12-28
**Token Budget:** 53,000 tokens (estimated)
**Dependencies:** None
**Next Phase:** v6.0.2 Core Integration


# --- FILE: docs/plans/v6.0.2-core-integration.md ---


# v6.0.2 Core Integration - Mode Enhancements

**Version:** 6.0.2 (Part 2 of 4)
**Branch:** `v6.0.2-core-integration`
**Token Budget:** 64,000 tokens (within 200K limit)
**Status:** Ready for Implementation

---

## Overview

This phase integrates the foundational schemas from v6.0.1 into the existing mode workflows. It's where the system starts generating job history creation job histories and performing evidence-based gap analysis.

**Goal:** Surgically enhance Mode 1 and Mode 3 to use v6.0.1 schemas without breaking existing functionality.

**Strategy:** Modify existing files minimally - add references to v6.0.1 modules, preserve all current logic.

---

## Prerequisites

**Must have v6.0.1 completed:**
- ✅ `shared/schemas/job-history-job history creation-schema.json` exists
- ✅ `shared/modules/skills-categorizer.md` exists
- ✅ `shared/modules/jd-processing.md` exists

---

## Scope

### ✅ Included in v6.0.2

1. **Evidence Matcher Module** - Links parsed JD to job history with citations
2. **Mode 1 Enhancement** - Generate job history job history creation format
3. **Mode 3 Enhancement** - Use parsing parser + evidence matching + blocking gates

### ❌ Not Included (Deferred to Later Phases)

- Entry point router (v6.0.3)
- Incremental updates (v6.0.3)
- Professional summary generation (v6.0.4)
- Re-comparison workflow (v6.0.3)

---

## Files to Create (1 New File)

### File 1: `/shared/modules/evidence-matching.md`

**Purpose:** Match JD requirements against job history with evidence citations and diff generation

**Size:** ~200 lines

**Content Structure:**
```xml
<evidence_matcher>
  <purpose>
    For EVERY requirement in the parsed JD, find evidence in job history and cite sources.
    Generate requirement-by-requirement gap analysis with evidence citations.
  </purpose>

  <matching_logic>
    <step_1_requirement_extraction>
      Extract all requirements from parsed JD:

      requirements = [
        ...jd.skills_needed.map(r => ({req: r, subcategory: "Skills Needed", importance: "Required"})),
        ...jd.skills_wanted.map(r => ({req: r, subcategory: "Skills Wanted", importance: "Preferred"})),
        ...jd.soft_skills_needed.map(r => ({req: r, subcategory: "Soft Skills Needed", importance: "Required"})),
        ...jd.soft_skills_wanted.map(r => ({req: r, subcategory: "Soft Skills Wanted", importance: "Preferred"})),
        ...jd.qualifications_needed.map(r => ({req: r, subcategory: "Qualifications Needed", importance: "Required"})),
        ...jd.certifications_needed.map(r => ({req: r, subcategory: "Certifications Needed", importance: "Required"})),
        ...jd.job_responsibilities.map(r => ({req: r, subcategory: "Responsibility", importance: "Required"}))
      ]
    </step_1_requirement_extraction>

    <step_2_evidence_search>
      For EACH requirement:

      1. **Exact Match Search:**
         - Search job history for exact keyword
         - Check: hard_skills_demonstrated, soft_skills_demonstrated, certifications
         - If found → status = "Matched"

      2. **Semantic Match Search:**
         - Search for related concepts (e.g., "Python" matches "developed ETL pipelines")
         - Check: core_responsibilities, key_achievements
         - If found → status = "Partial"

      3. **Missing:**
         - No evidence found in any section
         - status = "Missing"
    </step_2_evidence_search>

    <step_3_citation_formatting>
      For each evidence found:

      {
        "content": "Direct quote from resume (exact text from achievement/responsibility)",
        "source": "Company | Job Title",
        "source_type": "achievement" | "responsibility" | "skill"
      }

      FORMATTING RULES (Opus Decision 5):
      - Same company, multiple roles → Show each role with dates
        Example: "Google | PM (2018-2020)" and "Google | Lead PM (2022-2024)"
      - Contractor → "Accenture (Client: DHS) | Analyst"
      - Freelance → "Consultant | Freelance (5 clients)"
      - NO prefixes like "Resume -", "at", "Candidate -"
      - Format: "Company | Job Title (dates if multiple roles at same company)"
    </step_3_citation_formatting>

    <step_4_gap_rationale>
      For each requirement, explain the gap:

      MATCHED:
        "Strong evidence across multiple roles"
        "Exact keyword match in skills section"

      PARTIAL:
        "Resume shows related experience (statistical analysis) but not explicit ML frameworks"
        "Demonstrated leadership but not at required scale (led team of 5, JD requires 10+)"

      MISSING:
        "No evidence of [SKILL] found in job history"
        "Experience gap: JD requires [X], resume shows [Y]"
    </step_4_gap_rationale>
  </matching_logic>

  <evidence_based_vs_keyword_check>
    <!-- Opus Decision 3: Two-part check -->

    For EACH requirement:

    1. **Evidence Match:** Did the candidate DEMONSTRATE this skill?
       - Look for achievements, responsibilities, projects
       - This is the PRIMARY assessment

    2. **Keyword Check:** Does the resume EXPLICITLY mention this keyword?
       - Check if keyword appears in skills section or summary
       - This is SECONDARY (for ATS optimization)

    OUTPUT:
    - IF evidence found AND keyword present → [MATCHED]
    - IF evidence found BUT keyword missing → [PARTIAL] with keyword recommendation
    - IF no evidence → [MISSING]

    Example:
    ```
    [MATCHED] Agile
      Evidence: "Led sprint planning and backlog grooming sessions" (TechCorp | PM)
      Keyword status: ✓ "Agile" appears in skills section

    [PARTIAL] Agile
      Evidence: "Managed iterative product development cycles" (StartupCo | PM)
      Gap: Keyword "Agile" not explicitly listed - add to skills section for ATS
    ```
  </evidence_based_vs_keyword_check>

  <color_coded_output>
    KEY: [MATCHED] (Green) | [PARTIAL] (Yellow) | [MISSING] (Red)

    [HARD SKILLS - REQUIRED]

    [MATCHED] Python
      Evidence:
      - "Developed ETL pipelines using Python and Pandas"
        → TechCorp | Data Engineer (2020-2022)
      - "Automated workflows with Python scripts (saved 20 hrs/week)"
        → StartupCo | Senior Analyst (2018-2020)

    [PARTIAL] Machine Learning
      Evidence:
      - "Applied statistical models to forecast trends"
        → StartupCo | Data Analyst (2017-2018)
      Gap: Resume shows statistical analysis but not explicit ML frameworks (scikit-learn, TensorFlow)
      Recommendation: If you have ML experience, add specific framework keywords

    [MISSING] Kubernetes
      Evidence: None found
      Gap: No container orchestration experience mentioned
      Recommendation: Not strategic to apply unless you're willing to learn Kubernetes

    SORTING ORDER:
    - Matched items first
    - Partial items second
    - Missing items last
  </color_coded_output>

  <diff_generation>
    <!-- For re-comparison workflow (v6.0.3) -->

    When comparing CURRENT job history to PREVIOUS comparison:

    {
      "improvements": [
        {
          "requirement": "Salesforce",
          "previous_status": "Missing",
          "current_status": "Matched",
          "new_evidence": "Implemented Salesforce integration (Acme Corp | PM)"
        }
      ],
      "no_change": ["SQL", "Agile", "Leadership"],
      "score_delta": "+9 points (72% → 81%)"
    }

    OUTPUT:
    ```
    ## Changes Since Last Comparison

    ### Improvements
    - [MISSING → MATCHED] Salesforce: Now matched from your new position at Acme Corp
    - [PARTIAL → MATCHED] Python: Updated context with new project details

    ### No Change
    - [MATCHED] SQL, Agile, Leadership
    - [MISSING] Kubernetes (still not in your history)

    ### Overall Score: 72% → 81% (+9 points)
    ```
  </diff_generation>

  <output_schema>
    {
      "requirement_analysis": [
        {
          "requirement": "Python programming",
          "subcategory": "Skills Needed",
          "importance": "Required",
          "status": "Matched",
          "evidence": [
            {
              "content": "Developed ETL pipelines using Python and Pandas",
              "source": "TechCorp | Data Engineer",
              "source_type": "achievement"
            }
          ],
          "gap_rationale": "Strong evidence across multiple roles",
          "keyword_present": true
        }
      ],
      "summary": {
        "matched_count": 12,
        "partial_count": 5,
        "missing_count": 3,
        "match_score": 75
      }
    }
  </output_schema>
</evidence_matcher>
```

**Key Features (from Opus review):**
- Requirement-by-requirement analysis (not aggregated)
- Evidence citations with source formatting
- Two-part check (evidence + keyword)
- Diff generation for re-comparison
- Color-coded output with sorting

---

## Files to Modify (3 Files - Surgical Changes)

### Modification 1: `PROJECT-INSTRUCTIONS.md`

**Changes:**

**Location 1: After line 15 (Mode detection section)**
```xml
<!-- ADD THIS SECTION -->
<job_history_schema_version>
  The system now uses Job History Schema job history creation (as of v6.0.2).

  Key changes from v1.0:
  - hard_skills_demonstrated and soft_skills_demonstrated (separated)
  - education field added
  - certifications array added
  - professional_summary per role added

  When generating job history, use the schema defined in:
  shared/schemas/job-history-job history creation-schema.json
</job_history_schema_version>
```

**Location 2: Lines 40-120 (Mode 1 job history creation section)**
```xml
<!-- REPLACE the job history creation instructions -->
<job_history_creation>
  After extracting resume data, generate job history in job history creation format:

  FOR EACH position in resume:
    1. Extract metadata (job_title, company, dates)
    2. Extract core_responsibilities (3-5 bullets)
    3. Extract key_achievements (3-5 bullets with metrics)
    4. Categorize skills using shared/modules/skills-categorizer.md:
       - Run each skill through categorization logic
       - Separate into hard_skills_demonstrated and soft_skills_demonstrated
    5. Extract education (if mentioned in context of this role)
    6. Extract certifications (if mentioned in context of this role)
    7. Extract tools_technologies (granular list)
    8. Extract impact_metrics (quantified results)
    9. Extract industry_domain
    10. Extract team_scope
    11. Generate professional_summary for this role:
        - 2-3 sentences summarizing role scope
        - Key achievements and metrics
        - 2-3 hard skills demonstrated
        - 1-2 soft skills demonstrated

  SAVE to: claude_generated_job_history_summaries_v2.txt
  FORMAT: Plain text with XML-like structure (see schema for details)
</job_history_creation>
```

**Location 3: After Mode 1 completion (new section after line 120)**
```xml
<!-- ADD THIS SECTION -->
<mode_1_completion_next_steps>
  After job history creation is generated and saved, present next steps:

  "✅ Analysis complete! Your job history has been saved.

  Next steps - What would you like to do?
  1. Optimize specific resume bullets (Mode 2)
  2. Check fit for a job description (Mode 3)
  3. Export job history for review

  Just let me know, or paste a job description to start Mode 3!"
</mode_1_completion_next_steps>
```

**Location 4: Line ~800 (version number)**
```xml
<!-- UPDATE version -->
<version>6.0.2</version>
```

---

### Modification 2: `modes/mode-3-jd-comparison.md`

**Changes:**

**Location 1: Lines 80-120 (JD extraction section)**
```xml
<!-- REPLACE current JD extraction with parsing parser -->
<jd_parsing>
  Use the JD parsing schema from shared/modules/jd-processing.md

  Extract all 17 fields:
  - company, job_title, location, work_lifestyle
  - remote_restrictions, employee_type, travel_required, clearance
  - salary_range, required_experience, required_education, job_responsibilities
  - skills_needed, skills_wanted (HARD skills - required/preferred)
  - soft_skills_needed, soft_skills_wanted (SOFT skills - required/preferred)
  - qualifications_needed, qualifications_wanted
  - certifications_needed, certifications_wanted

  IMPORTANT: Use skills-categorizer.md to separate hard vs soft skills
</jd_parsing>
```

**Location 2: After line 150 (add requirement-by-requirement gap tracking)**
```xml
<!-- ADD THIS SECTION -->
<requirement_by_requirement_gap_analysis>
  Use shared/modules/evidence-matching.md to analyze EVERY requirement.

  For EACH requirement:
  1. Search job history creation for evidence
  2. Determine status (Matched/Partial/Missing)
  3. Collect evidence citations with sources
  4. Provide gap rationale

  OUTPUT using color-coded format:
  - KEY legend at top
  - Section headers ([HARD SKILLS - REQUIRED], etc.)
  - Matched → Partial → Missing sorting within each section
  - Evidence citations in "Company | Job Title" format
</requirement_by_requirement_gap_analysis>
```

**Location 3: After line 220 (add blocking gates)**
```xml
<!-- ADD THIS SECTION -->
<blocking_gates>
  After gap analysis, check blocking gates (Opus Decision 2: Soft block with warning):

  <gate_1_hard_skill_deficit>
    IF count(Missing Hard Skills) > count(Matched Hard Skills):
      DISPLAY WARNING:
      "⚠ WARNING: Poor Job Fit Detected

      Hard Skills Required by JD:
        [MATCHED] {list matched skills}
        [MISSING] {list missing skills}

      You are missing {X} of {Y} required hard skills.

      Proceeding will use tokens to generate recommendations that are unlikely
      to be useful. This is not advised.

      Do you want to proceed anyway? (yes/no)"

      IF user says "no":
        STOP analysis, save tokens
      IF user says "yes":
        CONTINUE to recommendations (user accepted risk)
  </gate_1_hard_skill_deficit>

  <gate_2_low_match_score>
    IF match_score < 30:
      DISPLAY WARNING:
      "⚠ LOW MATCH SCORE DETECTED (<30)

      Final Match Score: {score}/100

      Based on the analysis, this position has significant gaps compared to your profile.
      Optimization is unlikely to bridge this gap effectively.

      Recommendation: Focus on roles with 50+ match scores where optimization can be strategic.

      Do you want to proceed anyway? (yes/no)"

      IF user says "no":
        STOP analysis
      IF user says "yes":
        CONTINUE to recommendations
  </gate_2_low_match_score>

  <gate_3_location_mismatch>
    <!-- KEEP EXISTING v5.1 logic from ADD_REMOTE_WORK_LOGIC.md -->
    <!-- This gate already exists, don't modify -->
  </gate_3_location_mismatch>
</blocking_gates>
```

**Location 4: After line 280 (add per-JD summary option placeholder)**
```xml
<!-- ADD THIS SECTION (basic version, full implementation in v6.0.4) -->
<per_jd_summary_placeholder>
  After gap analysis completes, if match_score >= 50:
    OFFER: "Would you like me to generate a customized professional summary for this JD?"

    IF yes:
      NOTE: "Per-JD summary generation will be implemented in v6.0.4.
             For now, use your master summary from job history."
</per_jd_summary_placeholder>
```

---

### Modification 3: `modes/mode-2-bullet-optimization.md`

**Changes:**

**Location 1: Line ~30 (job history file reference)**
```xml
<!-- UPDATE to support both v1.0 and job history creation -->
<job_history_loading>
  <!-- Backward compatibility - check job history creation first, fallback to v1.0 -->

  IF file exists: claude_generated_job_history_summaries_v2.txt:
    LOAD job history creation format
    USE hard_skills_demonstrated and soft_skills_demonstrated arrays
  ELSE IF file exists: claude_generated_job_history_summaries.txt:
    LOAD v1.0 format
    USE skills_demonstrated array (combined hard/soft)
    RECOMMEND: "I see you have v1.0 job history. Consider re-running Mode 1 to upgrade to job history creation for better keyword matching with separated hard/soft skills."
  ELSE:
    ERROR: "No job history found. Please run Mode 1 first to analyze your resume."
</job_history_loading>
```

**Location 2: Line ~60 (skills reference for keyword insertion)**
```xml
<!-- UPDATE to use job history creation skills arrays -->
<keyword_insertion_logic>
  IF using job history creation job history:
    - Use hard_skills_demonstrated for technical keyword insertion
    - Use soft_skills_demonstrated for behavioral keyword insertion
  ELSE IF using v1.0 job history:
    - Use skills_demonstrated array (combined)
</keyword_insertion_logic>
```

---

## Implementation Steps

### Step 1: Create Evidence Matcher Module
```bash
# Create evidence-matching.md in shared/modules/
# Write matching logic with citation formatting
```

**Validation:**
- Test with sample JD + job history
- Verify all requirements analyzed
- Check evidence citation format ("Company | Title")

---

### Step 2: Modify PROJECT-INSTRUCTIONS.md
```bash
# Read current file
# Make 4 surgical additions (line 15, 40-120, 120, 800)
# Preserve all existing logic
```

**Validation:**
- Mode 1 still works for standalone analysis
- job history creation job history generation triggered
- Next steps message appears after completion

---

### Step 3: Modify mode-3-jd-comparison.md
```bash
# Read current file
# Make 4 surgical additions (80-120, 150, 220, 280)
# Preserve v5.1 location blocking gate
```

**Validation:**
- JD parsing works
- Evidence matching produces citations
- Blocking gates fire correctly
- v5.1 location logic still works

---

### Step 4: Modify mode-2-bullet-optimization.md
```bash
# Read current file
# Make 2 surgical additions (line 30, 60)
# Ensure backward compatibility
```

**Validation:**
- Mode 2 works with job history creation job history
- Mode 2 falls back to v1.0 if job history creation not found
- Upgrade recommendation shown for v1.0 users

---

## Testing Checklist

### Mode 1 Enhancement Tests

- [ ] Mode 1 generates job history creation with all 12 sections
- [ ] Professional summary generated for each role
- [ ] Hard/soft skills separated correctly
- [ ] Education extracted (if present)
- [ ] Certifications extracted (if present)
- [ ] "Next Steps" message appears after completion
- [ ] job history creation file saved to correct location

### Mode 3 Enhancement Tests

- [ ] JD parsing extracts all fields
- [ ] Requirement-by-requirement gap analysis works
- [ ] Evidence citations formatted as "Company | Title"
- [ ] Color-coded output displayed correctly
- [ ] Matched/Partial/Missing sorting works
- [ ] Gate 1 (hard skill deficit) fires correctly
- [ ] Gate 2 (low match score) fires correctly
- [ ] Gate 3 (location mismatch) still works from v5.1
- [ ] User can override gates with "yes/no"

### Mode 2 Backward Compatibility Tests

- [ ] Mode 2 loads job history creation job history successfully
- [ ] Mode 2 falls back to v1.0 if job history creation not found
- [ ] Upgrade recommendation shown for v1.0 users
- [ ] Keyword insertion uses hard/soft skills correctly (job history creation)
- [ ] Keyword insertion works with combined skills (v1.0)

### Evidence Matcher Tests

- [ ] Exact match: "Python" in hard_skills → status = "Matched"
- [ ] Semantic match: "developed ETL pipelines" → status = "Partial" for "Python"
- [ ] Missing: No evidence found → status = "Missing"
- [ ] Citations include source: "TechCorp | Data Engineer"
- [ ] Multiple roles at same company → separate citations with dates
- [ ] Contractor format: "Accenture (Client: DHS) | Analyst"

---

## Dependencies

**Requires:**
- ✅ v6.0.1 (all 3 files must exist)

**Required by:**
- v6.0.3 (router will detect job history creation job history)
- v6.0.4 (summary generator will read job history creation job history)

---

## Success Criteria

v6.0.2 is successful if:

1. ✅ Mode 1 generates job history creation (100% of new analyses)
2. ✅ Mode 3 uses JD parsing (100% of JD comparisons)
3. ✅ Evidence matching produces citations for all requirements
4. ✅ Blocking gates fire correctly with soft blocking (allow override)
5. ✅ Mode 2 backward compatible with v1.0 job histories
6. ✅ All tests pass without errors
7. ✅ No regressions in existing functionality

---

## Issues & Mitigations

### Issue 1: Evidence Citation Source Inconsistency (from Opus review)

**Problem:** Job histories might have inconsistent company/title formats.

**Mitigation:**
- Standardize format during job history creation (Mode 1)
- Enforce "Company | Job Title" in job history creation schema
- Post-processing in evidence matcher to normalize

### Issue 2: Blocking Gates Too Aggressive

**Problem:** Gates might block users who are close matches.

**Mitigation:**
- Soft blocking with override option (Opus Decision 2)
- Clear warning message explaining why blocking
- User decides whether to proceed (yes/no)

### Issue 3: v1.0 to job history creation Migration Confusion

**Problem:** Users with v1.0 job history might not know to upgrade.

**Mitigation:**
- Mode 2 shows clear upgrade recommendation
- Explains benefits of job history creation (better keyword matching)
- Doesn't force upgrade (backward compatible)

---

## Next Steps

**After v6.0.2 Completes:**

1. **Git Workflow:**
   ```bash
   git checkout -b v6.0.2-core-integration
   git add shared/modules/ PROJECT-INSTRUCTIONS.md modes/
   git commit -m "feat(v6.0.2): integrate job history creation schema into modes 1 & 3, add evidence matching"
   git push origin v6.0.2-core-integration
   ```

2. **Testing:**
   - Run full end-to-end test: New resume → Mode 1 → Mode 3 with JD
   - Verify job history creation job history generated
   - Verify JD parsing works
   - Verify blocking gates fire

3. **Proceed to v6.0.3:**
   - Build entry point router
   - Add incremental update handler
   - Add re-comparison workflow
   - See `/docs/plans/v6.0.3-router-workflows.md`

---

**Plan Created:** 2025-12-28
**Token Budget:** 64,000 tokens (estimated)
**Dependencies:** v6.0.1 (required)
**Next Phase:** v6.0.3 Router & Workflows


# --- FILE: docs/plans/v6.0.3-router-workflows.md ---


# v6.0.3 Router & Workflows - Entry Point & Additional Features

**Version:** 6.0.3 (Part 3 of 4)
**Branch:** `v6.0.3-router-workflows`
**Token Budget:** 49,000 tokens (within 200K limit)
**Status:** Ready for Implementation

---

## Overview

This phase adds the entry point router for auto-detecting user intent and two additional workflows: incremental position updates and JD re-comparison.

**Goal:** Create seamless user experience with intelligent routing and support for ongoing resume maintenance.

**Strategy:** Build router module + integrate incremental update logic into Mode 3 for re-comparison.

---

## Prerequisites

**Must have v6.0.2 completed:**
- ✅ Mode 1 generates job history creation
- ✅ Mode 3 uses JD parsing
- ✅ Evidence matcher module exists

---

## Scope

### ✅ Included in v6.0.3

1. **Entry Point Router** - Auto-detect user state + confirm before executing
2. **Incremental Updates** - Add/edit/remove positions without full re-analysis
3. **JD Re-Comparison** - Re-run comparison with updated job history + diff output

### ❌ Not Included (Deferred to v6.0.4)

- Professional summary generation (master + per-JD)
- Summary customization logic
- Documentation updates
- Multi-track career support (removed from v6.0 scope per Opus Decision 1a)

---

## Files to Create (1 New File)

### File 1: `/shared/modules/workflow-router.md`

**Purpose:** Detect user intent and route to appropriate mode with confirmation

**Size:** ~300 lines

**Content Structure:**
```xml
<workflow_router>
  <purpose>
    Analyze user input and context to determine which workflow to execute.
    Always confirm with user before proceeding (hybrid auto-detect + confirmation).
  </purpose>

  <context_detection>
    <check_job_history>
      IF file exists: claude_generated_job_history_summaries_v2.txt
      AND file is not empty
      THEN state.hasJobHistory = true
      ELSE state.hasJobHistory = false
    </check_job_history>

    <check_jd_provided>
      <!-- JD Detection Heuristics (from Opus review Issue #4) -->

      JD_INDICATORS = [
        "Job Description:", "JD:", "Role:", "Requirements:",
        "Apply for:", "Position at", "Responsibilities:",
        "Qualifications:", "We are looking for"
      ]

      JD_VALIDATION_HEURISTICS = {
        length: text.length > 200 && text.length < 5000,
        has_keywords: text includes ("requirements" OR "qualifications" OR "responsibilities"),
        has_structure: text includes (bullet points OR numbered lists),
        has_company: text mentions company name or role title
      }

      IF user message matches JD_INDICATORS:
        IF JD_VALIDATION_HEURISTICS pass:
          state.hasJD = true
          state.jdConfidence = "high"
        ELSE:
          state.hasJD = "maybe"
          state.jdConfidence = "low"
          ASK USER: "This looks like a job description, but I'm not certain. Is this a JD you want to analyze?"
    </check_jd_provided>

    <check_resume_uploaded>
      IF user uploads file (PDF/DOCX/TXT):
        state.hasResume = true
      OR IF user pastes text > 300 words:
        state.hasResume = true
    </check_resume_uploaded>

    <check_override_commands>
      <!-- From Issue #9: Router doesn't handle resume updates -->

      OVERRIDE_KEYWORDS = {
        "re-analyze": Force Mode 1,
        "start over": Delete job history creation file + Force Mode 1,
        "start fresh": Delete job history creation file + Force Mode 1,
        "update job history": Force Mode 1 (append mode),
        "add position": Incremental update mode,
        "remove position": Incremental update mode,
        "edit position": Incremental update mode
      }

      IF user message matches OVERRIDE_KEYWORDS:
        state.forceMode = detected_mode
    </check_override_commands>
  </context_detection>

  <routing_scenarios>
    <!-- 5 core scenarios + 3 additional workflows -->

    <scenario_1_new_user priority="1">
      <condition>state.hasResume = true AND state.hasJobHistory = false</condition>
      <route>Mode 1 (Full Analysis)</route>
      <confirmation>
        "I detected a new resume upload. I'll perform a comprehensive resume analysis
        and create your job history profile.

        After analysis, you can:
        - Optimize specific bullets (Mode 2)
        - Check fit for a job description (Mode 3)

        Proceed with full analysis?"
      </confirmation>
      <on_confirm>Execute Mode 1</on_confirm>
      <on_decline>Ask "What would you like me to do instead?"</on_decline>
    </scenario_1_new_user>

    <scenario_2_jd_comparison priority="2">
      <condition>state.hasJobHistory = true AND state.hasJD = true</condition>
      <route>Mode 3 (JD Comparison)</route>
      <confirmation>
        "I detected your job history and a job description. I'll analyze your fit
        for this role using the parsing gap analysis system.

        This will compare your profile against:
        - Required/preferred hard skills
        - Required/preferred soft skills
        - Experience, education, certifications
        - Location/remote work compatibility

        Proceed with JD fit analysis?"
      </confirmation>
      <on_confirm>Execute Mode 3</on_confirm>
      <on_decline>Ask "Would you like to do something else instead?"</on_decline>
    </scenario_2_jd_comparison>

    <scenario_3_bullet_optimization priority="3">
      <condition>state.hasJobHistory = true AND user mentions ("bullet", "optimize", "improve wording")</condition>
      <route>Mode 2 (Bullet Optimization)</route>
      <confirmation>
        "I'll optimize your resume bullets using your job history as context.

        Which bullets would you like me to improve? You can:
        - Paste specific bullets to optimize
        - Upload your current resume for bulk optimization

        Proceed?"
      </confirmation>
      <on_confirm>Execute Mode 2</on_confirm>
    </scenario_3_bullet_optimization>

    <scenario_4_ambiguous priority="4">
      <condition>state.hasJobHistory = true AND state.hasJD = false AND no override detected</condition>
      <route>None (Ask user)</route>
      <clarification>
        "I see you have a job history on file. What would you like to do?

        1. Check fit for a specific job description (Mode 3)
        2. Optimize resume bullets (Mode 2)
        3. Re-analyze my resume with updated info (Mode 1)
        4. Add/edit a position in my job history

        Please select 1-4 or describe what you need."
      </clarification>
    </scenario_4_ambiguous>

    <scenario_5_first_interaction priority="5">
      <condition>state.hasResume = false AND state.hasJobHistory = false</condition>
      <route>None (Explain system)</route>
      <welcome>
        "Welcome to the Resume Analyzer & Optimizer!

        I can help you:
        1. **Analyze your resume** - Get comprehensive feedback (Mode 1)
        2. **Optimize bullets** - Improve specific resume lines (Mode 2)
        3. **Check job fit** - Compare your resume to a job description (Mode 3)

        To get started, please upload your resume (PDF, DOCX, or paste text).

        If you have a specific job description you're targeting, include that too!

        Note: Your job history is saved to files in this project. If you close this
        session, your data persists but conversation context is lost. Start a new
        session anytime - I'll pick up where you left off using your saved files."
      </welcome>
    </scenario_5_first_interaction>

    <scenario_6_incremental_update priority="6">
      <condition>user message matches ("add position", "edit position", "remove position")</condition>
      <route>Incremental Update Handler</route>
      <confirmation>
        "I'll help you update your job history.

        What would you like to do?
        1. Add a new position
        2. Edit an existing position
        3. Remove a position

        Please select 1-3 or describe the change."
      </confirmation>
      <on_confirm>Execute incremental update logic (see below)</on_confirm>
    </scenario_6_incremental_update>

    <scenario_7_re_comparison priority="7">
      <condition>user message matches ("compare again", "re-run", "updated history") AND state.hasJobHistory = true</condition>
      <route>JD Re-Comparison Handler</route>
      <confirmation>
        "I'll re-run the JD comparison with your updated job history.

        Please paste the job description you want to re-analyze."
      </confirmation>
      <on_confirm>Execute re-comparison logic (see below)</on_confirm>
    </scenario_7_re_comparison>

    <scenario_8_ambiguous_input priority="8">
      <!-- From Opus Decision 7: Two-step guided conversation -->

      <condition>Cannot determine intent from input</condition>
      <route>None (Clarify with user)</route>
      <step_1_confirm_assumption>
        "This looks like [DETECTED_TYPE]. Is that correct? (yes/no)"
      </step_1_confirm_assumption>
      <step_2a_if_yes>
        "Would you like me to [ACTION]? (yes/no)"
      </step_2a_if_yes>
      <step_2b_if_no>
        "Got it. Is this:
         1. Part of a resume (I'll analyze it)
         2. Part of a JD (I'll compare against your job history)
         3. Something else"
      </step_2b_if_no>
    </scenario_8_ambiguous_input>
  </routing_scenarios>

  <incremental_update_handler>
    <!-- From Opus review Part 7: Incremental Position Updates -->

    <add_position>
      STEP 1: Collect position details
        Ask same questions as Mode 1 position loop:
        - "What was your job title?"
        - "Which company?"
        - "What were your dates of employment?"
        - "Tell me about your responsibilities..."

      STEP 2: Generate job history creation sections
        - Use skills-categorizer.md for hard/soft separation
        - Generate professional_summary for this role
        - Extract all 12 sections

      STEP 3: Insert at correct chronological position
        - Sort positions by dates (most recent first)
        - Insert new position in array

      STEP 4: Recalculate aggregates
        - Update total_years_experience
        - Rebuild skills aggregation (all hard/soft skills across positions)

      STEP 5: Save and confirm
        SAVE to: claude_generated_job_history_summaries_v2.txt
        CONFIRM: "Added [Title] at [Company]. Job history now has [N] positions."
    </add_position>

    <edit_position>
      STEP 1: User selects position
        LIST positions: "Which position? 1. Company A (2021-2023) 2. Company B (2019-2021)"

      STEP 2: Show current values
        DISPLAY: Current job_title, company, dates, responsibilities, etc.

      STEP 3: Ask what to change
        "What would you like to update? (You can change multiple fields)"

      STEP 4: Update in place
        - Modify selected fields
        - Re-categorize skills if skills changed
        - Regenerate professional_summary if major changes

      STEP 5: Recalculate aggregates
        - Update total_years_experience if dates changed
        - Rebuild skills aggregation

      STEP 6: Save and confirm
        SAVE changes
        CONFIRM: "Updated [Title] at [Company]."
    </edit_position>

    <remove_position>
      STEP 1: User selects position
        LIST positions for deletion

      STEP 2: Confirm deletion
        WARN: "Are you sure? This will remove [Title] at [Company] from your job history."

      STEP 3: Remove from array
        - Delete position from positions array

      STEP 4: Recalculate aggregates
        - Update total_years_experience
        - Rebuild skills aggregation

      STEP 5: Save and confirm
        SAVE changes
        CONFIRM: "Removed [Title] at [Company]. Job history now has [N] positions."
    </remove_position>
  </incremental_update_handler>

  <re_comparison_handler>
    <!-- From Opus review Part 7: JD Re-Comparison -->

    <workflow>
      STEP 1: Check for previous comparison
        - User provides JD identifier (company name, job title)
        - Search jd_cache for matching JD
        - Location: /mnt/project/jd_parsed/[company]_[job]_parsed.json

      STEP 2a: If cached JD found
        LOAD: Previous parsed JD
        DISPLAY: "Found your comparison from [date]. Re-running with updated job history..."
        SKIP: JD parsing (use cached version)

      STEP 2b: If cached JD not found
        DISPLAY: "I don't have that JD saved. Please paste the job description again."
        WAIT: For user to provide JD text
        PARSE: Using jd-processing.md (parsing schema)
        CACHE: Save parsed JD for future re-comparisons

      STEP 3: Run evidence matcher
        - Use shared/modules/evidence-matching.md
        - Match against CURRENT job_history_v2.0.json
        - Generate requirement-by-requirement analysis

      STEP 4: Generate diff output
        IF previous comparison exists:
          COMPARE: Current results vs previous results
          HIGHLIGHT:
          - Improvements (Missing → Matched, Partial → Matched)
          - Regressions (Matched → Missing - rare but possible)
          - No change (still Matched, still Missing)
          - Score delta (e.g., 72% → 81%)

        OUTPUT:
        ```
        ## Changes Since Last Comparison

        ### Improvements
        - [MISSING → MATCHED] Salesforce: Now matched from your new position at Acme Corp
        - [PARTIAL → MATCHED] Python: Updated context with new project details

        ### No Change
        - [MATCHED] SQL, Agile, Leadership
        - [MISSING] Kubernetes (still not in your history)

        ### Overall Score: 72% → 81% (+9 points)
        ```

      STEP 5: Store versioned comparison
        SAVE: /mnt/project/jd_parsed/[company]_[job]_v2_parsed.json
        KEEP: Previous version as v1 for history
    </workflow>

    <cache_management>
      User commands:
      - "Clear JD cache" → Delete all /mnt/project/jd_parsed/ files
      - "List saved JDs" → Show all cached comparisons with dates
      - "Delete [Company] JD" → Remove specific cached JD
    </cache_management>
  </re_comparison_handler>
</workflow_router>
```

**Key Features (from Opus review):**
- 8 routing scenarios (5 core + 3 additional)
- JD validation heuristics (avoid false positives)
- Override commands for force-routing
- Incremental update logic (add/edit/remove positions)
- Re-comparison with diff generation
- Ambiguous input handling (two-step clarification)

---

## Files to Modify (1 File - Surgical Change)

### Modification 1: `PROJECT-INSTRUCTIONS.md`

**Changes:**

**Location 1: After line 15 (before mode detection)**
```xml
<!-- ADD THIS SECTION -->
<entry_point_routing>
  Before executing any mode, consult shared/modules/workflow-router.md to:
  1. Detect user state (hasJobHistory, hasJD, hasResume)
  2. Identify user intent (which workflow to execute)
  3. Confirm with user before proceeding
  4. Handle override commands (re-analyze, start fresh, add position, etc.)

  The router handles 8 scenarios:
  - New user (no job history)
  - JD comparison (has job history + JD)
  - Bullet optimization (has job history + wants optimization)
  - Ambiguous (has job history, unclear intent)
  - First interaction (no context)
  - Incremental update (add/edit/remove position)
  - Re-comparison (re-run JD analysis with updated history)
  - Ambiguous input (cannot determine type)

  ALWAYS route through workflow-router.md first
</entry_point_routing>
```

---

## Implementation Steps

### Step 1: Create Workflow Router Module
```bash
# Create workflow-router.md in shared/modules/
# Write all 8 routing scenarios
# Include incremental update handler
# Include re-comparison handler
```

**Validation:**
- Test all 8 scenarios with sample inputs
- Verify JD validation heuristics work
- Check override commands trigger correct modes

---

### Step 2: Modify PROJECT-INSTRUCTIONS.md
```bash
# Add entry routing section after line 15
# Preserve all existing logic
```

**Validation:**
- Router consulted before mode execution
- User confirmation requested
- Override commands work

---

### Step 3: Create JD Cache Directory
```bash
# Create directory for storing parsed JDs
mkdir -p /mnt/project/jd_parsed/
```

**Validation:**
- Directory exists
- Permissions allow read/write

---

## Testing Checklist

### Router Tests (8 Scenarios)

- [ ] Scenario 1: New user uploads resume → routes to Mode 1
- [ ] Scenario 2: User with job history pastes JD → routes to Mode 3
- [ ] Scenario 3: User says "optimize bullets" → routes to Mode 2
- [ ] Scenario 4: User with job history, unclear intent → asks for clarification
- [ ] Scenario 5: First interaction, no context → shows welcome message
- [ ] Scenario 6: User says "add position" → incremental update handler
- [ ] Scenario 7: User says "compare again" → re-comparison handler
- [ ] Scenario 8: Ambiguous input → two-step clarification

### JD Validation Tests

- [ ] Structured JD (clear sections) → detected with high confidence
- [ ] Conversational JD (narrative) → detected with medium confidence
- [ ] LinkedIn post (looks like JD) → low confidence, asks user to confirm
- [ ] Short text (<200 words) → not detected as JD
- [ ] Very long text (>5000 words) → not detected as JD

### Override Command Tests

- [ ] User says "re-analyze" with existing job history → forces Mode 1
- [ ] User says "start fresh" → deletes job history creation file, forces Mode 1
- [ ] User says "add position" → incremental update mode
- [ ] User says "edit position" → incremental update mode
- [ ] User says "remove position" → incremental update mode

### Incremental Update Tests

**Add Position:**
- [ ] Collects all required fields (job title, company, dates)
- [ ] Generates job history creation sections (12 sections)
- [ ] Inserts at correct chronological position
- [ ] Recalculates total_years_experience
- [ ] Rebuilds skills aggregation
- [ ] Saves to job history creation file
- [ ] Confirms addition with position count

**Edit Position:**
- [ ] Lists existing positions for selection
- [ ] Shows current values
- [ ] Updates selected fields
- [ ] Recalculates aggregates if dates changed
- [ ] Saves changes
- [ ] Confirms update

**Remove Position:**
- [ ] Lists positions for deletion
- [ ] Confirms with user (Are you sure?)
- [ ] Removes from array
- [ ] Recalculates aggregates
- [ ] Saves changes
- [ ] Confirms removal with new position count

### Re-Comparison Tests

- [ ] User provides JD identifier (company + job title)
- [ ] System finds cached JD from previous comparison
- [ ] Loads cached JD (skips re-parsing)
- [ ] Runs evidence matcher with CURRENT job history
- [ ] Generates diff output (improvements, no change, regressions)
- [ ] Shows score delta (e.g., 72% → 81%)
- [ ] Stores versioned comparison (v1, v2)
- [ ] If cached JD not found, asks user to paste JD again

### Cache Management Tests

- [ ] "List saved JDs" → shows all cached comparisons
- [ ] "Delete [Company] JD" → removes specific cached JD
- [ ] "Clear JD cache" → deletes all cached JDs
- [ ] Cache persists across sessions

---

## Dependencies

**Requires:**
- ✅ v6.0.2 (Mode 1, Mode 3 enhancements)
- ✅ Evidence matcher module

**Required by:**
- v6.0.4 (summary generator will use router context)

---

## Success Criteria

v6.0.3 is successful if:

1. ✅ Router detects all 8 scenarios correctly (100%)
2. ✅ JD validation avoids false positives (>95% accuracy)
3. ✅ Override commands work reliably (100%)
4. ✅ Incremental updates modify job history without errors
5. ✅ Re-comparison generates diff output correctly
6. ✅ JD cache persists across sessions
7. ✅ User confirmation requested before all mode executions
8. ✅ No regressions in existing functionality

---

## Issues & Mitigations

### Issue 1: JD Detection False Positives (from plan Issue #4)

**Problem:** LinkedIn posts or articles might look like JDs.

**Mitigation:**
- JD validation heuristics (length, keywords, structure)
- Low-confidence detection asks user to confirm
- User can always override with explicit command

### Issue 2: Incremental Update Complexity

**Problem:** Adding a position requires collecting all 12 sections.

**Mitigation:**
- Reuse Mode 1 question flow (same questions)
- Clear step-by-step prompts
- Allow partial data (mark missing sections as "Not specified")

### Issue 3: Re-Comparison JD Not Found

**Problem:** User wants to re-compare but didn't cache original JD.

**Mitigation:**
- Clear error message: "I don't have that JD saved"
- Ask user to paste JD again
- Parse and cache for future re-comparisons

---

## Next Steps

**After v6.0.3 Completes:**

1. **Git Workflow:**
   ```bash
   git checkout -b v6.0.3-router-workflows
   git add shared/modules/ PROJECT-INSTRUCTIONS.md
   mkdir -p /mnt/project/jd_parsed
   git commit -m "feat(v6.0.3): add workflow router, incremental updates, and re-comparison"
   git push origin v6.0.3-router-workflows
   ```

2. **Testing:**
   - Test all 8 routing scenarios
   - Test incremental updates (add/edit/remove)
   - Test re-comparison with cached JD
   - Test cache management commands

3. **Proceed to v6.0.4:**
   - Build professional summary generator
   - Add master summary (Mode 1)
   - Add per-JD summary customization (Mode 3)
   - Update documentation (CHANGELOG, PROJECT-INSTRUCTIONS)
   - See `/docs/plans/v6.0.4-summary-polish.md`

---

**Plan Created:** 2025-12-28
**Token Budget:** 49,000 tokens (estimated)
**Dependencies:** v6.0.2 (required)
**Next Phase:** v6.0.4 Summary & Polish


# --- FILE: docs/plans/v6.0.4-summary-polish.md ---


# v6.0.4 Summary & Polish - Final Integration & Documentation

**Version:** 6.0.4 (Part 4 of 4 - Final)
**Branch:** `v6.0.4-summary-polish`
**Token Budget:** 37,000 tokens (within 200K limit)
**Status:** Ready for Implementation

---

## Overview

This is the final phase of v6.0, adding professional summary generation and completing the system integration with full documentation.

**Goal:** Deliver the complete v6.0 feature set with polished UX and comprehensive documentation.

**Strategy:** Add summary generation module, update all documentation, perform final integration testing.

---

## Prerequisites

**Must have v6.0.3 completed:**
- ✅ Workflow router exists and works
- ✅ Incremental updates functional
- ✅ Re-comparison workflow operational

---

## Scope

### ✅ Included in v6.0.4

1. **Professional Summary Generator** - Master summary (Mode 1) + per-JD customization (Mode 3)
2. **Documentation Updates** - CHANGELOG, PROJECT-INSTRUCTIONS, settings files
3. **Final Integration Testing** - End-to-end workflows validated
4. **Progress Indicators** - User feedback during long operations

### ❌ Not Included

- Multi-track career support (removed from v6.0 per Opus Decision 1a)
- State recovery/checkpoints (not possible per Opus Decision 9)
- Performance benchmarks with time targets (per Opus Decision 10)

---

## Files to Create (1 New File)

### File 1: `/shared/modules/summary-generation.md`

**Purpose:** Generate professional summaries (master + per-JD customization)

**Size:** ~150 lines

**Content Structure:**
```xml
<summary_generator>
  <purpose>
    Generate two types of professional summaries:
    1. Master summary - Generic, comprehensive (stored in job history)
    2. Per-JD summary - Customized with JD keywords (ephemeral, not stored)
  </purpose>

  <master_summary_generation>
    <!-- For Mode 1: Job History Creation -->

    <trigger>After all positions extracted, before saving job history creation</trigger>

    <structure>
      3-4 sentences covering:
      1. Role + Scope (title, years of experience, industry)
      2. Achievements + Metrics (quantified results across career)
      3. Hard Skills (2-3 technical/measurable skills)
      4. Soft Skills (1-2 interpersonal/behavioral skills)
    </structure>

    <requirements>
      - Aggregate career metrics (total years, number of companies, team sizes)
      - Name-drop 2-3 recognizable companies (if applicable)
      - Include 2-3 hard skills from hard_skills_demonstrated arrays
      - Include 1-2 soft skills from soft_skills_demonstrated arrays
      - Quantify leadership scope (team size, budget, users, revenue)
    </requirements>

    <example>
      INPUT:
        positions = [
          {company: "Google", job_title: "Senior PM", dates: "2020-2023", ...},
          {company: "Salesforce", job_title: "PM", dates: "2018-2020", ...},
          {company: "StartupCo", job_title: "Associate PM", dates: "2016-2018", ...}
        ]

      OUTPUT:
        "Senior Product Manager with 8 years leading B2B SaaS products at Google and Salesforce.
        Launched 12+ revenue-generating features ($5M ARR), managed roadmaps for 500K+ users,
        and led cross-functional teams of 10+. Expert in Agile methodologies, JIRA, SQL, and
        data-driven prioritization. Known for exceptional stakeholder communication and ability
        to translate technical concepts for executive audiences."
    </example>

    <storage>
      SAVE to: job_history_v2.0.json → master_summary field
      NOT per-position (this is aggregate across entire career)
    </storage>
  </master_summary_generation>

  <per_jd_summary_customization>
    <!-- For Mode 3: JD Comparison -->

    <trigger>
      After gap analysis completes, IF match_score >= 50:
        OFFER: "Would you like me to generate a customized professional summary for this JD?"
    </trigger>

    <timing>
      <!-- From plan Issue #5: Offer BEFORE or AFTER gap analysis? -->

      OPTION A (Early): After JD parsing, before gap analysis
        PRO: User gets summary immediately for application
        CON: Summary may not reflect gap insights

      OPTION B (Late): After gap analysis, as part of recommendations
        PRO: Summary can address specific gaps identified
        CON: User might want summary sooner

      DECISION: OPTION B (after gap analysis)
        RATIONALE: Summary should leverage gap insights to optimize keyword placement
    </timing>

    <customization_logic>
      STEP 1: Load master summary from job history
        base_summary = job_history_v2.0.master_summary

      STEP 2: Extract JD keywords (top 3-5 missing hard skills with "Partial" status)
        jd_keywords = gap_analysis
          .filter(r => r.subcategory === "Skills Needed" && r.status === "Partial")
          .slice(0, 5)
          .map(r => r.requirement)

      STEP 3: Replace generic hard skills with JD-specific keywords
        ORIGINAL: "Expert in Agile methodologies, JIRA, SQL, and data-driven decision-making"
        JD_KEYWORDS: ["Python", "AWS", "Kubernetes"]
        CUSTOMIZED: "Expert in Python, AWS cloud architecture, Kubernetes orchestration, and data-driven decision-making"

      STEP 4: Add JD-specific industry/domain terms
        IF jd.industry_domain in ["Fintech", "Healthcare", "E-commerce"]:
          ADD domain expertise mention

      STEP 5: Maintain metrics and achievements from master summary
        DO NOT change quantified results (team size, revenue, users)
        These are factual and should not be altered
    </customization_logic>

    <output_format>
      [PROFESSIONAL SUMMARY - CUSTOMIZED FOR THIS JD]

      {customized_summary}

      Changes Made:
      - Added JD keywords: "Python", "AWS", "Kubernetes"
      - Emphasized cloud architecture experience (from "Managed AWS deployments" achievement)
      - Retained leadership scope and metrics

      IMPORTANT: This summary is optimized for this specific JD. Copy it to your resume for this application.
    </output_format>

    <storage>
      NOT stored permanently - ephemeral (generated on-demand)
      User must copy/paste into their resume
    </storage>
  </per_jd_summary_customization>

  <edge_cases>
    <missing_master_summary>
      IF job_history_v2.0.master_summary is empty:
        Generate from scratch using all positions
        SAVE to job history for future use
    </missing_master_summary>

    <low_match_score>
      IF match_score < 50:
        DO NOT offer per-JD summary
        REASON: Too many gaps - customization won't help
    </low_match_score>

    <no_partial_skills>
      IF no "Partial" skills in gap analysis:
        Use matched skills as keywords instead
        CUSTOMIZE to emphasize JD-specific context
    </no_partial_skills>
  </edge_cases>

  <progress_indicators>
    <!-- Opus Decision 10: Show progress without time targets -->

    DURING MASTER SUMMARY GENERATION:
      "Generating professional summary..."
      "Aggregating career metrics..."
      "Selecting key achievements..."
      "Done. Summary added to job history."

    DURING PER-JD CUSTOMIZATION:
      "Customizing summary for this JD..."
      "Extracting JD keywords..."
      "Optimizing keyword placement..."
      "Done. Here's your customized summary:"
  </progress_indicators>
</summary_generator>
```

**Key Features (from plan + Opus review):**
- Master summary generation for Mode 1
- Per-JD customization for Mode 3
- Timing decision (after gap analysis)
- Edge case handling (missing summary, low score, no partials)
- Progress indicators without time estimates

---

## Files to Modify (4 Files - Surgical Changes)

### Modification 1: `PROJECT-INSTRUCTIONS.md`

**Changes:**

**Location 1: Lines 40-120 (Mode 1 job history creation) - UPDATE**
```xml
<!-- ADD to job history creation section -->
<professional_summary_generation>
  After extracting all positions:

  1. Use shared/modules/summary-generation.md to generate master summary
  2. Aggregate career metrics:
     - total_years_experience (sum of all position durations)
     - total_companies (count of unique companies)
     - max_team_size (largest team_scope across all positions)
     - notable_companies (Fortune 500, well-known brands)
  3. Generate 3-4 sentence summary
  4. Save to job_history_v2.0.master_summary

  DISPLAY to user:
    "✅ Professional summary generated and saved."
</professional_summary_generation>
```

**Location 2: After Mode 1 completion message - UPDATE**
```xml
<!-- ENHANCE completion message -->
<mode_1_completion_message>
  "✅ Analysis complete! Your job history has been saved.

  Your profile includes:
  - {N} positions analyzed
  - {X} hard skills identified, {Y} soft skills
  - Professional summary generated

  Note: Your job history is saved to files in this project. If you close this
  session, your data persists but conversation context is lost. Start a new
  session anytime - I'll pick up where you left off using your saved files.

  Next steps - What would you like to do?
  1. Optimize specific resume bullets (Mode 2)
  2. Check fit for a job description (Mode 3)
  3. Export job history for review

  Just let me know, or paste a job description to start Mode 3!"
</mode_1_completion_message>
```

**Location 3: Version number - UPDATE**
```xml
<version>6.0.4</version>
```

---

### Modification 2: `modes/mode-3-jd-comparison.md`

**Changes:**

**Location 1: After line 280 (per-JD summary placeholder) - REPLACE**
```xml
<!-- REPLACE placeholder with full implementation -->
<per_jd_summary_customization>
  After gap analysis completes:

  IF match_score >= 50:
    ASK USER: "Would you like me to generate a customized professional summary for this JD?"

    IF yes:
      1. Use shared/modules/summary-generation.md
      2. Load master summary from job history
      3. Extract top 3-5 JD keywords from "Partial" skills
      4. Customize summary with JD-specific keywords
      5. Present customized summary with change log
      6. Remind user to copy for this application

  IF match_score < 50:
    SKIP summary customization (too many gaps)
</per_jd_summary_customization>
```

**Location 2: Add progress indicators - NEW**
```xml
<!-- ADD progress indicators at key steps -->
<progress_indicators>
  STEP 1 (JD Parsing):
    "Parsing job description..."
    "Extracting skills and requirements..."

  STEP 2 (Gap Analysis):
    "Matching against your job history..."
    "Analyzing {total_requirements} requirements..."
    "Generating gap analysis..."

  STEP 3 (Summary Customization):
    "Customizing professional summary for this JD..."
    "Optimizing keyword placement..."

  FINAL:
    "Done."
</progress_indicators>
```

---

### Modification 3: `docs/CHANGELOG.md`

**Changes:**

**Location: After line 10 (add v6.0.0 entry)**
```markdown
## v6.0.0 - Complete Workflow System (2025-12-28)

### 🚨 BREAKING CHANGES

- **Job History Schema job history creation**: New schema with 12 sections (up from 8 in v1.0)
  - Added: `hard_skills_demonstrated`, `soft_skills_demonstrated`
  - Added: `education`, `certifications`, `tools_technologies`, `professional_summary`
  - Migration: Fresh start - no automatic migration from v1.0
  - Mode 2 maintains backward compatibility with v1.0

### ✨ Added

#### v6.0.1 - Foundation
- **Job History Schema job history creation** with hard/soft skills separation
- **Skills Categorizer** module with confidence scoring
- **Standard JD Parser** restored from legacy system

#### v6.0.2 - Core Integration
- **Evidence-Based Matching** with requirement-by-requirement gap analysis
- **Mode 1 Enhancement**: Generate job history job history creation format
- **Mode 3 Enhancement**: Use JD parsing + evidence matching
- **Blocking Gates**: Hard skill deficit, low match score, location mismatch (soft blocks with override)
- **Color-Coded Output**: [MATCHED] / [PARTIAL] / [MISSING] with evidence citations

#### v6.0.3 - Router & Workflows
- **Entry Point Router** with auto-detect + confirmation (8 scenarios)
- **Incremental Updates**: Add/edit/remove positions without full re-analysis
- **JD Re-Comparison**: Re-run comparison with updated job history + diff output
- **JD Cache**: Store parsed JDs for faster re-comparisons

#### v6.0.4 - Summary & Polish
- **Professional Summary Generation**:
  - Master summary (stored in job history)
  - Per-JD customization (ephemeral, keyword-optimized)
- **Progress Indicators**: User feedback during long operations
- **File Persistence Notifications**: Clear messaging about data storage

### 🔄 Changed

- **Mode 3 JD Parsing**: Upgraded from aggregate categories to parsing schema
- **Gap Analysis**: Changed from category-level to requirement-by-requirement tracking
- **Evidence Citations**: Standardized format "Company | Job Title"
- **Blocking Gates**: Soft blocking with user override (not hard blocking)

### 🐛 Fixed

- **Hard/Soft Skill Classification**: Confidence scoring to flag ambiguous skills
- **JD Detection**: Validation heuristics to avoid false positives
- **Evidence Source Formatting**: Consistent "Company | Title" format enforced

### 📚 Documentation

- Added comprehensive implementation plans (v6.0.1 - v6.0.4)
- Updated PROJECT-INSTRUCTIONS.md with v6.0 features
- Added Opus review findings to planning docs

### 🧪 Testing

- 31 must-have tests identified and validated
- Full end-to-end workflow testing completed
- Backward compatibility with v1.0 verified

### 📊 Migration Guide

**From v5.1 to v6.0:**

1. **Job History**:
   - v1.0 files preserved (not deleted)
   - Mode 2 works with v1.0 (backward compatible)
   - Run Mode 1 to generate job history creation job history
   - job history creation recommended for better keyword matching

2. **Mode 3 JD Comparison**:
   - No action needed - automatically uses parsing parser
   - Blocking gates now soft-blocking (allow override)

3. **Entry Point Router**:
   - Auto-routing with confirmation
   - Override commands: "re-analyze", "start fresh", "add position"

### ⚠️ Known Limitations

- Multi-track career support: Deferred to v6.2+
- State recovery/checkpoints: Not possible without environment control
- Performance time targets: Not documented (progress indicators without times)

---

## v5.1.0 - Remote Work Classification for Job Analysis (2025-12-28)

[Previous changelog entries preserved...]
```

---

### Modification 4: `settings.json` and `settings.local.json`

**Changes:**

**Add to both files:**
```json
{
  "job_history": {
    "schema_version": "2.0.0",
    "storage_path": "/mnt/project/",
    "v1_file": "claude_generated_job_history_summaries.txt",
    "v2_file": "claude_generated_job_history_summaries_v2.txt"
  },
  "jd_cache": {
    "enabled": true,
    "path": "/mnt/project/jd_parsed/",
    "retention_days": 90
  },
  "summary_generation": {
    "master_summary_auto_generate": true,
    "per_jd_summary_auto_offer": true,
    "min_match_score_for_customization": 50
  }
}
```

---

## Implementation Steps

### Step 1: Create Summary Generator Module
```bash
# Create summary-generation.md in shared/modules/
# Write master summary + per-JD customization logic
```

**Validation:**
- Test master summary generation with 3+ positions
- Test per-JD customization with sample JD
- Verify progress indicators display

---

### Step 2: Update PROJECT-INSTRUCTIONS.md
```bash
# Add summary generation to Mode 1 (lines 40-120)
# Enhance Mode 1 completion message
# Update version to 6.0.4
```

**Validation:**
- Mode 1 generates master summary
- Completion message shows profile stats
- File persistence notification displayed

---

### Step 3: Update mode-3-jd-comparison.md
```bash
# Replace per-JD summary placeholder (line 280)
# Add progress indicators
```

**Validation:**
- Per-JD summary offered after gap analysis (if score >= 50)
- Customization uses JD keywords
- Progress indicators show during analysis

---

### Step 4: Update CHANGELOG.md
```bash
# Add complete v6.0.0 entry
# Document all 4 sub-versions
# Add migration guide
```

**Validation:**
- All features documented
- Breaking changes clearly marked
- Migration guide complete

---

### Step 5: Update Settings Files
```bash
# Add v6.0 configuration to settings.json
# Add same to settings.local.json
```

**Validation:**
- Configuration valid JSON
- Paths correctly specified

---

## Testing Checklist

### Summary Generation Tests

**Master Summary:**
- [ ] Generates 3-4 sentence summary
- [ ] Aggregates career metrics (years, companies, team size)
- [ ] Includes 2-3 hard skills
- [ ] Includes 1-2 soft skills
- [ ] Name-drops 2-3 recognizable companies (if applicable)
- [ ] Quantifies leadership scope
- [ ] Saved to job_history_v2.0.master_summary

**Per-JD Customization:**
- [ ] Offered after gap analysis (if score >= 50)
- [ ] NOT offered if score < 50
- [ ] Loads master summary as baseline
- [ ] Extracts top 3-5 JD keywords from "Partial" skills
- [ ] Replaces generic hard skills with JD-specific keywords
- [ ] Maintains metrics and achievements from master
- [ ] Presents change log showing customizations
- [ ] Reminds user to copy for application

### Progress Indicator Tests

- [ ] Mode 1: Shows progress during position extraction
- [ ] Mode 3: Shows progress during JD parsing
- [ ] Mode 3: Shows progress during gap analysis
- [ ] Mode 3: Shows progress during summary customization
- [ ] No time estimates shown (per Opus Decision 10)

### Documentation Tests

- [ ] CHANGELOG has complete v6.0.0 entry
- [ ] Breaking changes clearly marked
- [ ] Migration guide provided
- [ ] All sub-versions documented
- [ ] Known limitations listed

### Settings Tests

- [ ] settings.json valid JSON
- [ ] Paths correctly specified
- [ ] Configuration values reasonable

### End-to-End Integration Tests

**Full Workflow 1: New User**
- [ ] User uploads resume
- [ ] Router detects new user → routes to Mode 1
- [ ] Mode 1 generates job history creation (all 12 sections)
- [ ] Master summary generated
- [ ] Completion message shows profile stats
- [ ] File persistence notification displayed
- [ ] Next steps offered (Mode 2, Mode 3)

**Full Workflow 2: JD Comparison**
- [ ] User with job history pastes JD
- [ ] Router detects JD → routes to Mode 3
- [ ] JD parsed using parsing schema
- [ ] Gap analysis performed (requirement-by-requirement)
- [ ] Evidence citations formatted correctly
- [ ] Blocking gates checked (soft blocking with override)
- [ ] Per-JD summary offered (if score >= 50)
- [ ] Summary customized with JD keywords

**Full Workflow 3: Incremental Update + Re-Comparison**
- [ ] User adds new position
- [ ] job history creation updated
- [ ] User requests re-comparison with previous JD
- [ ] Cached JD loaded
- [ ] Evidence matcher runs with UPDATED job history
- [ ] Diff generated (improvements, no change, score delta)

---

## Dependencies

**Requires:**
- ✅ v6.0.3 (router, incremental updates, re-comparison)

**Required by:**
- None (this is the final phase)

---

## Success Criteria

v6.0.4 (and v6.0 overall) is successful if:

1. ✅ Master summary generated for 100% of Mode 1 runs
2. ✅ Per-JD summary offered when appropriate (score >= 50)
3. ✅ Customization uses JD keywords correctly
4. ✅ Progress indicators display during long operations
5. ✅ CHANGELOG complete and accurate
6. ✅ All end-to-end workflows tested and passing
7. ✅ No regressions in existing functionality
8. ✅ User documentation clear and comprehensive

---

## Final Deliverables

**After v6.0.4 Completes:**

### New Files Created (Across All Phases)
1. `shared/schemas/job-history-job history creation-schema.json`
2. `shared/modules/skills-categorizer.md`
3. `shared/modules/jd-processing.md`
4. `shared/modules/evidence-matching.md`
5. `shared/modules/workflow-router.md`
6. `shared/modules/summary-generation.md`
7. `docs/plans/v6.0.1-foundation.md`
8. `docs/plans/v6.0.2-core-integration.md`
9. `docs/plans/v6.0.3-router-workflows.md`
10. `docs/plans/v6.0.4-summary-polish.md`

### Files Modified (Across All Phases)
1. `PROJECT-INSTRUCTIONS.md`
2. `modes/mode-3-jd-comparison.md`
3. `modes/mode-2-bullet-optimization.md`
4. `docs/CHANGELOG.md`
5. `settings.json`
6. `settings.local.json`

### User Data Files
- `claude_generated_job_history_summaries_v2.txt` (generated by Mode 1)
- `/mnt/project/jd_parsed/*.json` (JD cache files)

**Total Implementation:**
- ~1,400 lines of new code
- ~420 lines of modified code
- 0 deletions (surgical additions only)
- 241,000 tokens across 4 phases

---

## Next Steps

**After v6.0.4 Completes:**

1. **Git Workflow:**
   ```bash
   git checkout -b v6.0.4-summary-polish
   git add shared/modules/ PROJECT-INSTRUCTIONS.md modes/ docs/ settings*
   git commit -m "feat(v6.0.4): add professional summary generation and complete v6.0 documentation"
   git push origin v6.0.4-summary-polish
   ```

2. **Merge All Sub-Versions:**
   ```bash
   git checkout -b v6.0-complete_workflow_system
   git merge v6.0.1-foundation
   git merge v6.0.2-core-integration
   git merge v6.0.3-router-workflows
   git merge v6.0.4-summary-polish
   git push origin v6.0-complete_workflow_system
   ```

3. **Create Pull Request:**
   - Title: "v6.0 Complete Workflow System"
   - Description: Copy from CHANGELOG v6.0.0 entry
   - Reference all 4 sub-version branches

4. **User Acceptance Testing:**
   - Test all workflows end-to-end
   - Validate with real resume + real JD
   - Verify backward compatibility with v1.0

5. **Release:**
   - Merge PR to main
   - Tag release: `git tag v6.0.0`
   - Update version in PROJECT-INSTRUCTIONS.md

---

## Post-Release

**Future Enhancements (v6.1+):**
- v6.1: Deferred test cases (summary edge cases, performance benchmarks)
- v6.2: Multi-track career support (PM vs Analyst tracks)
- v6.3: Advanced JD parsing (machine learning classification)
- v6.4: Export functionality (PDF, DOCX, JSON)

**User Feedback:**
- Monitor GitHub issues for bugs
- Collect feature requests
- Iterate based on real usage patterns

---

**Plan Created:** 2025-12-28
**Token Budget:** 37,000 tokens (estimated)
**Dependencies:** v6.0.3 (required)
**Status:** Final Phase - Ready for Implementation


# --- FILE: docs/plans/v6.0.5-docs_cleanup.md ---


# v6.0.5 - Documentation Cleanup & Structural Reorganization

**Branch:** `v6.0.5-docs_cleanup`
**Date:** 2025-12-29
**Type:** PATCH (Documentation & structure cleanup, no functional changes)

---

## 🎯 Objectives

1. **Rename `/shared/` → `/phases/`** - More intuitive naming for v6.0 modular architecture
2. **Remove outdated files** - Delete/archive v5.0 legacy files no longer referenced
3. **Create new wireframes** - Visual documentation for v6.0 workflow (ASCII + Mermaid)
4. **Update all references** - Ensure PROJECT-INSTRUCTIONS.md and other files point to correct paths
5. **Consolidate test cases** - Organize test documentation for v6.0.1-6.0.4

---

## 📁 Folder Structure Changes

### Before (v6.0.4)
```
/optimize-my-resume/
├── /shared/                        ← Confusing name
│   ├── /phase-1/
│   ├── /phase-2/
│   ├── /phase-3/
│   ├── /phase-4/
│   ├── /v5-legacy/                 ← Outdated
│   └── opus-handoff.md             ← Temporary artifact
├── /modes/                         ← v5.0 files (not referenced)
├── /wireframes/                    ← v5.0 wireframes (outdated)
├── CHANGELOG.md (root)             ← Duplicate/outdated
└── ADD_REMOTE_WORK_LOGIC.md        ← v5.1 prompt (obsolete)
```

### After (v6.0.5)
```
/optimize-my-resume/
├── /phases/                        ← Renamed from /shared/
│   ├── /phase-1/                   ← Foundation (v6.0.1)
│   ├── /phase-2/                   ← Core Integration (v6.0.2)
│   ├── /phase-3/                   ← Router & Workflows (v6.0.3)
│   └── /phase-4/                   ← Summary & Polish (v6.0.4)
├── /wireframes/                    ← NEW: v6.0 visual documentation
│   ├── phase-1-foundation.md       ← ASCII + Mermaid
│   ├── phase-2-core-integration.md
│   ├── phase-3-router-workflows.md
│   ├── phase-4-summary-polish.md
│   └── complete-workflow.md        ← End-to-end v6.0 flow
├── /docs/legacy/                   ← NEW: Archived obsolete files
│   ├── /modes-v5/                  ← Moved from /modes/
│   ├── /wireframes-v5/             ← Moved from /wireframes/
│   ├── /shared-v5/                 ← v5-legacy subfolder
│   ├── CHANGELOG-v5.md             ← Root CHANGELOG.md
│   └── ADD_REMOTE_WORK_LOGIC.md    ← v5.1 implementation prompt
└── (CHANGELOG.md removed)          ← Duplicate deleted
```

---

## 🗂️ Detailed File Operations

### Phase 1: Rename `/shared/` → `/phases/`

**Files to rename:**
```bash
mv shared/ phases/
```

**References to update:**
1. `PROJECT-INSTRUCTIONS.md` - All `shared/phase-X/` → `phases/phase-X/`
2. `README.md` - File structure diagram
3. `docs/CHANGELOG.md` - v6.0.0 entry references
4. `ROADMAP.md` - Phase tracking references
5. `quick-start-mode.md` - If any references exist

**Expected changes:** ~15-20 file path updates across 5 files

---

### Phase 2: Archive Obsolete Files

#### 2.1 Create Legacy Archive Directory
```bash
mkdir -p docs/legacy/{modes-v5,wireframes-v5,shared-v5,implementation-prompts}
```

#### 2.2 Move Outdated Files

**From `/modes/` (v5.0 - Not referenced):**
```bash
mv modes/mode-1-full-analysis.md docs/legacy/modes-v5/
mv modes/mode-2-bullet-optimization.md docs/legacy/modes-v5/
mv modes/mode-3-jd-comparison.md docs/legacy/modes-v5/
rmdir modes/  # Remove empty directory
```

**From `/wireframes/` (v5.0 - Outdated):**
```bash
mv wireframes/mode-1-workflow.md docs/legacy/wireframes-v5/
mv wireframes/mode-2-workflow.md docs/legacy/wireframes-v5/
mv wireframes/mode-3-workflow.md docs/legacy/wireframes-v5/
rmdir wireframes/  # Will be recreated with v6.0 wireframes
```

**From `/phases/v5-legacy/` (Renamed from `/shared/v5-legacy/`):**
```bash
mv phases/v5-legacy/initial-greeting.md docs/legacy/shared-v5/
mv phases/v5-legacy/job-summary-creation.md docs/legacy/shared-v5/
rmdir phases/v5-legacy/
```

**Root-level obsolete files:**
```bash
mv CHANGELOG.md docs/legacy/CHANGELOG-v5.md  # Duplicate, outdated
mv ADD_REMOTE_WORK_LOGIC.md docs/legacy/implementation-prompts/
mv phases/opus-handoff.md docs/plans/archive/opus-handoff.md
```

#### 2.3 Create Legacy README
```bash
# Create docs/legacy/README.md explaining what's archived and why
```

---

### Phase 3: Create New Wireframes (v6.0)

Create `/wireframes/` directory with comprehensive visual documentation.

#### 3.1 Phase-Specific Wireframes (5 files)

Each file contains:
1. **ASCII diagram** - Terminal-friendly visualization
2. **Mermaid diagram** - GitHub-rendered flowchart
3. **Phase description** - What happens, inputs/outputs, files involved

**Files to create:**

1. **`wireframes/phase-1-foundation.md`**
   - Job History Creation creation flow
   - JD parsing flow
   - Entry router decision tree

2. **`wireframes/phase-2-core-integration.md`**
   - Evidence matching flow (requirement-by-requirement)
   - Blocking gates logic
   - Mode 1 & Mode 3 enhancements

3. **`wireframes/phase-3-router-workflows.md`**
   - 8-scenario routing flowchart
   - Incremental update workflow
   - JD re-comparison with diff

4. **`wireframes/phase-4-summary-polish.md`**
   - Master summary generation
   - Per-JD summary customization flow

5. **`wireframes/complete-workflow.md`**
   - End-to-end user journey (all 3 modes)
   - Entry routing → Mode execution → Output
   - State transitions between modes

#### 3.2 Wireframe Template Structure

Each wireframe follows this format:

```markdown
# Phase X - [Phase Name]

**Version:** 1.0
**Last Updated:** 2025-12-29
**Related Modules:** phases/phase-X/

---

## Overview
[Brief description of what this phase does]

## ASCII Diagram
[Terminal-friendly ASCII art flowchart]

## Mermaid Diagram
[GitHub-rendered Mermaid flowchart]

## Inputs
- [What data/files are required]

## Outputs
- [What gets generated/modified]

## Files Involved
- phases/phase-X/[module].md

## Decision Points
- [Key branching logic]
```

---

### Phase 4: Update Documentation References

#### 4.1 Files Requiring Updates

**`PROJECT-INSTRUCTIONS.md`:**
- Change: `shared/phase-1/` → `phases/phase-1/`
- Change: `shared/phase-2/` → `phases/phase-2/`
- Change: `shared/phase-3/` → `phases/phase-3/`
- Change: `shared/phase-4/` → `phases/phase-4/`
- Estimated: 15-20 occurrences

**`README.md`:**
- Update file structure tree
- Change: `/shared/` → `/phases/`
- Update folder descriptions

**`docs/CHANGELOG.md`:**
- Update v6.0.0 entry references
- Add v6.0.5 entry documenting cleanup

**`ROADMAP.md`:**
- Update phase tracking references
- Add v6.0.5 entry

**`quick-start-mode.md`:**
- Check for any `shared/` references (unlikely but verify)

---

## 📋 Test Case Recommendations

### Current State

**Existing test files:**
- `docs/plans/v6.0-deep-dive-test-cases.md` - General v6.0 test cases (95+ tests)
- Referenced in v6.0.1 context but covers all phases

### Recommendation 1: Consolidate Test Documentation

**Option A: Keep as-is**
- Single comprehensive test file covers all v6.0 features
- Easier to maintain (one source of truth)
- Risk: May become too large/unwieldy

**Option B: Split by phase** (RECOMMENDED)
- Create phase-specific test files:
  - `docs/plans/test-cases-phase-1.md` (Foundation)
  - `docs/plans/test-cases-phase-2.md` (Core Integration)
  - `docs/plans/test-cases-phase-3.md` (Router & Workflows)
  - `docs/plans/test-cases-phase-4.md` (Summary & Polish)
- Keep `v6.0-deep-dive-test-cases.md` as master reference
- Benefits: Easier to navigate, clearer ownership

### Recommendation 2: Test Case Coverage

**Current coverage (from v6.0-deep-dive-test-cases.md):**
- ✅ JD Parser: 22 test cases
- ✅ Skills Categorizer: 25 test cases
- ✅ Evidence Matcher: 16 test cases
- ✅ Router: 17 test cases
- ✅ Summary Generator: 8 test cases
- **Total: 95+ test cases**

**Missing coverage:**
- ⚠️ Phase 2 integration tests (Mode 1 → Mode 3 flow)
- ⚠️ Phase 3 incremental update edge cases
- ⚠️ Phase 3 re-comparison diff accuracy
- ⚠️ Phase 4 professional summary validation

### Recommendation 3: Should Opus Create Phase-Specific Tests?

**Question:** Should I ask Opus to create test cases for v6.0.2-6.0.4 to validate implementation?

**Analysis:**

**Pros:**
- ✅ Comprehensive validation of implementation vs plan
- ✅ Opus has context on original design intent
- ✅ Can identify gaps in current test coverage
- ✅ Phase-specific tests easier to maintain

**Cons:**
- ❌ May duplicate existing test cases
- ❌ Time investment (Opus needs context for each phase)
- ❌ v6.0 already implemented - retroactive testing less valuable

**RECOMMENDED APPROACH:**

**Option 1: Targeted Gap-Filling** (RECOMMENDED)
- Review existing `v6.0-deep-dive-test-cases.md`
- Identify gaps in Phase 2-4 coverage
- Ask Opus to create ONLY missing test cases
- Append to existing file or create supplements

**Option 2: Full Phase-Specific Test Suite**
- Ask Opus to create comprehensive test suites for each phase
- Use existing tests as baseline, expand with implementation details
- More thorough but time-intensive

**Option 3: Skip for now**
- v6.0 already released and documented
- Focus on v6.1+ testing when new features are added
- Use existing 95+ tests as sufficient coverage

**MY RECOMMENDATION:** **Option 1 - Targeted Gap-Filling**

**Action items:**
1. Read `v6.0-deep-dive-test-cases.md` to identify gaps
2. Create a "Test Coverage Gap Analysis" section
3. Request Opus to fill specific gaps:
   - Mode 1 → Mode 3 integration flow
   - Incremental update edge cases (add/edit/remove)
   - Re-comparison diff accuracy
   - Professional summary validation
4. Append new tests to existing file with clear section headers

---

## 🔄 Implementation Sequence

### Step 1: Rename & Update References (30 min)
1. Rename `shared/` → `phases/`
2. Update PROJECT-INSTRUCTIONS.md references (15-20 changes)
3. Update README.md, CHANGELOG.md, ROADMAP.md
4. Test: Search for any remaining `shared/` references

### Step 2: Archive Obsolete Files (15 min)
1. Create `docs/legacy/` directory structure
2. Move `/modes/` → `docs/legacy/modes-v5/`
3. Move `/wireframes/` → `docs/legacy/wireframes-v5/`
4. Move root obsolete files (CHANGELOG.md, ADD_REMOTE_WORK_LOGIC.md)
5. Move `phases/v5-legacy/` → `docs/legacy/shared-v5/`
6. Create `docs/legacy/README.md`

### Step 3: Create New Wireframes (60 min)
1. Create `/wireframes/` directory
2. Write `phase-1-foundation.md` (ASCII + Mermaid)
3. Write `phase-2-core-integration.md` (ASCII + Mermaid)
4. Write `phase-3-router-workflows.md` (ASCII + Mermaid)
5. Write `phase-4-summary-polish.md` (ASCII + Mermaid)
6. Write `complete-workflow.md` (end-to-end flow)

### Step 4: Documentation Updates (20 min)
1. Update CHANGELOG.md with v6.0.5 entry
2. Update ROADMAP.md with v6.0.5 entry
3. Verify all documentation links work

### Step 5: Git Operations (10 min)
1. Stage all changes
2. Commit with structured message
3. Push to origin

**Total estimated time:** ~2 hours

---

## ✅ Success Criteria

### Functional
- [ ] All `/shared/` references updated to `/phases/`
- [ ] No broken file paths in PROJECT-INSTRUCTIONS.md
- [ ] README.md file structure accurate
- [ ] All obsolete files archived (not deleted)

### Documentation
- [ ] 5 new wireframes created (ASCII + Mermaid)
- [ ] `docs/legacy/README.md` explains what's archived
- [ ] CHANGELOG.md v6.0.5 entry complete
- [ ] ROADMAP.md v6.0.5 entry complete

### Testing
- [ ] Test plan recommendation documented
- [ ] Gap analysis complete (if pursuing Option 1)

### Quality
- [ ] No duplicate files across legacy and active directories
- [ ] Clear separation: active (phases/), legacy (docs/legacy/), plans (docs/plans/)
- [ ] All inline version comments updated (v6.0.5)

---

## 📊 File Impact Summary

**Files to rename:** 1 directory (`shared/` → `phases/`)
**Files to move:** ~12 files (to `docs/legacy/`)
**Files to delete:** 1 file (root `CHANGELOG.md` duplicate)
**Files to create:** 6 files (5 wireframes + legacy README)
**Files to modify:** 5 files (PROJECT-INSTRUCTIONS.md, README.md, CHANGELOG.md, ROADMAP.md, quick-start-mode.md)

**Total changes:** ~25 file operations

---

## 🔍 Validation Steps

### Pre-Commit Checks
```bash
# 1. Search for remaining shared/ references
grep -r "shared/" --exclude-dir=".git" --exclude-dir="docs/legacy"

# 2. Verify phases/ references work
grep -r "phases/phase-1" PROJECT-INSTRUCTIONS.md

# 3. Check for duplicate files
find . -name "*.md" -type f | sort | uniq -d

# 4. Verify no broken symlinks
find . -type l ! -exec test -e {} \; -print
```

### Post-Commit Checks
```bash
# 1. Test PROJECT-INSTRUCTIONS.md loads in Claude
# (Manual: Copy to Claude Project, verify no errors)

# 2. Verify wireframes render on GitHub
# (Manual: Check wireframes/ directory on GitHub web)

# 3. Confirm legacy files preserved
ls -la docs/legacy/modes-v5/
ls -la docs/legacy/wireframes-v5/
```

---

## 📝 Commit Message Template

```
refactor(v6.0.5): documentation cleanup and structural reorganization

BREAKING CHANGES:
- Renamed /shared/ → /phases/ for clearer v6.0 architecture naming
- Moved v5.0 legacy files to /docs/legacy/ (modes, wireframes, prompts)
- Deleted duplicate root CHANGELOG.md (docs/CHANGELOG.md is canonical)

Added:
- 5 new v6.0 wireframes (ASCII + Mermaid) for each phase + complete workflow
- docs/legacy/ directory with organized v5.0 archival
- docs/legacy/README.md explaining archived content

Changed:
- Updated all references: shared/phase-X/ → phases/phase-X/
- PROJECT-INSTRUCTIONS.md: 15 path updates
- README.md: File structure diagram updated
- CHANGELOG.md: v6.0.5 entry added
- ROADMAP.md: v6.0.5 tracking added

Removed:
- /modes/ directory (moved to docs/legacy/modes-v5/)
- /wireframes/ directory (v5.0 wireframes moved to docs/legacy/wireframes-v5/)
- /shared/v5-legacy/ (moved to docs/legacy/shared-v5/)
- Root CHANGELOG.md (duplicate, outdated)
- ADD_REMOTE_WORK_LOGIC.md (v5.1 prompt, archived)

Impact:
- No functional changes - purely documentation and structure
- All v6.0 modules remain intact (phases/phase-1 through phase-4)
- Improved repository navigation and clarity
- Clear separation: active code vs legacy vs plans

🤖 Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
```

---

## 🚀 Next Steps (Post-v6.0.5)

### Immediate (v6.0.6 potential)
1. **Test case gap-filling** - Implement Recommendation Option 1
2. **Wireframe validation** - Get user feedback on ASCII vs Mermaid preference
3. **Legacy cleanup review** - Confirm nothing important was archived

### Future (v6.1.0+)
1. **Output specification templates** - From ROADMAP backlog
2. **Enhanced error messages (E001-E008)** - From ROADMAP
3. **Batch JD comparison** - From ROADMAP backlog

---

**Plan Status:** READY FOR EXECUTION
**Created:** 2025-12-29
**Next Step:** Execute Phase 1 (Rename & Update References)


# --- FILE: docs/plans/v6.1.0.md ---


# v6.1.0 - Documentation Enhancement & Structural Reorganization

**Version:** 6.1.0 (MINOR - New features + documentation enhancements)
**Branch:** `v6.1.0`
**Date:** 2025-12-29
**Type:** MINOR (New features: Job Summary documentation, enhanced wireframes, terminology consistency)

---

## 🎯 Overview

v6.1.0 introduces documentation enhancements, structural reorganization, and terminology consistency across the project. Unlike v6.0.5 (cleanup-only), this is a MINOR version bump because we're adding:
- **New feature documentation:** Job Summary usage guide
- **New wireframes:** 10 comprehensive visual guides (ASCII + Mermaid)
- **Enhanced test coverage:** Gap-filling test cases for Phases 2-4

---

## 📋 Sub-Version Strategy

Instead of one large v6.1.0 commit, we'll use semantic sub-versioning:

| Sub-Version | Focus | Files Modified | Plan Document |
|-------------|-------|----------------|---------------|
| **v6.1.1** | Folder restructure (`/shared/` → `/phases/`) | 5 files | `v6.1.1-folder-restructure.md` |
| **v6.1.2** | Documentation updates (README, CHANGELOG, ROADMAP) | 4 files | `v6.1.2-documentation-updates.md` |
| **v6.1.3** | Wireframe creation (10 new files) | 10 files | `v6.1.3-wireframes.md` |
| **v6.1.4** | Legacy archival (obsolete files cleanup) | ~12 files | `v6.1.4-legacy-archival.md` |
| **v6.1.5** | Test case gap-filling (Opus deliverable) | 1 file | `v6.1.5-test-gaps.md` |

Each sub-version gets:
- ✅ Its own plan document in `/docs/plans/`
- ✅ Its own git commit with conventional commit message
- ✅ ROADMAP tracking entry
- ✅ CHANGELOG entry (consolidated in v6.1.0 final release)

---

## 🗂️ Sub-Version Details

### v6.1.1 - Folder Restructure

**Goal:** Rename `/shared/` → `/phases/` for clearer architecture naming

**Changes:**
1. Rename directory: `mv shared/ phases/`
2. Update references in:
   - `PROJECT-INSTRUCTIONS.md` (~15 occurrences)
   - `README.md` (file structure tree)
   - `docs/CHANGELOG.md` (v6.0.0 entry)
   - `ROADMAP.md` (phase tracking)
   - `quick-start-mode.md` (if any references)

**Success Criteria:**
- [ ] All `shared/phase-X/` references changed to `phases/phase-X/`
- [ ] No broken file paths
- [ ] Search returns 0 results for `shared/phase-` (excluding docs/legacy)

**Estimated Time:** 30 minutes

---

### v6.1.2 - Documentation Updates

**Goal:** Update terminology (Mode → Phase) and add Job Summary feature documentation

**Changes:**

#### README.md Updates (28 occurrences)

**Section 1: Mode → Phase Terminology**
- Line 11-13: "Mode 1/2/3" → "Phase 1/2/3" (What This System Does)
- Line 30: "Makes Mode 3 much better" → "Makes Phase 3 much better"
- Line 65-67: Mode references in Claude instructions → Phase references
- Line 252, 257, 262: Tip section headers (Mode → Phase)
- Line 268: "After Mode 1 analyzes" → "After Phase 1 analyzes"
- Line 283-285: Troubleshooting section (Mode → Phase)
- Line 304: Section header "What Each Mode Does" → "What Each Phase Does"
- Line 306, 330, 347: Subsection headers (Mode → Phase)
- Line 378: "How to Use All Three Modes Together" → "How to Use All Three Phases Together"
- Line 382, 388, 393, 399: Workflow steps (Mode → Phase)
- Line 492: FAQ answer (Mode → Phase)

**Section 2: Job Summary Feature Documentation** (NEW)

Add new tip section after Line 271:

```markdown
### 5. **Use Job Summary Generation for Applications**
   - After Phase 3 analyzes a job description, ask: "Create a professional summary for this job"
   - The system generates TWO types of summaries:
     - **Master Summary:** Comprehensive overview of your entire career (stored in job history)
     - **Per-JD Summary:** Customized version optimized for the specific job posting (ephemeral)
   - **Use cases:**
     - Cover letters: Lead with the per-JD summary
     - LinkedIn applications: Paste customized summary in "Why are you interested?" section
     - Email applications: Include in the body to show tailored interest
   - **Pro tip:** The per-JD summary includes JD keywords for ATS optimization
```

**Section 3: Version Update**
- Line 407-408: Update version from 6.0.0 → 6.1.0
- Line 411: "What's New in v6.0" → "What's New in v6.1"
- Add v6.1.0 feature list:
  ```markdown
  ### What's New in v6.1:
  - **Enhanced Documentation** - Consistent phase terminology across all docs
  - **Job Summary Usage Guide** - Clear instructions for professional summary generation
  - **Visual Wireframes** - 10 comprehensive workflow diagrams (ASCII + Mermaid)
  - **Improved File Structure** - `/phases/` folder for clearer organization
  - **Expanded Test Coverage** - 30+ new test cases for Phases 2-4
  ```

#### CHANGELOG.md Update

Add v6.1.0 entry:

```markdown
### v6.1.0 - Documentation Enhancement & Job Summary Guide (2025-12-29)
> **Branch:** `v6.1.0`

#### Added
- **Job Summary Usage Guide** - New tip section in README explaining how to use professional summary generation
  - Master summary vs per-JD summary differences
  - Use cases (cover letters, LinkedIn, email applications)
  - ATS keyword optimization tip
- **Comprehensive Wireframes** - 10 visual workflow guides (5 ASCII + 5 Mermaid)
  - Phase 1: Foundation (job history creation, JD parser, entry router)
  - Phase 2: Core Integration (evidence matching, blocking gates)
  - Phase 3: Router & Workflows (8-scenario routing, incremental updates)
  - Phase 4: Summary & Polish (professional summary generation)
  - Complete Workflow: End-to-end user journey
- **Test Case Expansion** - 30+ new test cases for Phases 2-4
  - Integration flow tests (Phase 1 → Phase 3)
  - Incremental update edge cases
  - Re-comparison diff accuracy validation
  - Professional summary quality checks

#### Changed
- **Terminology Consistency** - "Mode 1/2/3" → "Phase 1/2/3" across all user-facing documentation
  - README.md: 28 occurrences updated
  - quick-start-mode.md: Updated to use phase terminology
  - Consistent with internal architecture (`/phases/` folder structure)
- **Folder Structure** - Renamed `/shared/` → `/phases/` for clearer naming
  - Updated all references in PROJECT-INSTRUCTIONS.md, README.md, CHANGELOG.md, ROADMAP.md
- **Version Numbering** - Updated README from v6.0.0 → v6.1.0

#### Removed
- **Obsolete v5.0 Files** - Archived to `/docs/legacy/`
  - `/modes/` directory → `/docs/legacy/modes-v5/`
  - `/wireframes/` (v5.0) → `/docs/legacy/wireframes-v5/`
  - `/phases/v5-legacy/` → `/docs/legacy/shared-v5/`
  - Root `CHANGELOG.md` (duplicate) → `/docs/legacy/CHANGELOG-v5.md`
  - `ADD_REMOTE_WORK_LOGIC.md` → `/docs/legacy/implementation-prompts/`

#### Impact
- ✅ Clearer user experience with consistent terminology
- ✅ Better onboarding with Job Summary usage guide
- ✅ Improved developer experience with visual wireframes
- ✅ Cleaner repository structure with legacy files archived
```

#### ROADMAP.md Update

Add v6.1.0 entry:

```markdown
### v6.1.0 - Documentation Enhancement (COMPLETE)
**Branch:** `v6.1.0` | **Status:** Complete | **Date:** 2025-12-29

**Sub-Versions:**
- [x] v6.1.1 - Folder restructure (`/shared/` → `/phases/`)
- [x] v6.1.2 - Documentation updates (terminology + Job Summary guide)
- [x] v6.1.3 - Wireframe creation (10 files)
- [x] v6.1.4 - Legacy archival
- [x] v6.1.5 - Test case gap-filling

**Features:**
- [x] Job Summary usage guide in README
- [x] Terminology consistency (Mode → Phase)
- [x] 10 comprehensive wireframes (ASCII + Mermaid)
- [x] 30+ new test cases for Phases 2-4
- [x] Legacy file archival to /docs/legacy/

**Notes:** Documentation-focused release improving user experience and developer onboarding.
```

**Success Criteria:**
- [ ] README has Job Summary tip section
- [ ] All 28 Mode→Phase references updated
- [ ] Version updated to 6.1.0
- [ ] CHANGELOG v6.1.0 entry complete
- [ ] ROADMAP v6.1.0 tracking added

**Estimated Time:** 45 minutes

---

### v6.1.3 - Wireframe Creation

**Goal:** Create 10 comprehensive visual workflow guides (5 ASCII + 5 Mermaid)

**Wireframe Structure:**

Each phase gets **2 files**:
1. `wireframes/phase-X-[name]-ascii.md` - ASCII diagram (terminal-friendly)
2. `wireframes/phase-X-[name]-mermaid.md` - Mermaid flowchart (GitHub-rendered)

**Files to Create:**

1. **Phase 1 - Foundation**
   - `wireframes/phase-1-foundation-ascii.md`
   - `wireframes/phase-1-foundation-mermaid.md`
   - Content: job history creation creation, JD parsing, entry router

2. **Phase 2 - Core Integration**
   - `wireframes/phase-2-core-integration-ascii.md`
   - `wireframes/phase-2-core-integration-mermaid.md`
   - Content: Evidence matching flow, blocking gates logic, Mode enhancements

3. **Phase 3 - Router & Workflows**
   - `wireframes/phase-3-router-workflows-ascii.md`
   - `wireframes/phase-3-router-workflows-mermaid.md`
   - Content: 8-scenario routing, incremental updates, JD re-comparison

4. **Phase 4 - Summary & Polish**
   - `wireframes/phase-4-summary-polish-ascii.md`
   - `wireframes/phase-4-summary-polish-mermaid.md`
   - Content: Master summary generation, per-JD customization

5. **Complete Workflow**
   - `wireframes/complete-workflow-ascii.md`
   - `wireframes/complete-workflow-mermaid.md`
   - Content: End-to-end user journey (entry → routing → execution → output)

**Wireframe Template:**

Each file follows this structure:

```markdown
# [Phase Name] - [ASCII/Mermaid]

**Version:** 1.0
**Last Updated:** 2025-12-29
**Related Modules:** `phases/phase-X/`

---

## Overview
[Brief description of what this phase does]

## Diagram

[ASCII art or Mermaid code here]

## Key Decision Points
- [Branching logic 1]
- [Branching logic 2]

## Inputs
- [Required data/files]

## Outputs
- [What gets generated/modified]

## Files Involved
- `phases/phase-X/[module].md`

## Related Phases
- **Previous:** [Link to previous phase]
- **Next:** [Link to next phase]
```

**Success Criteria:**
- [ ] 10 wireframe files created (5 ASCII + 5 Mermaid)
- [ ] All diagrams render correctly (ASCII in terminal, Mermaid on GitHub)
- [ ] Each wireframe has overview, diagram, inputs, outputs, files
- [ ] Cross-references between phases working

**Estimated Time:** 90 minutes

---

### v6.1.4 - Legacy Archival

**Goal:** Archive obsolete v5.0 files to `/docs/legacy/`

**Directory Structure:**

```
docs/legacy/
├── README.md                           ← Explains what's archived and why
├── modes-v5/
│   ├── mode-1-full-analysis.md
│   ├── mode-2-bullet-optimization.md
│   └── mode-3-jd-comparison.md
├── wireframes-v5/
│   ├── mode-1-workflow.md
│   ├── mode-2-workflow.md
│   └── mode-3-workflow.md
├── shared-v5/
│   ├── initial-greeting.md
│   └── job-summary-creation.md
├── implementation-prompts/
│   └── ADD_REMOTE_WORK_LOGIC.md
└── CHANGELOG-v5.md                     ← Root CHANGELOG.md (duplicate)
```

**File Operations:**

```bash
# Create legacy directory structure
mkdir -p docs/legacy/{modes-v5,wireframes-v5,shared-v5,implementation-prompts}

# Move modes (v5.0 - not referenced)
mv modes/mode-1-full-analysis.md docs/legacy/modes-v5/
mv modes/mode-2-bullet-optimization.md docs/legacy/modes-v5/
mv modes/mode-3-jd-comparison.md docs/legacy/modes-v5/
rmdir modes/

# Move wireframes (v5.0 - outdated)
mv wireframes/mode-1-workflow.md docs/legacy/wireframes-v5/
mv wireframes/mode-2-workflow.md docs/legacy/wireframes-v5/
mv wireframes/mode-3-workflow.md docs/legacy/wireframes-v5/
rmdir wireframes/  # Will be recreated with v6.1 wireframes

# Move shared v5-legacy
mv phases/v5-legacy/initial-greeting.md docs/legacy/shared-v5/
mv phases/v5-legacy/job-summary-creation.md docs/legacy/shared-v5/
rmdir phases/v5-legacy/

# Move root obsolete files
mv CHANGELOG.md docs/legacy/CHANGELOG-v5.md
mv ADD_REMOTE_WORK_LOGIC.md docs/legacy/implementation-prompts/

# Move Opus handoff (temporary artifact)
mv phases/opus-handoff.md docs/plans/archive/opus-handoff.md
```

**Create Legacy README:**

`docs/legacy/README.md`:

```markdown
# Legacy Files Archive

This directory contains v5.0 files that have been superseded by v6.0+ architecture.

**Last Updated:** 2025-12-29 (v6.1.4)

---

## What's Here

### `/modes-v5/` - v5.0 Mode Definitions
Original mode files from v5.0 release. Superseded by `/phases/` modular architecture in v6.0.

**Files:**
- `mode-1-full-analysis.md` - Full resume analysis (v5.0)
- `mode-2-bullet-optimization.md` - Bullet optimization (v5.0)
- `mode-3-jd-comparison.md` - JD comparison (v5.0)

**Replaced by:**
- `/phases/phase-1/` - job history creation, JD parser, entry router (v6.0.1)
- `/phases/phase-2/` - Evidence matching, blocking gates (v6.0.2)
- `/phases/phase-3/` - Workflow router, incremental updates (v6.0.3)
- `/phases/phase-4/` - Summary generation (v6.0.4)

---

### `/wireframes-v5/` - v5.0 Visual Diagrams
Original workflow wireframes from v5.0. Replaced by comprehensive ASCII + Mermaid diagrams in v6.1.3.

**Files:**
- `mode-1-workflow.md` - Full analysis wireframe (v5.0)
- `mode-2-workflow.md` - Bullet optimization wireframe (v5.0)
- `mode-3-workflow.md` - JD comparison wireframe (v5.0)

**Replaced by:** `/wireframes/` (v6.1.3)
- 10 files: 5 ASCII + 5 Mermaid (phase-1 through phase-4 + complete workflow)

---

### `/shared-v5/` - v5.0 Shared Components
Legacy shared components from v5.0, pre-modular architecture.

**Files:**
- `initial-greeting.md` - User greeting template (v5.0)
- `job-summary-creation.md` - Job summary generator (v5.0)

**Replaced by:**
- `/phases/phase-1/entry-router.md` - Handles greetings via routing (v6.0.1)
- `/phases/phase-4/summary-generation.md` - Professional summary (v6.0.4)

---

### `/implementation-prompts/` - One-Time Implementation Prompts
Terminal prompts used for implementing specific features. No longer needed after implementation.

**Files:**
- `ADD_REMOTE_WORK_LOGIC.md` - v5.1 remote work classification implementation prompt

**Status:** Feature implemented in v5.1, integrated into v6.0 system

---

### `CHANGELOG-v5.md` - Outdated Changelog
Root-level changelog from v5.0 (duplicate of `docs/CHANGELOG.md`).

**Why archived:**
- Duplicate file (canonical version is `docs/CHANGELOG.md`)
- Last updated Dec 27, 2024 (stops at v5.0)
- Superseded by comprehensive v6.0 changelog

**Current changelog:** `docs/CHANGELOG.md` (v6.0.0+)

---

## Why Archive Instead of Delete?

These files provide historical context for:
1. **Understanding evolution** - How v5.0 architecture evolved to v6.0
2. **Migration reference** - For users with v5.0 job history files
3. **Design decisions** - Why certain approaches were replaced
4. **Rollback capability** - If needed to reference v5.0 implementation

---

## Related Documentation

- **Current Architecture:** See `PROJECT-INSTRUCTIONS.md` (v6.0.0)
- **Version History:** See `docs/CHANGELOG.md`
- **Roadmap:** See `ROADMAP.md`
- **Plans:** See `docs/plans/v6.*.md`
```

**Success Criteria:**
- [ ] All obsolete files moved to `/docs/legacy/`
- [ ] Legacy README created explaining archival
- [ ] No duplicate files in active directories
- [ ] Original directories removed (modes/, old wireframes/)

**Estimated Time:** 20 minutes

---

### v6.1.5 - Test Case Gap-Filling

**Goal:** Create test cases for Phases 2-4 to supplement existing Phase 1 coverage

**Background:**
- Existing: `v6.0-deep-dive-test-cases.md` (95+ tests, mostly Phase 1)
- Missing: Integration tests, incremental updates, re-comparison, summary validation

**Deliverable:** Plan for Opus to create 30+ new test cases

---

## 📄 OPUS TEST PLAN (Copy this section to give to Opus)

```markdown
# Test Case Gap-Filling for v6.0 Phases 2-4

**Goal:** Create test cases for Phases 2-4 to supplement the existing 95+ test cases in `v6.0-deep-dive-test-cases.md`

**Context:**
- v6.0 is fully implemented across 4 phases
- Existing test file covers Phase 1 comprehensively (JD parser, skills categorizer, router basics)
- Gaps exist in Phase 2-4 integration flows and edge cases

---

## Test Coverage Gaps Identified

### Gap 1: Phase 2 Integration Flow (Mode 1 → Mode 3)
**Missing:** End-to-end integration tests validating data flow from job history creation to evidence matching

**Required Test Cases (~8 tests):**

1. **INT-001:** User runs Phase 1 (creates job history creation) → immediately runs Phase 3 (JD comparison)
   - **Validate:** job history creation job history loads correctly, hard/soft skills separated, evidence citations use proper format
   - **Expected:** All 12 job history sections accessible, no null reference errors

2. **INT-002:** User has v1.0 job history → runs Phase 3 (backward compatibility)
   - **Validate:** Phase 3 loads v1.0 format, suggests upgrade, still functions
   - **Expected:** Evidence matching works with combined skills_demonstrated array

3. **INT-003:** Phase 1 creates job history with missing sections (no education/certifications)
   - **Validate:** Phase 3 handles null sections gracefully
   - **Expected:** Evidence matcher doesn't fail, marks education/certification requirements as MISSING

4. **INT-004:** Job history has duplicate skills across positions (e.g., "Python" in 3 roles)
   - **Validate:** Evidence citations list all occurrences
   - **Expected:** Multiple citations: "Python mentioned in: Position 1, Position 2, Position 3"

5. **INT-005:** Phase 1 creates job history with overlapping dates (moonlighting scenario)
   - **Validate:** Evidence matcher doesn't double-count years of experience
   - **Expected:** Conservative aggregate calculation, note overlap in citations

6. **INT-006:** JD requirement matches achievement but not explicit skill listing
   - **Validate:** Evidence matcher infers skill from achievement context
   - **Expected:** Status = INFERRED, citation = achievement quote, confidence score documented

7. **INT-007:** JD has "Required" and "Preferred" skills → job history matches some of each
   - **Validate:** Evidence matcher weights Required > Preferred in scoring
   - **Expected:** Missing Required skill impacts score more than missing Preferred

8. **INT-008:** Blocking gates trigger (hard skill deficit, low match score, location mismatch)
   - **Validate:** User can override each gate, system continues after "yes" confirmation
   - **Expected:** Override logged, recommendations still generated with warning

---

### Gap 2: Phase 3 Incremental Updates
**Missing:** Edge case tests for add/edit/remove position operations

**Required Test Cases (~10 tests):**

1. **INC-001:** User adds new position to job history (most recent role)
   - **Validate:** Position inserted chronologically (Position 1), indices shifted
   - **Expected:** Previous Position 1 becomes Position 2, aggregates recalculated

2. **INC-002:** User adds position in the middle (not most recent)
   - **Validate:** Correct chronological insertion, indices recalculated
   - **Expected:** If dates are 2015-2017, inserted between 2018 and 2014 positions

3. **INC-003:** User edits existing position (updates achievements)
   - **Validate:** Only target position modified, others unchanged
   - **Expected:** Version comment added, aggregates recalculated if metrics changed

4. **INC-004:** User removes position from job history
   - **Validate:** Position deleted, indices recalculated, aggregates updated
   - **Expected:** Years of experience reduced, skills from removed position excluded from aggregates

5. **INC-005:** User adds position with no hard skills
   - **Validate:** hard_skills_demonstrated = empty array, not null
   - **Expected:** Schema validation passes, evidence matcher handles gracefully

6. **INC-006:** User edits position dates (extending duration)
   - **Validate:** Aggregate years of experience recalculated
   - **Expected:** If original 2020-2022 (2 years) → 2020-2023 (3 years), total +1 year

7. **INC-007:** User adds position with company that already exists in history
   - **Validate:** Both positions preserved, evidence citations disambiguate
   - **Expected:** "Google | Software Engineer (2018-2020)" vs "Google | Senior SWE (2020-2022)"

8. **INC-008:** User removes last remaining position
   - **Validate:** System warns before deletion
   - **Expected:** "This will delete your entire job history. Confirm?"

9. **INC-009:** User adds position with future start date (error case)
   - **Validate:** Date validation catches error
   - **Expected:** "Start date cannot be in the future. Please verify dates."

10. **INC-010:** User adds position while Phase 3 comparison is in progress
    - **Validate:** System handles concurrent operations
    - **Expected:** Either queue update or prompt user to wait for comparison to complete

---

### Gap 3: Phase 3 Re-Comparison with Diff Output
**Missing:** Diff accuracy validation tests

**Required Test Cases (~7 tests):**

1. **DIFF-001:** User updates job history (adds Python skill) → re-runs previous JD comparison
   - **Validate:** Diff shows: "Python: MISSING → MATCHED"
   - **Expected:** Improvements section lists Python with before/after status

2. **DIFF-002:** User re-runs comparison without any job history changes
   - **Validate:** Diff shows "No changes detected"
   - **Expected:** All requirements maintain same status (MATCHED stays MATCHED, MISSING stays MISSING)

3. **DIFF-003:** Score delta calculation accuracy
   - **Validate:** Previous score 72%, new score 81% → delta = +9 points
   - **Expected:** Diff output: "Overall Match: 72% → 81% (+9 points improvement)"

4. **DIFF-004:** User updates job history but removes a previously matched skill
   - **Validate:** Diff shows regression: "SQL: MATCHED → PARTIAL" (if still partially present)
   - **Expected:** Regressions section lists SQL with explanation

5. **DIFF-005:** JD cached version mismatch (cache is v1, current schema is v2)
   - **Validate:** System detects version mismatch, re-parses JD
   - **Expected:** Warning: "Cached JD uses outdated schema. Re-parsing..."

6. **DIFF-006:** User runs re-comparison with different job history version (v1.0 → job history creation upgrade)
   - **Validate:** Diff handles schema change gracefully
   - **Expected:** Note: "Job history upgraded from v1.0 to job history creation. Hard/soft skills now separated."

7. **DIFF-007:** User deletes cached JD → tries to re-compare
   - **Validate:** System detects missing cache, prompts for JD re-upload
   - **Expected:** "Cached JD not found. Please paste the job description again."

---

### Gap 4: Phase 4 Professional Summary Validation
**Missing:** Summary quality and accuracy tests

**Required Test Cases (~7 tests):**

1. **SUM-001:** Master summary generation from complete job history (3 positions)
   - **Validate:** 3-4 sentences, includes aggregates (total years, companies, team sizes)
   - **Expected:** "Senior PM with 8 years across Google, Amazon, Startup. Led 15+ product launches..."

2. **SUM-002:** Master summary from single position
   - **Validate:** Adjusts phrasing to avoid "across X companies"
   - **Expected:** "Senior PM with 3 years at Google. Led 5 product launches..."

3. **SUM-003:** Per-JD summary customization (JD requires Python, AWS, Kubernetes)
   - **Validate:** Replaces generic hard skills with JD-specific keywords
   - **Expected:** Original: "Expert in Agile, SQL, JavaScript" → Customized: "Expert in Python, AWS, Kubernetes"

4. **SUM-004:** Summary generation with no quantified metrics in job history
   - **Validate:** Omits metrics sentence gracefully
   - **Expected:** "Senior PM with 5 years at TechCorp. Led cross-functional teams. Expert in..."

5. **SUM-005:** Per-JD summary when match score < 50
   - **Validate:** System doesn't offer per-JD summary (low fit job)
   - **Expected:** Only master summary provided, no customization offered

6. **SUM-006:** Summary exceeds 350 character limit
   - **Validate:** Truncates intelligently at sentence boundary
   - **Expected:** Last incomplete sentence removed, ends with period

7. **SUM-007:** User has career change (unrelated positions: Teacher → Software Engineer)
   - **Validate:** Summary emphasizes transferable skills
   - **Expected:** "Career transitioned from education to software engineering. 3 years teaching..."

---

## Test File Structure Recommendation

**Option A: Append to Existing File** (RECOMMENDED)
Add new sections to `v6.0-deep-dive-test-cases.md`:

```markdown
## PART 10: Phase 2 Integration Flow Tests (8 tests)
[INT-001 through INT-008]

## PART 11: Phase 3 Incremental Update Tests (10 tests)
[INC-001 through INC-010]

## PART 12: Phase 3 Re-Comparison Diff Tests (7 tests)
[DIFF-001 through DIFF-007]

## PART 13: Phase 4 Professional Summary Tests (7 tests)
[SUM-001 through SUM-007]
```

**Option B: Create Separate Phase Files**
Create new files:
- `test-cases-phase-2-integration.md` (8 tests)
- `test-cases-phase-3-workflows.md` (17 tests)
- `test-cases-phase-4-summaries.md` (7 tests)

---

## Deliverable Format

For each test case, provide:

```markdown
| Test ID | Scenario | Input | Expected Output | Validation Rule |
|---------|----------|-------|-----------------|-----------------|
| [ID] | [Description] | [What user provides] | [What system should do] | [How to verify correctness] |
```

**Example:**

| Test ID | Scenario | Input | Expected Output | Validation Rule |
|---------|----------|-------|-----------------|-----------------|
| INT-001 | Phase 1 → Phase 3 integration | job history creation + JD | Evidence citations with proper format | Check: "Company \| Job Title" format, no "Resume -" prefix |

---

## Success Criteria

- [ ] 32 new test cases created (8 + 10 + 7 + 7)
- [ ] Each test has: ID, scenario, input, expected output, validation rule
- [ ] Tests integrated into existing test documentation (appended to `v6.0-deep-dive-test-cases.md` or separate files)
- [ ] Test IDs follow naming convention (INT-XXX, INC-XXX, DIFF-XXX, SUM-XXX)
- [ ] Total test coverage: 127+ tests (95 existing + 32 new)

---

## Additional Context for Opus

**Existing Test Coverage (v6.0-deep-dive-test-cases.md):**
- JD Parser: 22 tests (missing fields, location, salary)
- Skills Categorizer: 25 tests (ambiguous skills, multi-meaning)
- Evidence Matcher: 16 tests (citations, confidence) - PARTIAL, needs integration tests
- Router: 17 tests (intent, state recovery)
- Summary Generator: 8 tests (edge cases) - PARTIAL, needs quality validation

**Phase Implementation Details:**
- **Phase 1 (v6.0.1):** job history creation, JD parsing protocol, entry router
- **Phase 2 (v6.0.2):** Evidence matching with citations, blocking gates
- **Phase 3 (v6.0.3):** Workflow router, incremental updates, re-comparison
- **Phase 4 (v6.0.4):** Professional summary (master + per-JD)

**Files to Reference:**
- `phases/phase-2/evidence-matching.md` - Evidence matching logic
- `phases/phase-3/incremental-updates.md` - Add/edit/remove operations
- `phases/phase-3/re-comparison.md` - Diff calculation logic
- `phases/phase-4/summary-generation.md` - Summary templates

---

**Estimated Completion Time:** 45-60 minutes
```

---

## 🔄 Execution Sequence

### Step 1: v6.1.1 - Folder Restructure (30 min)
1. Rename `shared/` → `phases/`
2. Update references in 5 files
3. Search for remaining `shared/` references
4. Commit: `refactor(v6.1.1): rename /shared/ to /phases/ for clarity`

### Step 2: v6.1.2 - Documentation Updates (45 min)
1. Update README.md (28 Mode→Phase changes + Job Summary tip)
2. Add CHANGELOG v6.1.0 entry
3. Add ROADMAP v6.1.0 entry
4. Commit: `docs(v6.1.2): terminology consistency and Job Summary guide`

### Step 3: v6.1.3 - Wireframe Creation (90 min)
1. Create `/wireframes/` directory
2. Write 10 wireframe files (5 ASCII + 5 Mermaid)
3. Test rendering (ASCII in terminal, Mermaid on GitHub)
4. Commit: `docs(v6.1.3): add comprehensive visual wireframes for all phases`

### Step 4: v6.1.4 - Legacy Archival (20 min)
1. Create `/docs/legacy/` structure
2. Move obsolete files
3. Create legacy README
4. Commit: `chore(v6.1.4): archive v5.0 legacy files to docs/legacy`

### Step 5: v6.1.5 - Test Case Gap-Filling (Opus)
1. Provide Opus with test plan (from section above)
2. Review Opus deliverable (32 new test cases)
3. Integrate into test documentation
4. Commit: `test(v6.1.5): add 32 test cases for Phases 2-4 integration`

**Total estimated time:** ~3 hours (excluding Opus work)

---

## ✅ Success Criteria

### Functional
- [ ] All `/shared/` references updated to `/phases/`
- [ ] README has Job Summary usage guide
- [ ] 28 Mode→Phase terminology updates complete
- [ ] 10 wireframe files created and rendering correctly
- [ ] All legacy files archived to `/docs/legacy/`
- [ ] No broken file paths or duplicate files

### Documentation
- [ ] CHANGELOG v6.1.0 entry complete with all sub-versions
- [ ] ROADMAP v6.1.0 tracking entry added
- [ ] Legacy README explains what's archived and why
- [ ] Version updated to 6.1.0 in README

### Testing
- [ ] Test plan provided to Opus
- [ ] 32 new test cases created by Opus
- [ ] Test cases integrated into documentation
- [ ] Total coverage: 127+ tests

### Quality
- [ ] Each sub-version has its own plan document
- [ ] Each commit uses conventional commit format
- [ ] Inline version comments added (v6.1.X)
- [ ] All files pass validation checks

---

## 📊 Impact Summary

**Files to rename:** 1 directory (`shared/` → `phases/`)
**Files to create:** 17 files (10 wireframes + 5 plans + 1 legacy README + 1 test doc)
**Files to modify:** 5 files (README, CHANGELOG, ROADMAP, PROJECT-INSTRUCTIONS, quick-start-mode)
**Files to move:** ~12 files (to `/docs/legacy/`)
**Files to delete:** 1 file (root `CHANGELOG.md` duplicate)

**Total changes:** ~36 file operations

---

## 🚀 Next Steps (Post-v6.1.0)

### v6.1.1+ (Future patches)
- User feedback on wireframe clarity
- Additional test cases if gaps found
- Quick-start-mode.md terminology updates

### v6.2.0+ (Future features)
- Output specification templates (from ROADMAP)
- Enhanced error messages (E001-E008)
- Batch JD comparison

---

**Plan Status:** READY FOR USER APPROVAL
**Created:** 2025-12-29
**Next Step:** Get user confirmation, then execute v6.1.1




# --- FILE: docs/plans/v6.1.7-gemini-grammar-tips.md ---


# implementation_plan.md - v6.1.7 Gemini Grammar Tips

This plan outlines the integration of Quality Assurance rules for grammar, consistency, and variation into the Optimize-My-Resume system instructions. These rules aim to improve the quality, readability, and ATS-friendliness of generated resume content.

## User Review Required

> [!IMPORTANT]
> This update adds a new `<quality_assurance_rules>` section to the system instructions, which will increase the token count of the prompt but significantly improve output quality.

## Proposed Changes

### Core Configuration and Documentation

#### [MODIFY] [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md)
- Insert the `<quality_assurance_rules>` section (including `phrase_variation_rule`, `symbol_consistency_rule`, `verb_tense_rule`, `keyword_diversity_rule`, and `pre_output_quality_checklist`) between `<critical_formatting_rules>` and `<character_limits>`.

#### [MODIFY] [quick-start-phase.md](quick-start-phase.md)
- Mirror the changes from `PROJECT-INSTRUCTIONS.md` to ensure the single-file version is up to date.

#### [MODIFY] [format-rules.md](core/format-rules.md)
- Add a new section "Quality Assurance Rules" to document these standards in the core configuration folder.

#### [MODIFY] [CHANGELOG.md](docs/CHANGELOG.md)
- Add v6.1.6 entry describing the new grammar and quality assurance rules.

#### [MODIFY] [ROADMAP.md](ROADMAP.md)
- Mark v6.1.6 as complete (once implemented).

## Verification Plan

### Manual Verification
- Verify that the new section is correctly placed in `PROJECT-INSTRUCTIONS.md` and `quick-start-phase.md`.
- Ensure no XML tags are broken during insertion.
- Check that `core/format-rules.md` accurately reflects the new rules.


# --- FILE: docs/plans/v6.1.8-location_red_flag_update.md ---


# v6.1.8 - Location Red Flag Update (Remote Payroll Restrictions)

**Branch:** `v6.1.8-location_red_flag_update`
**Date:** 2025-12-30
**Type:** PATCH (Enhancement to existing blocking gate logic)
**Parent:** v6.1.7-gemini-grammar-tips

---

## 🎯 Goal

Add remote payroll restrictions to the `<location_red_flags>` section to warn users when job descriptions specify state-specific remote work limitations due to payroll compliance.

**Business Context:**
Many companies limit remote work to specific states where they have payroll tax registrations. This is a critical blocking factor that users need to know upfront before investing time in applications.

---

## 📋 Current State Analysis

### Files Containing `location_red_flags`

**Active Implementation:**
- `PROJECT-INSTRUCTIONS.md` (Line 337-344)
  - Used in Phase 1 JD parsing step
  - Part of requirement categorization logic
  - Feeds into blocking gates in Phase 2

**Legacy Files (v5.0):**
- `docs/legacy/modes-v5/mode-3-jd-comparison.md`
- `docs/legacy/implementation-prompts/ADD_REMOTE_WORK_LOGIC.md`

### Current `location_red_flags` Content

```xml
<location_red_flags priority="critical">
  - "Must be located in [specific state/city]" when user is elsewhere
  - "On-site required" when user seeks remote
  - "Hybrid X days/week" when user seeks fully remote
  - "Remote - [state] residents only" when user is in different state
  - "Relocation required" without relocation assistance mentioned
  - "Fake remote" indicators: "Remote during training, then on-site", "Remote but must come to office weekly"
</location_red_flags>
```

### Gap Identified

**Missing:** Explicit detection of payroll restriction language like:
- "The following states are not approved for remote payroll at this time: [list]"
- "Remote work only available in: CA, NY, TX, FL"
- "Payroll compliance restricts remote work to certain states"
- "We are unable to support remote employees in: [states]"

**Impact:** Users may waste time on applications for roles where they're ineligible due to location, even though the role is "remote."

---

## 🛠️ Proposed Changes

### Change 1: Update `PROJECT-INSTRUCTIONS.md`

**Location:** Lines 337-344 (inside `<categorization>` within Step 1 of JD parsing)

**Current Text:**
```xml
<location_red_flags priority="critical">
  - "Must be located in [specific state/city]" when user is elsewhere
  - "On-site required" when user seeks remote
  - "Hybrid X days/week" when user seeks fully remote
  - "Remote - [state] residents only" when user is in different state
  - "Relocation required" without relocation assistance mentioned
  - "Fake remote" indicators: "Remote during training, then on-site", "Remote but must come to office weekly"
</location_red_flags>
```

**New Text:**
```xml
<location_red_flags priority="critical">
  - "Must be located in [specific state/city]" when user is elsewhere
  - "The following states are not approved for remote payroll at this time: [list]" when user's state is excluded
  - "On-site required" when user seeks remote
  - "Hybrid X days/week" when user seeks fully remote
  - "Remote - [state] residents only" when user is in different state
  - "Relocation required" without relocation assistance mentioned
  - "Fake remote" indicators: "Remote during training, then on-site", "Remote but must come to office weekly"
</location_red_flags>
```

**Rationale:**
- Inserted after "Must be located in [specific state/city]" because both are absolute location restrictions
- Placed before work arrangement flags (on-site, hybrid) to group by restriction type
- Uses explicit "not approved for remote payroll" language to distinguish from general state residency requirements

---

### Change 2: Add State Abbreviation Mapping

**Location:** After `</location_red_flags>` (new section in categorization)

**New Section Added:**
```xml
<state_abbreviation_mapping>
  <instruction>When location requirements contain state abbreviations (e.g., "AL, AK, MT"), expand them to full state names for clarity in output.</instruction>
  <usage>
    - When parsing payroll restrictions: "States: AL, AK, MT" → "Alabama, Alaska, Montana"
    - When displaying location warnings: Show both formats - "Excluded states: Alabama (AL), Alaska (AK), Montana (MT)"
    - Apply to all location-related parsing: remote restrictions, residency requirements, excluded states
  </usage>
  <mapping>
    AL=Alabama, AK=Alaska, AZ=Arizona, AR=Arkansas, CA=California, CO=Colorado, CT=Connecticut,
    DE=Delaware, FL=Florida, GA=Georgia, HI=Hawaii, ID=Idaho, IL=Illinois, IN=Indiana, IA=Iowa,
    KS=Kansas, KY=Kentucky, LA=Louisiana, ME=Maine, MD=Maryland, MA=Massachusetts, MI=Michigan,
    MN=Minnesota, MS=Mississippi, MO=Missouri, MT=Montana, NE=Nebraska, NV=Nevada, NH=New Hampshire,
    NJ=New Jersey, NM=New Mexico, NY=New York, NC=North Carolina, ND=North Dakota, OH=Ohio,
    OK=Oklahoma, OR=Oregon, PA=Pennsylvania, RI=Rhode Island, SC=South Carolina, SD=South Dakota,
    TN=Tennessee, TX=Texas, UT=Utah, VT=Vermont, VA=Virginia, WA=Washington, WV=West Virginia,
    WI=Wisconsin, WY=Wyoming, DC=District of Columbia
  </mapping>
</state_abbreviation_mapping>
```

**Also Updated:** `location_mismatch` instruction (line ~378) to reference state abbreviation mapping

**Rationale:**
- Improves user experience by showing full state names instead of abbreviations
- Reduces confusion for users unfamiliar with all state codes
- Maintains both formats (full name + abbreviation) for clarity
- Applies universally to all location parsing (not just payroll restrictions)

---

## 📊 Impact Analysis

### Files Affected

| File | Lines | Change Type | Risk Level |
|------|-------|-------------|------------|
| PROJECT-INSTRUCTIONS.md | 337-380 | Add 1 bullet + state mapping section + enhanced location_mismatch | Low |

**Total Changes:** 1 file, ~25 lines added

### Backward Compatibility

✅ **No breaking changes**
- Additive change only (new bullet point)
- Existing logic continues to work
- No schema changes required
- No version bump needed for job history or JD cache

### User-Facing Impact

**Before:**
User might miss payroll restrictions buried in JD text, apply for role, get rejected after interview due to location.

**After (with state abbreviation expansion):**
User sees explicit warning during Phase 1 JD parsing with expanded state names:
```
⚠️ LOCATION RED FLAG DETECTED:
"The following states are not approved for remote payroll at this time:"
Excluded states: Alabama (AL), Alaska (AK), Montana (MT), Wyoming (WY)

This role is remote but restricted to specific states due to payroll compliance.
Verify your state is approved before proceeding.
```

**Improvement:** State abbreviations are automatically expanded to full names, making it easier for users to quickly identify if their state is excluded without needing to look up state codes.

### Blocking Gates Logic

**No changes required** to blocking gate implementation (Phase 2: `evidence-matching.md` line 396).

The location blocking gate already checks for location mismatches. This change improves **detection accuracy** of payroll restrictions during JD parsing, which then feeds into the existing gate.

---

## ✅ Success Criteria

### Functional Requirements

- [ ] `location_red_flags` updated with payroll restriction bullet
- [ ] New bullet placed in logical order (after general location, before work arrangement)
- [ ] Inline version comment added: `<!-- v6.1.8 Change: Added payroll restriction detection -->`
- [ ] No syntax errors in XML structure
- [ ] Search confirms only 1 active `location_red_flags` block exists

### Documentation Requirements

- [ ] ROADMAP.md updated with v6.1.8 entry
- [ ] CHANGELOG.md updated (or CHANGELOG_DEV.md if dev-facing only)
- [ ] Commit message follows conventional commit format

### Testing Requirements

- [ ] Manual verification: Paste a JD with payroll restrictions, confirm detection
- [ ] Grep search confirms no duplicate `location_red_flags` blocks
- [ ] Git diff shows only intended changes

---

## 🧪 Test Case

### Test JD Snippet (with payroll restriction)

```
About the Role:
We're hiring a Senior Product Manager to lead our SaaS platform. This is a remote position.

Location Requirements:
The following states are not approved for remote payroll at this time: Alabama, Alaska, Montana, North Dakota, South Dakota, Vermont, West Virginia, Wyoming.

Requirements:
- 5+ years PM experience
- ...
```

### Expected Behavior

**Phase 1 JD Parsing Output:**

```xml
<categorization>
  <location_red_flags priority="critical">
    ⚠️ DETECTED: "The following states are not approved for remote payroll at this time: AL, AK, MT, ND, SD, VT, WV, WY"
  </location_red_flags>
</categorization>
```

**Phase 2 Blocking Gate Output:**

```
========================================
BLOCKING GATES CHECK
========================================

✓ Hard Skill Deficit: PASS
✓ Match Score: PASS
⚠️ Location: WARNING (payroll restriction detected)

WARNING: This role has state-specific payroll restrictions.
Excluded states: AL, AK, MT, ND, SD, VT, WV, WY

If you are in one of these states, do not proceed with application.
```

---

## 🔍 Validation Steps

### Pre-Implementation Checklist

```bash
# 1. Verify current line numbers
grep -n "location_red_flags" PROJECT-INSTRUCTIONS.md

# 2. Verify XML structure is valid
# (Manual: Check opening/closing tags match)

# 3. Backup current state
git stash  # if uncommitted changes exist
```

### Post-Implementation Checklist

```bash
# 1. Verify change applied correctly
git diff PROJECT-INSTRUCTIONS.md

# 2. Search for duplicate location_red_flags blocks
grep -c "<location_red_flags" PROJECT-INSTRUCTIONS.md
# Expected output: 1 (only one block in active files)

# 3. Verify XML structure remains valid
# (Manual: Check all tags properly closed)

# 4. Test with sample JD (manual)
# Paste JD with payroll restriction, verify detection
```

---

## 📝 Implementation Steps

### Step 1: Update PROJECT-INSTRUCTIONS.md

**Part A: Add payroll restriction detection**
1. Open `PROJECT-INSTRUCTIONS.md`
2. Navigate to line 337-344 (`<location_red_flags>` block)
3. Add new bullet after line 338 ("Must be located in [specific state/city]"):
   ```xml
   - "The following states are not approved for remote payroll at this time: [list]" when user's state is excluded
   ```
4. Add inline comment above the new line:
   ```xml
   <!-- v6.1.8 Change: Added payroll restriction detection -->
   ```

**Part B: Add state abbreviation mapping**
5. After `</location_red_flags>` closing tag, add new section:
   ```xml
   <!-- v6.1.8 Enhancement: State abbreviation expansion for payroll restrictions -->
   <state_abbreviation_mapping>
     <instruction>When location requirements contain state abbreviations (e.g., "AL, AK, MT"), expand them to full state names for clarity in output.</instruction>
     <usage>
       - When parsing payroll restrictions: "States: AL, AK, MT" → "Alabama, Alaska, Montana"
       - When displaying location warnings: Show both formats - "Excluded states: Alabama (AL), Alaska (AK), Montana (MT)"
       - Apply to all location-related parsing: remote restrictions, residency requirements, excluded states
     </usage>
     <mapping>
       [50 states + DC mapping]
     </mapping>
   </state_abbreviation_mapping>
   ```

**Part C: Update location_mismatch instruction**
6. Navigate to `<location_mismatch>` instruction (around line 378)
7. Enhance to reference state abbreviation mapping:
   ```xml
   <location_mismatch>JD requires on-site/hybrid when user needs remote, OR geographic restrictions user cannot meet. When displaying state-specific restrictions, use state_abbreviation_mapping to expand abbreviations (e.g., "Excluded: Alabama (AL), Alaska (AK), Montana (MT)" instead of just "AL, AK, MT").</location_mismatch>
   ```

### Step 2: Update Documentation

**ROADMAP.md:**
```markdown
### v6.1.8 - Location Red Flag Update (COMPLETE)
**Branch:** `v6.1.8-location_red_flag_update` | **Status:** Complete | **Date:** 2025-12-30

**Changes:**
- [x] Enhanced location_red_flags to detect state-specific remote payroll restrictions
- [x] Improved blocking gate accuracy for location mismatches

**Impact:** Users now get explicit warnings for jobs with payroll compliance restrictions.
```

**CHANGELOG.md** (or CHANGELOG_DEV.md):
```markdown
### v6.1.8 - Location Red Flag Update (2025-12-30)
> **Branch:** `v6.1.8-location_red_flag_update`

#### Changed
- **Enhanced `location_red_flags` detection** - Added explicit pattern for state-specific remote payroll restrictions
  - New pattern: "The following states are not approved for remote payroll at this time: [list]"
  - Improves blocking gate accuracy for location mismatches
  - Prevents wasted effort on applications where user's state is excluded

#### Impact
- ✅ Better detection of payroll compliance restrictions during JD parsing (Phase 1)
- ✅ More accurate location blocking gate warnings (Phase 2)
- ✅ No breaking changes - additive enhancement only
```

### Step 3: Git Operations

```bash
# Stage changes
git add PROJECT-INSTRUCTIONS.md ROADMAP.md docs/CHANGELOG.md

# Commit with conventional commit message
git commit -m "$(cat <<'EOF'
feat(v6.1.8): enhance location_red_flags with payroll restrictions and state abbreviation expansion

Added explicit pattern to detect state-specific remote payroll restrictions:
- "The following states are not approved for remote payroll at this time: [list]"

Added state abbreviation mapping (50 states + DC) to automatically expand
state codes (e.g., "AL, AK, MT" → "Alabama (AL), Alaska (AK), Montana (MT)"):
- Improves user experience by showing full state names
- Reduces confusion for users unfamiliar with all state codes
- Applies to all location parsing (payroll restrictions, residency requirements, etc.)

This improves blocking gate accuracy by catching payroll compliance
restrictions that may appear in JDs as:
- "Remote work only available in: [states]"
- "We are unable to support remote employees in: [states]"
- "Payroll compliance restricts remote work to certain states"

Changes:
- PROJECT-INSTRUCTIONS.md: Added location_red_flags bullet + state_abbreviation_mapping section + enhanced location_mismatch
- ROADMAP.md: Added v6.1.8 completion entry
- docs/CHANGELOG.md: Added v6.1.8 changelog entry
- docs/plans/v6.1.8-location_red_flag_update.md: Updated plan document

Impact:
- Better Phase 1 JD parsing accuracy with clearer state name display
- More accurate Phase 2 location blocking gate warnings
- Prevents wasted effort on ineligible applications
- Improved user experience (no need to decode state abbreviations)

🤖 Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
EOF
)"

# Push to origin
git push -u origin v6.1.8-location_red_flag_update
```

---

## 🚀 Next Steps

### Immediate (Post-v6.1.8)
1. Monitor user feedback on payroll restriction detection accuracy
2. Consider adding examples to JD parsing documentation
3. Evaluate if `remote_restrictions` field (parsing parser) should be enhanced

### Future Enhancements (v6.2.0+)
1. **User profile integration** - Compare restricted states against user's home state automatically
2. **Payroll database** - Maintain common state restriction lists by company size
3. **Multi-location support** - Handle "Remote - multiple offices in CA/NY/TX" scenarios
4. **Smart state detection** - Auto-detect user's current state from job history locations

**Note:** State abbreviation expansion was originally planned for future but has been implemented in v6.1.8.

---

## 🔗 Related Files

**Primary:**
- `PROJECT-INSTRUCTIONS.md` - Main implementation (lines 337-344)

**Phase Files:**
- `phases/phase-1/jd-parsing.md` - Location extraction logic (lines 57-69, 76-79)
- `phases/phase-2/evidence-matching.md` - Blocking gates check (line 396)

**Legacy (Reference Only):**
- `docs/legacy/modes-v5/mode-3-jd-comparison.md`
- `docs/legacy/implementation-prompts/ADD_REMOTE_WORK_LOGIC.md`

---

**Plan Status:** READY FOR IMPLEMENTATION
**Created:** 2025-12-30
**Estimated Time:** 10 minutes
**Risk Level:** Low (additive change, no breaking changes)

---

**End of Plan Document**


# --- FILE: docs/plans/v6.1.9_gap-analysis_test-cases_plan.md ---


# v6.1.9 Gap Analysis Test Cases - Patch Plan

**Version:** 6.1.9
**Branch:** `v6.1.9-gap-analysis_test-cases`
**Type:** Improvement/Enhancement
**Date:** 2025-12-30
**Status:** Complete

---

## Summary

Consolidate and expand test case coverage for Phases 2-4 by merging Sonnet's baseline tests with Opus expansions, corrections, and gap-filling tests. Additionally, add industry-standard skill priority weights (3:2:1 model) to scoring methodology across all relevant system files.

---

## Problem Statement

The existing test suite had gaps in Phase 2-4 coverage:
1. Sonnet's 32 baseline tests covered happy paths but missed edge cases
2. Logic errors existed in some test definitions (e.g., INC-004 index direction)
3. Boundary conditions were not tested (score = 30, confidence = 0.5)
4. Error recovery and blocking gate combinations were untested

---

## Changes

### Files Created

| File | Location | Description |
|------|----------|-------------|
| `phase-2-4-test-cases.md` | `docs/plans/testing/` | 79 merged test cases (Sonnet + Opus) |

### Files Modified

| File | Change |
|------|--------|
| `test-results.md` | Add execution results for new tests |
| `core/fit-thresholds.md` | Add skill-level priority weights (3:2:1 model) |
| `phases/phase-2/evidence-matching.md` | Update scoring formula with priority weights |
| `PROJECT-INSTRUCTIONS.md` | Add skill priority weights to scoring methodology |
| `quick-start-phase.md` | Add skill priority weights to scoring methodology |
| `docs/CHANGELOG.md` | Add v6.1.9 release notes |

---

## Detailed Change Rationale

### Issue Found: Missing Skill-Level Weights

**Discovery:** While creating test case FIX-008 (Required vs Preferred Weight Ratio), Opus identified that the system had **category-level weights** but **no skill-level weights**.

**Existing (Before v6.1.9):**
```xml
<scoring_methodology>
  <core_qualifications weight="50%">...</core_qualifications>
  <critical_requirements weight="30%">...</critical_requirements>
  <preferred_qualifications weight="20%">...</preferred_qualifications>
</scoring_methodology>
```

This defined weights for *categories* of requirements, but NOT for individual skills within those categories. The formula in `evidence-matching.md` was:
```
Scoring Method:
- Matched = 100% weight
- Partial = 50% weight
- Missing = 0% weight

Calculation: (10 * 1.0 + 3 * 0.5 + 3 * 0.0) / 16 = 0.72 = 72%
```

**Problem:** All skills treated equally regardless of importance:
- Missing "Python (Required)" = same impact as missing "Terraform (Preferred)"
- This doesn't match how recruiters evaluate candidates
- ATS systems typically weight required skills higher

**Solution:** Added 3:2:1 skill priority weights based on industry research:
- Required skills: 1.5x weight (priority 3)
- Preferred skills: 1.0x weight (priority 2)
- Optional skills: 0.5x weight (priority 1)

**Sources:**
- Rezi.ai ATS Resume Checker (uses 3:2:1 priority scoring)
- Recruiterflow: "10% change in weighting can shift scores by 5-8 points"
- Jobscan: 80% match rate target for resume optimization

---

## Specific Changes Per File

### 1. `core/fit-thresholds.md`

**Issue:** No skill-level priority weights defined.

**Added (Lines 65-101):**
```xml
### Skill-Level Priority Weights (v6.1.9)

<skill_priority_scoring>
  <!-- 3:2:1 Priority Model -->
  <required_skills priority="3" weight="1.5x">
    Skills explicitly marked as "Required", "Must have", or "Essential"
    Missing a required skill has 1.5x the negative impact of missing a preferred skill
  </required_skills>

  <preferred_skills priority="2" weight="1.0x">
    Skills marked as "Preferred", "Nice to have", or "Bonus"
    Baseline weight for gap calculations
  </preferred_skills>

  <optional_skills priority="1" weight="0.5x">
    Skills mentioned but not emphasized, inferred from context
    Half the impact of preferred skills
  </optional_skills>
</skill_priority_scoring>
```

Plus example calculation table and sources.

**Version Header Updated:** `<!-- Version: 5.0 -->` → `<!-- Version: 5.1 (v6.1.9 update) -->`

---

### 2. `phases/phase-2/evidence-matching.md`

**Issue:** Scoring formula treated all requirements equally.

**Before (Lines 381-388):**
```
Scoring Method:
- Matched = 100% weight
- Partial = 50% weight
- Missing = 0% weight

Calculation: (10 * 1.0 + 3 * 0.5 + 3 * 0.0) / 16 = 0.72 = 72%
```

**After (Lines 383-404):**
```
Scoring Method (v6.1.9 - Priority-Weighted):
- Matched = 100% of skill weight
- Partial = 50% of skill weight
- Missing = 0% of skill weight

Skill Priority Weights (3:2:1 Model):
- Required skills: 1.5x weight (priority 3)
- Preferred skills: 1.0x weight (priority 2)
- Optional/Inferred skills: 0.5x weight (priority 1)

Example Calculation:
| Skill | Status | Priority | Base Points | Weighted |
|-------|--------|----------|-------------|----------|
| Python (Required) | MATCHED | 3 | 10 | 15 pts |
| SQL (Required) | MATCHED | 3 | 10 | 15 pts |
| AWS (Preferred) | PARTIAL | 2 | 5 | 5 pts |
| Kubernetes (Preferred) | MISSING | 2 | 0 | 0 pts |
| Leadership (Required) | MATCHED | 3 | 10 | 15 pts |

Formula: (Sum of Weighted Points) / (Max Possible Weighted Points) × 100
```

**Version History Updated:** Added `v1.1 (2025-12-30): Added priority-weighted scoring formula`

---

### 3. `PROJECT-INSTRUCTIONS.md`

**Issue:** System prompt had category weights but no skill-level weights.

**Added after `<scoring_methodology>` block (Lines 391-397):**
```xml
<!-- v6.1.9: Skill-Level Priority Weights (3:2:1 Model) -->
<skill_priority_scoring>
  <required_skills priority="3" weight="1.5x">Skills marked "Required", "Must have", "Essential"</required_skills>
  <preferred_skills priority="2" weight="1.0x">Skills marked "Preferred", "Nice to have", "Bonus"</preferred_skills>
  <optional_skills priority="1" weight="0.5x">Skills inferred from context, not emphasized</optional_skills>
  <note>Missing a Required skill has 1.5x the negative impact of missing a Preferred skill. See core/fit-thresholds.md for full methodology.</note>
</skill_priority_scoring>
```

**Version Header Updated:**
- Line 1: `v6.1.7` → `v6.1.9`
- Line 6: Added `<!-- v6.1.9 Release: Skill priority weights (3:2:1 model), test case expansion (79 tests) -->`

---

### 4. `quick-start-phase.md`

**Issue:** Quick-start version also missing skill-level weights.

**Added same `<skill_priority_scoring>` block (Lines 135-141):**
```xml
<!-- v6.1.9: Skill-Level Priority Weights (3:2:1 Model) -->
<skill_priority_scoring>
  <required_skills priority="3" weight="1.5x">Skills marked "Required", "Must have", "Essential"</required_skills>
  <preferred_skills priority="2" weight="1.0x">Skills marked "Preferred", "Nice to have", "Bonus"</preferred_skills>
  <optional_skills priority="1" weight="0.5x">Skills inferred from context, not emphasized</optional_skills>
  <note>Missing a Required skill has 1.5x the negative impact of missing a Preferred skill.</note>
</skill_priority_scoring>
```

**Version Header Updated:** Line 1 and Line 6: `v6.1.7` → `v6.1.9`

---

### 5. `docs/CHANGELOG.md`

**Added v6.1.9 release notes (Lines 12-47)** with:
- **Added:** Skill Priority Weights, Expanded Test Suite
- **Changed:** Scoring Formula, System Instructions, Core Configuration
- **Fixed:** Sonnet Test Logic Errors (4 corrections)
- **Impact:** Summary of user benefits

---

### 6. Testing Folder Reorganization

**Issue:** The `v6.1.5-testing/` folder contained redundant files after consolidation:
- Duplicate `v6.0-deep-dive-test-cases.md` (existed in both `docs/plans/` and `docs/plans/v6.1.5-testing/`)
- Obsolete planning docs (`v6.1.5-test-gaps.md`, `v6.1.5-opus-test-instructions.md`)
- Source files now merged into consolidated (`v6.1.5-sonnet-test-cases.md`, `v6.1.5-opus-expanded-test-cases.md`)

**Files Removed (5):**

| File | Reason |
|------|--------|
| `docs/plans/v6.0-deep-dive-test-cases.md` | Duplicate of file in testing folder |
| `v6.1.5-test-gaps.md` | Planning doc - task completed |
| `v6.1.5-opus-test-instructions.md` | One-time instructions - task completed |
| `v6.1.5-sonnet-test-cases.md` | Content merged into consolidated file |
| `v6.1.5-opus-expanded-test-cases.md` | Content merged into consolidated file |

**Folder Renamed:** `v6.1.5-testing/` → `testing/`

**Files Renamed:**

| Before | After | Reason |
|--------|-------|--------|
| `v6.0-deep-dive-test-cases.md` | `phase-1-test-cases.md` | Descriptive of content |
| `v6.1.9-consolidated-test-cases.md` | `phase-2-4-test-cases.md` | Descriptive of content |
| `v6.1.5-test-results.md` | `test-results.md` | Version-agnostic |

**Final Structure:**
```
docs/plans/testing/
├── phase-1-test-cases.md   (95+ Phase 1 JD parser tests)
├── phase-2-4-test-cases.md (79 Phase 2-4 consolidated tests)
└── test-results.md         (execution results)
```

**Net Impact:** -665 lines of redundant content removed.

---

### Test Case Additions

| Category | Count | Author | Focus |
|----------|-------|--------|-------|
| INT | 8 | Sonnet | Phase 2 Integration |
| INC | 10 | Sonnet | Incremental Updates |
| DIFF | 7 | Sonnet | Re-Comparison |
| SUM | 7 | Sonnet | Summary Generation |
| INTX | 8 | Opus | Extended Integration |
| INCX | 10 | Opus | Extended Incremental |
| DIFFX | 7 | Opus | Extended Diff |
| SUMX | 8 | Opus | Extended Summary |
| GATE | 7 | Opus | Blocking Gate Combinations |
| ERR | 7 | Opus | Error Recovery |
| FIX | 12 | Opus | Logic Corrections & Gaps |
| **Total** | **79** | | |

---

## Sonnet Logic Corrections Applied

| Original Test | Issue | Correction |
|---------------|-------|------------|
| INC-004 | Said indices "shifted up" | Corrected to "shifted DOWN" |
| SUM-005 | Used score 42 as threshold | Corrected to use gate threshold (<30) |
| INT-007 | No weight ratios specified | Added: Required = 1.5x Preferred |
| INT-006 | Confidence "> 0.5" ambiguous | Clarified: ">= 0.5" (inclusive) |

---

## Implementation Checklist

### Phase 1: Test Case Development
- [x] Review Sonnet's test cases for logic issues
- [x] Create Opus expanded test cases (INTX, INCX, DIFFX, SUMX, GATE, ERR)
- [x] Create FIX series for logic corrections and gaps
- [x] Merge all tests into consolidated file
- [x] Create patch plan document

### Phase 2: Skill Priority Weights
- [x] Add 3:2:1 skill priority weights to `core/fit-thresholds.md`
- [x] Update scoring formula in `phases/phase-2/evidence-matching.md`
- [x] Add skill priority weights to `PROJECT-INSTRUCTIONS.md`
- [x] Add skill priority weights to `quick-start-phase.md`

### Phase 3: Finalization
- [x] Create git branch (`v6.1.9-gap-analysis_test-cases`)
- [x] Execute P0/P1 priority tests
- [x] Update test results file
- [x] Update `docs/CHANGELOG.md` with v6.1.9 release notes
- [x] Commit and push final changes

### Phase 4: Testing Folder Cleanup
- [x] Remove duplicate `docs/plans/v6.0-deep-dive-test-cases.md`
- [x] Remove obsolete planning files (merged into consolidated)
- [x] Rename folder `v6.1.5-testing/` → `testing/`
- [x] Rename files with clearer naming convention
- [x] Update plan file with new paths

---

## Test Execution Priority

| Priority | Tests | Rationale |
|----------|-------|-----------|
| P0 (Critical) | GATE-*, ERR-001 to ERR-003, FIX-004 to FIX-010 | Blocking gates, data integrity |
| P1 (High) | INT-*, INTX-001 to INTX-004, DIFF-001, DIFFX-001 | Core workflow |
| P2 (Medium) | INC-*, INCX-*, SUM-*, SUMX-* | Feature completeness |
| P3 (Low) | Remaining | Edge cases |

---

## Success Criteria

- [x] All 79 test cases documented in consolidated file
- [x] Logic corrections applied to Sonnet baseline
- [x] P0 and P1 tests executed with results recorded
- [x] No blocking issues identified
- [x] Skill priority weights added to all scoring files

---

## Related Files

### Test Documentation
- `docs/plans/testing/phase-1-test-cases.md` - Phase 1 JD parser tests (95+)
- `docs/plans/testing/phase-2-4-test-cases.md` - Phase 2-4 consolidated tests (79)
- `docs/plans/testing/test-results.md` - Test execution results

### Scoring Methodology Updates
- `core/fit-thresholds.md` - Skill priority weights definition
- `phases/phase-2/evidence-matching.md` - Scoring formula implementation
- `PROJECT-INSTRUCTIONS.md` - System prompt (full version)
- `quick-start-phase.md` - System prompt (quick start version)

### Release Documentation
- `docs/CHANGELOG.md` - Version history

---

## Skill Priority Weights (v6.1.9 Addition)

Based on industry ATS scoring best practices (Rezi.ai, Jobscan, Recruiterflow):

| Skill Type | Priority | Weight | Description |
|------------|----------|--------|-------------|
| Required | 3 | 1.5x | "Required", "Must have", "Essential" |
| Preferred | 2 | 1.0x | "Preferred", "Nice to have", "Bonus" |
| Optional | 1 | 0.5x | Inferred from context, not emphasized |

**Impact:** Missing a Required skill has 1.5x the negative impact of missing a Preferred skill.


# --- FILE: docs/plans/v6.1.11_various_fixes_plan.md ---


# Patch Plan: v6.1.11 - Quality Gate, Auto-Export & Keyword Evidence

**Version:** 6.1.11
**Branch:** v6.1.11-various_fixes
**Type:** Improvement/Enhancement
**Created:** 2025-12-31
**Status:** Complete

---

## Executive Summary

This patch addresses critical gaps in the output quality enforcement system and keyword handling:

1. **Missing Auto-Regeneration Loop:** While quality checks exist, there's no instruction to regenerate bullets when issues are found
2. **Missing Auto-Export:** No automatic plain text export after quality validation passes
3. **Missing Keyword Evidence Principle:** No safeguard preventing keyword stuffing without backing evidence (v6.1.11 addition)
4. **Missing Keyword Input Handling:** No workflow for handling keywords provided with JD or after bullet generation (v6.1.11 addition)

These gaps allow quality issues to slip through, create manual copy-paste work, and risk inauthentic keyword usage.

---

## Problem Analysis

### Fix #1: Missing Automatic Quality Gate with Regeneration

**Current State:**
- `pre_output_quality_checklist` exists with automated scan patterns (lines 632-646 in PROJECT-INSTRUCTIONS.md)
- Scans for: escaped tildes (\~), gerunds, repeated phrases, keyword duplication
- Verb diversity requirements defined in core/verb-categories.md (5 categories, 20% target each)

**Gap Identified:**
- NO instruction that says: "IF issues found, REGENERATE bullets and re-validate"
- NO instruction to check verb diversity (all 5 categories represented)
- NO enforcement loop that repeats until all checks pass

**Impact:**
Quality issues can appear in final output:
- Escaped characters (\~, \%, \+) make it to final bullets
- Gerunds (-ing verbs) start bullets instead of past-tense verbs
- Exact phrases repeat 3+ times across positions
- Verb diversity fails (0% representation of a category)
- Same verb category repeats within a single position

**Root Cause:**
The system can DETECT problems but has no instruction to FIX them automatically.

### Fix #2: Missing Automatic Plain Text Export

**Current State:**
- No plain text export functionality exists in the system
- Users must manually copy bullets from markdown output
- No standardized format for plain text export

**Gap Identified:**
- NO instruction to auto-generate plain text file after quality gate passes
- NO defined output format for plain text export
- NO defined output location for generated files

**Impact:**
- Users waste time manually copy-pasting bullets
- Inconsistent formatting when users create their own exports
- No metadata (character count, word count) in plain text format
- No easy way to share bullets without markdown formatting

**Root Cause:**
Plain text export was never implemented as an automatic feature.

---

## Proposed Solution

### Solution #1: Implement Automatic Quality Gate

Add a new `<automatic_quality_gate>` section to PROJECT-INSTRUCTIONS.md that:

1. **Runs BEFORE presenting output** (blocking gate)
2. **Executes quality checklist** (existing automated_scan_patterns)
3. **Checks verb diversity:**
   - All 5 categories (Built, Lead, Managed, Improved, Collaborate) represented
   - No category appears 0 times
   - No category repeats within same position
4. **Regenerates if issues found:**
   - Identifies affected positions
   - Regenerates bullets using missing categories
   - Re-runs quality checklist
   - Repeats until all checks pass
5. **Proceeds to plain text export** (only after passing)

**Location:** PROJECT-INSTRUCTIONS.md, after line 646 (after `pre_output_quality_checklist`)

**Structure:**
```xml
<automatic_quality_gate>
  <trigger>After generating bullets, BEFORE presenting output:</trigger>
  <step_1_run_quality_checklist>
    Run pre_output_quality_checklist automated scans
  </step_1_run_quality_checklist>
  <step_2_check_verb_diversity>
    Verify: All 5 verb categories (Built, Lead, Managed, Improved, Collaborate)
    are represented across bullets
    Flag: Any category appearing 0 times = REGENERATE
    Flag: Same category repeated within position = REGENERATE
  </step_2_check_verb_diversity>
  <step_3_regenerate_if_needed>
    IF issues found:
      1. Identify affected positions
      2. Regenerate bullets using missing categories
      3. Re-run quality checklist
      4. Repeat until all checks pass
    ELSE: Proceed to step 4
  </step_3_regenerate_if_needed>
  <step_4_export_plain_text>
    Auto-generate plain text export (see automatic_plain_text_export)
  </step_4_export_plain_text>
</automatic_quality_gate>
```

### Solution #2: Implement Automatic Plain Text Export

Add a new `<automatic_plain_text_export>` section to PROJECT-INSTRUCTIONS.md that:

1. **Triggers after quality gate passes** (all bullets finalized)
2. **Formats output as plain text:**
   - Professional Summary
   - Position bullets (no markdown)
   - Character count per bullet
   - Total word count
3. **Creates file in standardized location:** `/mnt/user-data/outputs/[job-specific-name].txt`
4. **Presents output** using present_files tool

**Location:** PROJECT-INSTRUCTIONS.md, after `automatic_quality_gate`

**Structure:**
```xml
<automatic_plain_text_export>
  <trigger>After quality_gate passes and all bullets finalized</trigger>
  <format>
    [Professional Summary]

    POSITION 1: [Title] at [Company]
    • [Bullet 1]
    • [Bullet 2]
    • [Bullet 3]

    POSITION 2: [Title] at [Company]
    • [Bullet 1]
    • [Bullet 2]
    ...

    Character Count: X (target: 100-210 per bullet)
    Word Count: X (target: 350-500 total)
  </format>
  <output_location>Create as /mnt/user-data/outputs/[job-title]-bullets.txt</output_location>
  <presentation>Display in response with present_files tool</presentation>
  <no_markdown_instruction>
    Do NOT show markdown formatting in plain text file.
    Use plain text bullet points (•) only.
    No code blocks, no bold, no italics.
  </no_markdown_instruction>
</automatic_plain_text_export>
```

---

## Implementation Steps

### Phase 1: Update PROJECT-INSTRUCTIONS.md

1. Add `<automatic_quality_gate>` section after line 646
2. Add `<automatic_plain_text_export>` section after `<automatic_quality_gate>`
3. Update version number to 6.1.10
4. Add changelog entry

### Phase 2: Update core/format-rules.md

1. Add reference to automatic_quality_gate in quality_assurance_rules section
2. Add validation requirement for auto-export

### Phase 3: Testing

1. Test with sample JD + job history
2. Verify quality gate catches issues:
   - Escaped tildes
   - Gerunds
   - Missing verb categories
   - Repeated verb categories within position
3. Verify regeneration loop works
4. Verify plain text export creates file
5. Verify plain text format is correct

### Phase 4: Documentation

1. Update CHANGELOG.md with v6.1.10 entry
2. Update ROADMAP.md with completion status
3. Update any lessons-learned documents if needed

---

## Files to Modify

1. **PROJECT-INSTRUCTIONS.md** (primary changes)
   - Add `<automatic_quality_gate>` section
   - Add `<automatic_plain_text_export>` section
   - Update version to 6.1.10

2. **core/format-rules.md** (reference update)
   - Add validation requirements for quality gate
   - Add validation requirements for auto-export

3. **docs/CHANGELOG.md** (documentation)
   - Add v6.1.10 entry

4. **ROADMAP.md** (documentation)
   - Mark v6.1.10 as completed

---

## Expected Outcomes

### After Fix #1 (Automatic Quality Gate):
- Zero escaped characters in final output
- Zero gerunds starting bullets
- Zero missing verb categories (all 5 represented)
- Zero repeated verb categories within same position
- Zero repeated exact phrases (>2 occurrences)

### After Fix #2 (Automatic Plain Text Export):
- Plain text file auto-generated for every bullet generation
- Standardized format across all exports
- Character/word counts included
- No markdown formatting in plain text
- Easy copy-paste into resume

---

## Risk Assessment

**Low Risk:**
- These are additive changes (no breaking changes)
- Existing quality_assurance_rules remain unchanged
- New sections are independent and don't affect other phases

**Mitigation:**
- Test with multiple JD scenarios
- Verify regeneration loop doesn't get stuck (add max iteration limit if needed)
- Ensure plain text export doesn't fail if output directory doesn't exist

---

## Success Criteria

1. ✅ Quality gate runs automatically before output presentation
2. ✅ Quality gate catches and regenerates bullets with issues
3. ✅ All 5 verb categories represented in every resume output
4. ✅ Plain text file auto-generated after quality gate passes
5. ✅ Plain text format is clean (no markdown, proper bullet points)
6. ✅ Character/word counts included in plain text export
7. ✅ All tests pass

---

## Rollback Plan

If issues arise:
1. Revert commits on v6.1.10-fix_2nd_pass branch
2. Return to main branch
3. Document issues in lessons-learned
4. Re-plan with adjustments

---

## Notes

- This patch addresses gaps identified in user feedback about quality consistency
- The automatic quality gate transforms detection into enforcement
- Plain text export reduces manual work and improves user experience
- Both fixes work together: quality gate ensures clean output, export makes it easy to use

---

**Plan Status:** ✅ Ready for Implementation
**Approval Required:** Yes
**Estimated Implementation Time:** 30-45 minutes


# --- FILE: docs/plans/v6.2.0_job-history-templates_plan.md ---


# Patch Plan: v6.2.0 - Job History Template System & Workflow Automation

**Version:** v6.2.0
**Branch:** `v6.2.0-job-history-templates`
**Type:** Feature Release (Template Infrastructure + Workflow Automation)
**Created:** January 2, 2026
**Status:** Implementation Complete - Documentation Pending

---

## 1. Executive Summary

This patch introduces a comprehensive template system ensuring consistent job history generation across all LLMs (Claude, Gemini, ChatGPT, Copilot), along with automated validation/conversion tools and two new workflow skills.

### Key Deliverables

1. **Template System** (4 files)
   - XML schema template
   - Markdown template
   - LLM generation instructions (3,500+ words)
   - Template system README

2. **Python Automation** (2 scripts)
   - Validation script (ensures schema compliance)
   - Conversion script (.txt → .md)

3. **Workflow Skills** (2 skills)
   - `/md-job-history` - Convert job history to Markdown
   - `/update-history` - Intelligent version management

4. **Job History Updates**
   - v7.0: JSON/Power Platform additions + CI/CD details
   - v7.1: Template system achievements

---

## 2. Problem Statement

### Issues Identified

**Cross-LLM Inconsistency:**
- Different LLMs might use different tag names
- Sections could appear in different orders
- No standardized validation process
- Inconsistent date formats across generations

**Format Challenges:**
- `.txt` files difficult for humans to read
- No automated way to generate presentation-ready versions
- Manual conversion error-prone

**Version Management:**
- No systematic workflow for surgical updates
- Risk of losing chat context during compaction
- Manual version increment decision-making

### Impact

Without this system:
- Job history structure could drift over time
- Different AI assistants would produce incompatible formats
- Presentation versions would require manual formatting
- Update process would be ad-hoc and inconsistent

---

## 3. Solution Architecture

### Template-Based Generation System

```
┌─────────────────────────────────────────────────────────┐
│  LLM (Claude/Gemini/ChatGPT/Copilot)                   │
│                                                         │
│  Reads: LLM_GENERATION_INSTRUCTIONS.md                 │
│  Follows: job_history_template.xml                     │
│  Generates: job_history_vX.txt                         │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│  Validation Pipeline                                    │
│                                                         │
│  python3 scripts/validate_job_history.py vX.txt        │
│  - Check required sections                             │
│  - Validate XML balance                                │
│  - Verify metadata completeness                        │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│  Conversion Pipeline                                    │
│                                                         │
│  python3 scripts/convert_job_history_to_md.py vX.txt   │
│  - Parse XML structure                                 │
│  - Generate emoji headers                              │
│  - Format metrics as tables                            │
│  - Create hierarchical Markdown                        │
└──────────────────────┬──────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────┐
│  Dual-Format Output                                     │
│                                                         │
│  job_history_vX.txt (XML - for LLMs)                   │
│  job_history_vX.md (Markdown - for humans)             │
└─────────────────────────────────────────────────────────┘
```

### Workflow Automation

```
/update-history [file?]
       ↓
┌──────────────────────┐
│ Analyze chat context │
│ Identify updates     │
└──────┬───────────────┘
       ↓
┌──────────────────────┐
│ Determine version    │
│ MAJOR/MINOR/PATCH    │
└──────┬───────────────┘
       ↓
┌──────────────────────┐
│ Copy & increment     │
│ v7.0 → v7.1          │
└──────┬───────────────┘
       ↓
┌──────────────────────┐
│ Apply surgical       │
│ updates (preserve)   │
└──────┬───────────────┘
       ↓
┌──────────────────────┐
│ Validate & convert   │
│ .txt → .md           │
└──────────────────────┘
```

---

## 4. Detailed Changes

### 4.1 Template Files Created

#### `templates/job_history_template.xml`
- **Purpose:** Defines exact XML schema all LLMs must follow
- **Lines:** 450+
- **Sections:**
  - File header format
  - Version history structure
  - Global sections (education, certifications, master_skills_inventory)
  - Position template with all 13 required sections
  - Tag name specifications
  - Date format standards

**Key features:**
```xml
<position id="[N]">
  <metadata>...</metadata>
  <professional_summary>...</professional_summary>
  <core_responsibilities>...</core_responsibilities>
  <key_achievements>...</key_achievements>
  <hard_skills_demonstrated>...</hard_skills_demonstrated>
  <soft_skills_demonstrated>...</soft_skills_demonstrated>
  <tools_technologies>...</tools_technologies>
  <impact_metrics>...</impact_metrics>
  <industry_domain>...</industry_domain>
  <methodology>...</methodology>
  <strategic_decisions>...</strategic_decisions>
  <team_scope>...</team_scope>
  <honest_limitations>...</honest_limitations>
</position>
```

#### `templates/job_history_template.md`
- **Purpose:** Markdown presentation format template
- **Lines:** 300+
- **Features:**
  - Emoji headers (🎯, 🏢, 📊, 💼)
  - Markdown tables for metrics
  - Hierarchical structure
  - Professional formatting

#### `templates/LLM_GENERATION_INSTRUCTIONS.md`
- **Purpose:** Comprehensive guide for all LLMs
- **Lines:** 350+
- **Word count:** 3,500+
- **Sections:**
  - Core principles (consistency across LLMs)
  - Exact schema enforcement
  - Tag name requirements (exact match table)
  - Section order mandates
  - Date format standards
  - Achievement structure (CONTEXT/ACTION/RESULT/IMPACT)
  - Style & tone guidelines
  - Validation checklist
  - Common mistakes to avoid
  - Quality assurance self-checks

**Critical rules enforced:**
- ALWAYS use exact template schema
- NEVER skip or rename sections
- ALWAYS validate before delivery

#### `templates/README.md`
- **Purpose:** Template system overview and usage guide
- **Lines:** 415
- **Sections:**
  - System overview
  - File descriptions
  - Workflow diagrams
  - Quick start guide
  - Format comparison (.txt vs .md)
  - Validation instructions
  - Best practices
  - Troubleshooting
  - Examples

### 4.2 Python Scripts Created

#### `scripts/validate_job_history.py`
- **Purpose:** Validate job history files against template schema
- **Lines:** 226
- **Language:** Python 3
- **Dependencies:** Standard library only (re, sys, pathlib, collections)

**Validation checks:**
```python
REQUIRED_GLOBAL_SECTIONS = [
    'education',
    'certifications',
    'master_skills_inventory'
]

REQUIRED_POSITION_SECTIONS = [
    'metadata',
    'professional_summary',
    'core_responsibilities',
    'key_achievements',
    'hard_skills_demonstrated',
    'impact_metrics'
]
```

**Features:**
- Header validation
- Version history checks
- Global sections verification
- Position structure validation
- Metadata completeness checks
- XML tag balance verification
- Professional summary length checks
- Detailed error/warning/info reporting

**Usage:**
```bash
python3 scripts/validate_job_history.py chat-history/job_history_vX.txt
```

**Output:**
```
✅ VALIDATION PASSED
Job history file matches template schema!
```

#### `scripts/convert_job_history_to_md.py`
- **Purpose:** Convert .txt (XML) to .md (Markdown)
- **Lines:** 400+
- **Language:** Python 3
- **Dependencies:** Standard library only (re, sys)

**Conversion features:**
- XML parsing with regex
- Emoji header generation
- Markdown table formatting for metrics
- Hierarchical structure creation
- Achievement expansion (CONTEXT/ACTION/RESULT/IMPACT)
- Professional summary formatting
- Skills list conversion
- Date formatting

**Usage:**
```bash
python3 scripts/convert_job_history_to_md.py chat-history/job_history_vX.txt
```

**Output:**
```
✅ Converted chat-history/job_history_vX.txt
   to chat-history/job_history_vX.md
```

### 4.3 Workflow Skills Created

#### `.claude/skills/md-job-history.md`
- **Skill name:** `/md-job-history`
- **Purpose:** Convert job history .txt to .md
- **Lines:** 180
- **Usage:** `/md-job-history [filename.txt]`

**Workflow:**
1. Identify source file (parameter or infer from context)
2. Validate file exists
3. Run conversion script
4. Report success with output filename

**Features:**
- Context-aware file detection
- Automatic validation before conversion
- User-friendly error messages
- Integration with /update-history workflow

#### `.claude/skills/update-history.md`
- **Skill name:** `/update-history`
- **Purpose:** Intelligent version management and surgical updates
- **Lines:** 517
- **Usage:** `/update-history [filename.txt]`

**Workflow:**
1. **Identify source file** (provided, inferred, or ask)
2. **Analyze chat context** for updates
3. **Determine version increment** (MAJOR/MINOR/PATCH)
4. **Copy and increment** version
5. **Apply surgical updates** (preserve existing content)
6. **Validate and convert** to both formats
7. **Provide summary** of changes

**Version increment rules:**
- **MAJOR** (v7.0 → v8.0): New/removed position, major restructuring
- **MINOR** (v7.0 → v7.1): Added achievements, updated metrics, new skills
- **PATCH** (v7.1 → v7.1.1): Typo fixes, minor clarifications

**Surgical update principles:**
```
✅ DO:
- Add new content to existing sections
- Enhance existing bullet points
- Insert new achievements/responsibilities
- Update specific metrics
- Preserve all existing detail

❌ DON'T:
- Rewrite entire sections from scratch
- Remove existing content (unless explicitly requested)
- Change structure/order without reason
- Lose existing metrics or details
```

### 4.4 Job History Updates

#### v7.0 Creation (from v6.0)
**File:** `chat-history/claude_generated_job_history_summaries_v7.txt`
**Version:** 7.0 (JSON/POWER PLATFORM ADDITIONS & CI/CD DETAILS)
**Lines:** 1,354
**Date:** January 2, 2026

**Changes applied:**

**Position 3 (State Department) - CI/CD Enhancements:**
- Added 6 new core responsibilities:
  - Release management (13+ releases over 3 months)
  - Deployment orchestration across environments
  - Pipeline automation (dev/test automated, prod manual)
  - Cross-tenant deployment procedures
  - Release notes and changelog maintenance
  - Semantic versioning application

- Added 7 new achievements:
  - 13+ weekly releases during MVP phase
  - 80% deployment time reduction (4h → 2h)
  - Zero deployment failures through standardization
  - Cross-tenant manual deployments
  - Changelog with semantic versioning

- Added 10 new hard skills:
  - Azure DevOps Pipelines (CI/CD)
  - Release Management
  - Deployment Orchestration
  - Power Platform Pipeline Management
  - Cross-Tenant Deployment
  - Semantic Versioning
  - Release Notes Documentation
  - Changelog Maintenance
  - Deployment Automation
  - Migration Procedures

- Added 4 new impact metrics:
  - 13+ releases over 3 months (1+ per week during MVP)
  - 80% deployment time reduction (4 hours → 2 hours)
  - 100% deployment success rate through standardization
  - 3-environment pipeline (dev/test/prod)

- Updated Canvas Power Apps to "Canvas and model-driven Power Apps" (4 locations)

**Position 4 (DoE SOC) - JSON Additions:**
- Updated Power Automate references to mention JSON format usage
- Added JSON to hard_skills_demonstrated

**Position 5 (Foxhole Technology/DoE SOC) - Major Updates:**
- Updated company from "Department of Education Security Operations Center (DoE SOC)" to "Foxhole Technology (DoE SOC contract)"
- Added RFP automation project achievement with 8 detailed bullets:
  - Power Apps Canvas app development
  - JSON folder structure parsing
  - 8-category organization with subcategories
  - Multi-user concurrent access
  - Real-time requirement validation
  - Auto-population from structured data
  - Export functionality
  - Compliance verification

- Added hard skills:
  - JSON Schema Design
  - Power Apps Canvas Development
  - Folder Structure Parsing

- Enhanced tools_technologies with JSON references

**Total impact:** 27 JSON references added across positions

#### v7.1 Creation (from v7.0)
**File:** `chat-history/claude_generated_job_history_summaries_v7.1.txt`
**Version:** 7.1 (TEMPLATE SYSTEM & WORKFLOW AUTOMATION)
**Lines:** 1,360+
**Date:** January 2, 2026

**Changes applied:**

**Position 0 (Current Role) - Template System Achievement:**
- Added Achievement #8 (template_system_automation):
  - **Context:** Job history generation across multiple LLMs lacked consistency and standardization
  - **Action:**
    - Created XML schema template defining exact structure
    - Authored 3,500+ word LLM instruction guide
    - Built Python validation script (226 lines)
    - Developed conversion script (.txt → .md)
    - Created two workflow skills (/md-job-history, /update-history)
  - **Result:**
    - 4 template files created
    - 2 Python scripts (validation + conversion)
    - 2 workflow skills documented
    - Dual-format output system established
  - **Impact:**
    - Solved cross-platform consistency problem
    - Ensured Claude, Gemini, ChatGPT, Copilot generate identical structure
    - Automated validation prevents schema drift
    - Template system prevents structural drift as LLM technology evolves

- Enhanced hard_skills_demonstrated:
  - Added "Python 3 (Scripting, Automation, Validation)"
  - Added "Schema Design & Template Systems"
  - Added "Cross-Platform Standardization"
  - Added "Technical Documentation (3,500+ word guides)"

- Enhanced tools_technologies:
  - Added "Python 3 (Validation & Conversion Scripts)" to development_tools category

**Files generated:**
- `chat-history/claude_generated_job_history_summaries_v7.1.txt`
- `chat-history/claude_generated_job_history_summaries_v7.1.md`

---

## 5. Implementation Timeline

### Session Chronology (January 2, 2026)

**Phase 1: v6 Creation** ✅
- Discussed natural language development emphasis
- Created v6.0 from v5.0
- Fixed missing positions (appended from v3)

**Phase 2: v7 Creation** ✅
- Identified JSON/Power Platform work
- Discovered Foxhole Technology context
- Added CI/CD details to Position 3
- Created v7.0 with surgical updates

**Phase 3: Template System** ✅
- Discussed file format (.txt vs .xml vs .md)
- Decided on dual-format approach
- Created XML schema template
- Created Markdown template
- Authored 3,500+ word LLM instructions
- Built Python validation script
- Built Python conversion script
- Created templates/README.md
- Generated v7.md from v7.txt

**Phase 4: Workflow Automation** ✅
- Created /md-job-history skill
- Created /update-history skill
- Documented both workflows

**Phase 5: v7.1 Creation** ✅
- User requested /update-history before chat compaction
- Created v7.1 with template system achievement
- Validated v7.1.txt (✅ PASSED)
- Converted to v7.1.md

**Phase 6: Patch Documentation** 🔄 (Current)
- Created patch branch
- Creating this plan document
- Next: Update Prompt Instructions
- Next: Update quick-start-guide
- Next: Run /doc-update

---

## 6. Testing & Validation

### Validation Test Results

**v7.0 Validation:**
```bash
$ python3 scripts/validate_job_history.py chat-history/claude_generated_job_history_summaries_v7.txt

✅ VALIDATION PASSED
Job history file matches template schema!

✓ INFO (8):
  ✓ Header found
  ✓ Version history found
  ✓ Found 5 version entries
  ✓ Section 'education' found
  ✓ Section 'certifications' found
  ✓ Section 'master_skills_inventory' found
  ✓ Found 6 positions
  ✓ All XML tags are balanced
```

**v7.1 Validation:**
```bash
$ python3 scripts/validate_job_history.py chat-history/claude_generated_job_history_summaries_v7.1.txt

✅ VALIDATION PASSED
Job history file matches template schema!

✓ INFO (8):
  ✓ Header found
  ✓ Version history found
  ✓ Found 6 version entries
  ✓ Section 'education' found
  ✓ Section 'certifications' found
  ✓ Section 'master_skills_inventory' found
  ✓ Found 6 positions
  ✓ All XML tags are balanced
```

### Conversion Test Results

**v7.0 Conversion:**
```bash
$ python3 scripts/convert_job_history_to_md.py chat-history/claude_generated_job_history_summaries_v7.txt

✅ Converted chat-history/claude_generated_job_history_summaries_v7.txt
   to chat-history/claude_generated_job_history_summaries_v7.md
```

**v7.1 Conversion:**
```bash
$ python3 scripts/convert_job_history_to_md.py chat-history/claude_generated_job_history_summaries_v7.1.txt

✅ Converted chat-history/claude_generated_job_history_summaries_v7.1.txt
   to chat-history/claude_generated_job_history_summaries_v7.1.md
```

### Manual Testing Checklist

- [x] XML template defines all required sections
- [x] Markdown template matches XML structure
- [x] LLM instructions are comprehensive (3,500+ words)
- [x] Validation script catches missing sections
- [x] Validation script catches unbalanced tags
- [x] Conversion script generates proper Markdown
- [x] Conversion script creates emoji headers
- [x] Conversion script formats metrics as tables
- [x] /md-job-history skill documented
- [x] /update-history skill documented
- [x] v7.0 validates successfully
- [x] v7.1 validates successfully
- [x] v7.0 converts to Markdown successfully
- [x] v7.1 converts to Markdown successfully

---

## 7. Documentation Updates Needed

### Files to Update

#### `.claude/Prompt Instructions.md`
**Section:** Job History Management
**Add:**
- Template system overview
- Reference to templates/README.md
- Validation workflow
- Conversion workflow
- /md-job-history skill usage
- /update-history skill usage
- Best practices for maintaining consistency

#### `docs/quick-start-guide.md`
**Section:** Job History
**Add:**
- Template system introduction
- How to generate job history following templates
- Validation instructions
- Conversion instructions
- Workflow skill references
- Examples of surgical updates

#### `CHANGELOG.md`
**Add v6.2.0 entry:**
```markdown
## [6.2.0] - 2026-01-02

### Added - Job History Template System & Workflow Automation
- Created comprehensive template system ensuring cross-LLM consistency
  - XML schema template (templates/job_history_template.xml)
  - Markdown template (templates/job_history_template.md)
  - LLM generation instructions (templates/LLM_GENERATION_INSTRUCTIONS.md - 3,500+ words)
  - Template system README (templates/README.md)
- Built Python automation tools
  - Validation script (scripts/validate_job_history.py - 226 lines)
  - Conversion script (scripts/convert_job_history_to_md.py - 400+ lines)
- Created workflow automation skills
  - /md-job-history - Convert job history to Markdown
  - /update-history - Intelligent version management
- Updated job history with new achievements
  - v7.0: JSON/Power Platform additions + CI/CD details (27 JSON references)
  - v7.1: Template system achievements

### Changed
- Job history now dual-format: .txt (XML) for LLMs, .md (Markdown) for humans
- Established surgical update strategy (preserve existing content)
- Standardized version increment rules (MAJOR/MINOR/PATCH)
```

#### `ROADMAP.md`
**Mark complete:**
- [ ] Job history template system
- [ ] Automated validation
- [ ] Markdown conversion
- [ ] /update-history workflow

**Consider adding:**
- [ ] HTML export with CSS styling
- [ ] PDF generation from Markdown
- [ ] Automated version increment suggestions
- [ ] Diff tool to compare versions

---

## 8. Lessons Learned

### Workflow Insight
**Lesson:** "Whenever the coding assistant asks to run a process, always run whatever is based on the chat history first so it is not lost when compacted."

**Context:** User recognized risk of losing template system context during chat compaction and requested running /update-history before continuing with /patch workflow.

**Application:** Always prioritize capturing chat-based work in permanent artifacts before continuing with new tasks.

### Surgical Enhancement Strategy
**Lesson:** "Do not completely rewrite... only update existing items or add new ones."

**Context:** User emphasized preservation of existing content throughout v6, v7, v7.1 creation.

**Application:** All job history updates use INSERT/ADD operations, not rewrites. Template system codifies this as "surgical updates."

### Dual-Format Architecture
**Lesson:** Optimize for both machine and human readability by maintaining source + generated versions.

**Context:** .txt (XML) provides semantic precision for LLMs, .md (Markdown) provides readability for humans.

**Application:** Keep .txt as source of truth, generate .md for presentations. Version control both, but .txt is authoritative.

---

## 9. Risk Assessment

### Low Risk
- Template system is documentation-only (no code changes)
- Python scripts are standalone utilities (no dependencies on main codebase)
- Skills are opt-in workflows (don't affect existing functionality)
- Job history updates are additive (no content removed)

### Medium Risk
- Skills not yet registered with Claude Code system
- Need user guidance on skill registration process
- Template adoption requires LLM awareness of new instructions

### Mitigation
- Skills work manually even if not registered
- Template files are well-documented with examples
- Validation script catches schema violations immediately
- Previous versions (v5, v6, v7.0) preserved

---

## 10. Success Criteria

### Must Have ✅
- [x] XML schema template created
- [x] Markdown template created
- [x] LLM instructions comprehensive (3,500+ words)
- [x] Validation script functional
- [x] Conversion script functional
- [x] Both skills documented
- [x] v7.0 created with JSON/CI/CD additions
- [x] v7.1 created with template achievements
- [x] All validation tests pass
- [x] All conversion tests pass

### Should Have 🔄
- [ ] Prompt Instructions updated
- [ ] Quick-start-guide updated
- [ ] CHANGELOG.md updated
- [ ] ROADMAP.md updated
- [ ] /doc-update executed

### Nice to Have ⏳
- [ ] Skills registered with Claude Code
- [ ] User documentation on skill registration
- [ ] Example of using templates with different LLM
- [ ] Video walkthrough of /update-history workflow

---

## 11. Rollback Plan

### If Template System Issues Arise

**Rollback steps:**
1. Previous versions preserved:
   - v5.txt (natural language development foundation)
   - v6.txt (complete version with all positions)
   - v7.0.txt (JSON/CI/CD additions)

2. Template files are additive (can be ignored):
   - Simply don't reference templates during generation
   - Continue with manual formatting

3. Scripts are standalone:
   - No integration with main codebase
   - Can be removed without impact

4. Skills are optional:
   - Workflows can be executed manually
   - Skill files can be deleted

### No Breaking Changes
- All changes are additive
- No existing functionality modified
- Previous versions available
- Manual workflows still functional

---

## 12. Next Steps

### Immediate (This Patch)
1. ✅ Create patch branch `v6.1.12-job-history-templates`
2. ✅ Create v7.1 with template system achievements
3. ✅ Validate v7.1.txt
4. ✅ Convert v7.1.txt to Markdown
5. 🔄 Create this plan document
6. ⏳ Update Prompt Instructions
7. ⏳ Update quick-start-guide
8. ⏳ Run /doc-update
9. ⏳ Commit all changes
10. ⏳ Merge to main

### Follow-up (Future Patches)
1. Test templates with Gemini/ChatGPT/Copilot
2. Create skill registration guide
3. Build HTML export functionality
4. Create PDF generation from Markdown
5. Develop diff tool for version comparison
6. Add GitHub Action for automatic validation

---

## 13. File Manifest

### Created Files

**Templates:**
- `templates/job_history_template.xml` (450+ lines)
- `templates/job_history_template.md` (300+ lines)
- `templates/LLM_GENERATION_INSTRUCTIONS.md` (350+ lines, 3,500+ words)
- `templates/README.md` (415 lines)

**Scripts:**
- `scripts/validate_job_history.py` (226 lines)
- `scripts/convert_job_history_to_md.py` (400+ lines)

**Skills:**
- `.claude/skills/md-job-history.md` (180 lines)
- `.claude/skills/update-history.md` (517 lines)

**Job History:**
- `chat-history/claude_generated_job_history_summaries_v7.txt` (1,354 lines)
- `chat-history/claude_generated_job_history_summaries_v7.md` (generated)
- `chat-history/claude_generated_job_history_summaries_v7.1.txt` (1,360+ lines)
- `chat-history/claude_generated_job_history_summaries_v7.1.md` (generated)

**Plans:**
- `docs/plans/v6.1.12_job-history-templates_plan.md` (this file)

### Modified Files
- None (all changes are new files)

### Total Lines of Code/Documentation
- Templates: ~1,515 lines
- Scripts: ~626 lines
- Skills: ~697 lines
- Job history: ~2,714 lines
- Plans: ~900+ lines
- **Total: ~6,452 lines created**

---

## 14. Approval

### Plan Status
- [x] Analysis complete
- [x] Implementation complete
- [x] Testing complete
- [ ] Documentation updates pending
- [ ] User approval pending

### Sign-off Required
- [ ] User approves plan documentation
- [ ] User approves Prompt Instructions updates
- [ ] User approves quick-start-guide updates
- [ ] User approves CHANGELOG entry
- [ ] Ready to merge to main

---

**Plan Created:** January 2, 2026
**Last Updated:** January 2, 2026
**Author:** Claude Sonnet 4.5
**Branch:** v6.2.0-job-history-templates
**Status:** Implementation Complete - Documentation Pending


# --- FILE: docs/plans/v6.3.0-adding_guardrails.md ---


# Guardrail & Validation Suggestions job history creation

Based on your request, I have refined the validation suggestions into specific, actionable guardrail instructions that can be directly integrated into the system's prompt architecture.

## 1. Metric Isolation & Traceability

> **Implementation Target:** Add to [job-history-creation.md](phases/phase-1/job-history-creation.md) (primary) and [evidence-matching.md](phases/phase-2/evidence-matching.md) (secondary).

### Specific Guardrail: The "Source-to-Output" Traceability Rule
**Instruction Text:**
```xml
<metric_traceability_guardrail>
  <instruction>
    For every numeric metric or specific achievement included in the output, you must perform an internal "source-check" before finalizing the draft.
  </instruction>
  <verification_steps>
    1. Identify the Job ID (Position N) for which you are writing.
    2. Scan ONLY the <position id="N"> block in the source job history.
    3. If the metric appears in any other position block, but NOT in block N, it is a HALLUCINATION and must be removed.
    4. Provide an internal "thinking" citation: [Metric X traced to Position N].
  </verification_steps>
</metric_traceability_guardrail>
```

---

## 2. Chronological Integrity

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) (primary, within `<position_ordering>` section) and [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md) (secondary).

### Specific Guardrail: Mandatory Pre-Draft Sorting Logic
**Instruction Text:**
```xml
<chronological_validation_guardrail>
  <priority>CRITICAL</priority>
  <pre_draft_step>
    Before drafting ANY position content, generate a "Sort Validation Table" in your internal thinking process:
    | Role Rank | Position ID | End Date | Start Date |
    |-----------|-------------|----------|------------|
    | 1 (Newest)| [ID]        | [Date]   | [Date]     |
    | 2         | [ID]        | [Date]   | [Date]     |
    
    Rule: Sort Order must be 'End Date' DESCENDING. If any End Date is later than the End Date of the position above it, the sort is invalid.
  </pre_draft_step>
</chronological_validation_guardrail>
```

---

## 3. Professional Summary Abstraction

> **Implementation Target:** Add to [summary-generation.md](phases/phase-4/summary-generation.md).

### Specific Guardrail: The 50/50 "Anti-Mirror" Rule
**Instruction Text:**
```xml
<summary_abstraction_guardrail>
  <instruction>
    The Professional Summary must function as an "Executive Synthesis," not a "Bullet Echo."
  </instruction>
  <constraints>
    - <constraint id="no_mirroring">No sentence in the summary can share more than 50% of its keywords with any single bullet point in the resume.</constraint>
    - <constraint id="synthesis_requirement">At least one sentence must synthesize metrics across multiple roles (e.g., "Led projects across [Industry A] and [Industry B], achieving [Cumulative Metric]").</constraint>
    - <constraint id="impact_first">Start sentences with the "Outcome" (The Why) rather than the "Action" (The How) to differentiate from bullets.</constraint>
  </constraints>
</summary_abstraction_guardrail>
```

---

## 4. Extended Validation Checks

> **Implementation Target:** Add to [metrics-requirements.md](core/metrics-requirements.md).

### Specific Guardrail: Rule-Metric Compatibility Heuristic
**Instruction Text:**
```xml
<validity_heuristic_check>
  <instruction>
    Perform a "Common Sense Audit" on metric-role pairings.
  </instruction>
  <audit_questions>
    - "Does it make sense for a [User_Role] to be personally responsible for [Result X]?"
    - "Is this metric too specific to a different job category (e.g., code coverage metrics in a PM role)?"
    - "If the metric is for a government role, does it strictly adhere to the Job History limitations for that specific agency?"
  </audit_questions>
</validity_heuristic_check>
```

---

---

# Part 2: Additional Guardrail Suggestions (Second Pass)

Upon further review, the following additional guardrails are proposed to strengthen data integrity and consistency.

## 5. honest_limitations Enforcement

> **Implementation Target:** Add to [evidence-matching.md](phases/phase-2/evidence-matching.md) (primary) and [job-history-creation.md](phases/phase-1/job-history-creation.md) (secondary).

### Specific Guardrail: The "Limitation Cross-Check"
To prevent the system from accidentally hallucinating a skill that the user explicitly listed as a "limitation" or "unknown" in an earlier phase.

**Instruction Text:**
```xml
<limitation_enforcement_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    Before finalizing any bullet point, cross-reference the generated content against the <honest_limitations> section of the target Position.
  </instruction>
  <logic>
    IF generated_bullet mentions [Skill X]
    AND <honest_limitations> contains "No experience with [Skill X]" OR "Limited exposure to [Skill X]"
    THEN:
      1. Flag as CONTRADICTION.
      2. Remove the claim or rephrase to match the limitation (e.g., "exposed to" instead of "expert in").
  </logic>
</limitation_enforcement_guardrail>
```

---

## 6. Data Loss Prevention during Updates

> **Implementation Target:** Add to [incremental-updates.md](phases/phase-3/incremental-updates.md).

### Specific Guardrail: The "Volume Preservation" Check
When performing "Surgical Updates" (Phase 3 Incremental Updates), there is a risk of accidentally truncating existing content.

**Instruction Text:**
```xml
<data_loss_prevention_protocol>
  <trigger>When executing /update-history or modifying existing positions</trigger>
  <verification_step>
    Compare the "Item Count" of the original vs. the new draft.
    
    Rule:
    - New `core_responsibilities` count >= Original count (unless deletion explicitly requested).
    - New `key_achievements` count >= Original count.
    
    IF New count < Original count:
      STOP and verify: "Did you intend to remove [Missing Item]?"
  </verification_step>
</data_loss_prevention_protocol>
```

---

## 7. Skill Categorization Consistency

> **Implementation Target:** Add to [jd-parsing.md](phases/phase-1/jd-parsing.md) (primary) and [verb-categories.md](core/verb-categories.md) (secondary).

### Specific Guardrail: Mutual Exclusivity Check
To ensure clean data separation between Hard and Soft skills.

**Instruction Text:**
```xml
<skill_classification_guardrail>
  <instruction>
    A single skill term cannot exist in both <hard_skills_demonstrated> and <soft_skills_demonstrated> within the same position.
  </instruction>
  <auto_correction>
    IF duplicates found:
    - Technical/Tools/Hard Skills -> Keep in <hard_skills_demonstrated>, remove from Soft.
    - Behavioral/Leadership/Interpersonal -> Keep in <soft_skills_demonstrated>, remove from Hard.
  </auto_correction>
</skill_classification_guardrail>
```

# Part 3: Additional Guardrail Suggestions (Third Pass - Claude)

After reviewing the existing guardrails and the full instruction set, I've identified several additional validation opportunities that focus on **quantitative constraints**, **position-level validation**, and **JD-specific quality checks**.

## 8. Character and Word Count Enforcement

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) within **EXISTING** `<quality_assurance_rules>` section (lines 11-50). **Do not create a new section.**

### Specific Guardrail: The "Budget Compliance" Gate
The system has clear limits (100-210 chars per bullet, 350-500 words total), but there's no explicit pre-output validation to enforce these.

**Instruction Text:**
```xml
<budget_enforcement_guardrail>
  <priority>HIGH</priority>
  <trigger>Before presenting final output</trigger>
  
  <per_bullet_validation>
    FOR EACH bullet:
      IF character_count < 100 OR character_count > 210:
        FLAG as "Out of range" and REGENERATE
        
    RULE: Zero tolerance for bullets outside 100-210 character range
  </per_bullet_validation>
  
  <total_word_count_validation>
    total_words = SUM(all_bullets.word_count)
    
    IF total_words > 500:
      STOP and apply reduction strategy:
        1. Identify oldest/weakest positions (4+ back)
        2. Reduce bullets from 3→2 or 2→1 for those positions
        3. Recalculate until total_words <= 500
        
    IF total_words < 350:
      FLAG as "Underutilized" - consider adding bullets to strongest positions
  </total_word_count_validation>
</budget_enforcement_guardrail>
```

---

## 9. Verb Diversity Per-Position Enforcement

> **Implementation Target:** Add to [verb-categories.md](core/verb-categories.md) (primary) and [format-rules.md](core/format-rules.md) (secondary).

### Specific Guardrail: The "No Repeat Category" Rule
The current `verb_diversity_rule` says to "maximize diversity" but doesn't explicitly prevent same-category repetition **within a single position**.

**Instruction Text:**
```xml
<position_verb_diversity_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Within a SINGLE position, no verb category may be used more than once.
  </instruction>
  
  <validation_logic>
    FOR EACH position:
      verb_categories_used = []
      
      FOR EACH bullet in position:
        category = identify_verb_category(bullet)
        
        IF category IN verb_categories_used:
          FLAG as "Duplicate category in position [N]"
          REGENERATE bullet using different category
        ELSE:
          verb_categories_used.append(category)
  </validation_logic>
  
  <exception>
    If position has 5+ bullets, allow ONE category to repeat (but still prefer diversity)
  </exception>
</position_verb_diversity_guardrail>
```

---

## 10. JD Keyword Density Validation

> **Implementation Target:** Add to [jd-parsing.md](phases/phase-1/jd-parsing.md) (primary) and [re-comparison.md](phases/phase-3/re-comparison.md) (secondary).

### Specific Guardrail: The "Keyword Saturation" Check
To prevent keyword stuffing while ensuring adequate coverage.

**Instruction Text:**
```xml
<keyword_density_guardrail>
  <priority>MODERATE</priority>
  <instruction>
    Validate that JD keywords are distributed naturally across bullets and summary.
  </instruction>
  
  <density_rules>
    <rule id="no_stuffing">
      No single bullet should contain more than 3 distinct JD keywords.
      IF bullet contains 4+ keywords: FLAG as "Keyword stuffing" and rephrase
    </rule>
    
    <rule id="minimum_coverage">
      Target: 8-12 unique JD keywords across entire output
      IF unique_keywords < 8: FLAG as "Insufficient keyword coverage"
    </rule>
    
    <rule id="natural_distribution">
      No keyword should appear more than 2 times across all bullets
      (Exception: Core role keywords that appear 5+ times in JD)
    </rule>
  </density_rules>
</keyword_density_guardrail>
```

---

## 11. Metrics Authenticity Cross-Check

> **Implementation Target:** Add to [metrics-requirements.md](core/metrics-requirements.md).

### Specific Guardrail: The "Plausibility Filter"
Beyond just checking if metrics exist in job history, validate they make logical sense.

**Instruction Text:**
```xml
<metric_plausibility_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Apply common-sense validation to numeric claims before output.
  </instruction>
  
  <plausibility_checks>
    <check id="percentage_range">
      All percentages must be 0-100%
      IF percentage > 100%: FLAG as "Implausible percentage"
    </check>
    
    <check id="time_savings">
      Time reduction claims must show valid before/after
      IF "reduced from X to Y" AND Y > X: FLAG as "Inverted time metric"
    </check>
    
    <check id="team_size_consistency">
      Team size should be consistent with role level
      IF role = "Junior" AND team_size > 10: FLAG for review
      IF role = "Senior/Lead" AND team_size = 0: FLAG as "Missing leadership scope"
    </check>
    
    <check id="currency_format">
      All currency values must include $ symbol and reasonable magnitude
      IF revenue_claim > $1B for individual contributor: FLAG for review
    </check>
  </plausibility_checks>
</metric_plausibility_guardrail>
```

---

## 12. Position Recency Weighting

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) within `<bullet_count_per_position>` section.

### Specific Guardrail: The "Freshness Priority" Rule
Ensure most recent positions get the most detailed treatment.

**Instruction Text:**
```xml
<recency_weighting_guardrail>
  <priority>MODERATE</priority>
  <instruction>
    Allocate bullets based on position recency and JD relevance.
  </instruction>
  
  <allocation_rules>
    <rule id="position_1_priority">
      Position 1 (most recent) should have:
        - Minimum 3 bullets
        - At least 2 quantified metrics
        - Strongest JD keyword matches
    </rule>
    
    <rule id="position_4_plus_constraint">
      Positions 4+ (older roles) should have:
        - Maximum 2 bullets (unless exceptionally relevant to JD)
        - Only include if directly relevant to JD requirements
    </rule>
    
    <validation>
      IF Position 1 has fewer bullets than Position 3+:
        FLAG as "Inverted recency priority" and rebalance
    </validation>
  </allocation_rules>
</recency_weighting_guardrail>
```

---

## 13. Summary-to-Bullets Metric Reconciliation

> **Implementation Target:** Add to [summary-generation.md](phases/phase-4/summary-generation.md).

### Specific Guardrail: The "Metric Consistency" Check
Ensure metrics mentioned in summary are actually supported by bullets.

**Instruction Text:**
```xml
<summary_metric_reconciliation_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Every quantified claim in the Professional Summary must be traceable to at least one bullet point.
  </instruction>
  
  <validation_process>
    1. Extract all metrics from Professional Summary (e.g., "10 years", "$5M", "500K+ users")
    2. FOR EACH metric in summary:
         Search all bullets for supporting evidence
         IF metric NOT found in any bullet:
           FLAG as "Unsupported summary claim"
           Options:
             A) Add supporting bullet
             B) Remove metric from summary
             C) Verify metric exists in job history and add to bullets
  </validation_process>
  
  <exception>
    Years of experience can be calculated from position dates without explicit bullet mention
  </exception>
</summary_metric_reconciliation_guardrail>
```

---

## 14. Automatic Quality Gate Iteration Limit

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) (primary, within **EXISTING** `<quality_assurance_rules>` section, lines 11-50, specifically enhance the `<automatic_quality_gate>` subsection) and [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md) (secondary). **Do not create a new section.**

### Specific Guardrail: The "Infinite Loop Prevention" Safety
The current `automatic_quality_gate` has a 3-iteration limit but doesn't specify what happens if fundamental issues persist.

**Instruction Text:**
```xml
<quality_gate_failure_protocol>
  <priority>CRITICAL</priority>
  <instruction>
    If quality gate fails after 3 iterations, provide diagnostic output to user.
  </instruction>
  
  <failure_handling>
    IF iterations >= 3 AND issues_remain:
      STOP regeneration loop
      
      OUTPUT to user:
        "⚠️ Quality Gate Alert
        
        After 3 regeneration attempts, the following issues persist:
        - [List specific issues: e.g., 'Position 2 has duplicate verb categories']
        - [List specific issues: e.g., 'Bullet 5 exceeds 210 character limit']
        
        This may indicate:
        1. Insufficient content in job history for this position
        2. JD requirements conflict with available experience
        3. Need for manual refinement
        
        Would you like me to:
        A) Present best attempt with warnings
        B) Skip this position
        C) Ask clarifying questions about [specific issue]"
  </failure_handling>
</quality_gate_failure_protocol>
```

---

## Summary of Third-Pass Additions

These 7 additional guardrails address:

1. **Quantitative Enforcement** (#8): Hard limits on character/word counts
2. **Position-Level Validation** (#9): Verb diversity within single positions
3. **Keyword Quality** (#10): Preventing stuffing while ensuring coverage
4. **Metric Plausibility** (#11): Common-sense validation of numeric claims
5. **Recency Logic** (#12): Ensuring newest positions get priority
6. **Cross-Reference Validation** (#13): Summary metrics must appear in bullets
7. **Failure Handling** (#14): Graceful degradation when quality gates fail repeatedly

These complement the earlier guardrails by adding **enforcement mechanisms** and **failure protocols** that were implicit but not explicitly defined.

# Part 4: Additional Guardrail Suggestions (Fourth Pass - Claude Extended Thinking)

After deep analysis of the instruction set and existing guardrails, I've identified critical gaps in **cross-phase consistency**, **phrase repetition enforcement**, **attribution accuracy**, and **skill inventory misuse**.

## 15. Phrase Repetition Enforcement

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) within **EXISTING** `<quality_assurance_rules>` section (lines 11-50). **Do not create a new section.**

### Specific Guardrail: The "Maximum-2-Occurrences" Scanner
The `phrase_variation_rule` states "maximum 2 times across entire resume" but there's no automated enforcement.

**Instruction Text:**
```xml
<phrase_repetition_enforcement_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Scan ALL bullets and summary for repeated multi-word phrases (3+ words).
  </instruction>
  
  <detection_logic>
    1. Extract all 3+ word sequences from bullets and summary
    2. Normalize: lowercase, remove punctuation
    3. Count occurrences of each sequence
    4. IF any sequence appears 3+ times:
         FLAG as "Excessive repetition: '[phrase]' appears [N] times"
         APPLY variation strategies from phrase_variation_rule
  </detection_logic>
  
  <variation_requirements>
    FOR sequences appearing 3+ times:
      - Keep in strongest/most-impactful position only
      - Replace in other positions with different achievements from those job histories
      - OR apply verb/format/structure variation strategies
  </variation_requirements>
  
  <example_phrases_to_track>
    - "version control"
    - "0% to 100%"
    - "reduced from X to Y"
    - "led team of"
    - "implemented system"
  </example_phrases_to_track>
</phrase_repetition_enforcement_guardrail>
```

---

## 16. Master Skills Inventory Quarantine

> **Implementation Target:** Add to [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md) (primary) and [evidence-matching.md](phases/phase-2/evidence-matching.md) (secondary).

### Specific Guardrail: The "Position-Evidence-Only" Rule
Prevents using `master_skills_inventory` when position-specific evidence is required.

**Instruction Text:**
```xml
<master_skills_quarantine_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    When generating bullets for Position N, ONLY use evidence from that position's sections.
    master_skills_inventory is QUARANTINED from bullet generation.
  </instruction>
  
  <allowed_sources_for_bullet_generation>
    FOR Position N bullets, ONLY reference:
      - position[N].tools_technologies
      - position[N].hard_skills_demonstrated
      - position[N].soft_skills_demonstrated
      - position[N].key_achievements
      - position[N].core_responsibilities
  </allowed_sources_for_bullet_generation>
  
  <forbidden_sources>
    NEVER reference for bullet generation:
      - master_skills_inventory (too generic, no position evidence)
      - Other positions' skills (cross-contamination)
  </forbidden_sources>
  
  <validation_check>
    BEFORE finalizing bullets for Position N:
      FOR EACH skill/tool mentioned in bullets:
        VERIFY: skill appears in position[N] sections
        IF skill only in master_skills_inventory:
          FLAG as "No position evidence for '[skill]' in Position [N]"
          REMOVE or ask user to confirm experience in this role
  </validation_check>
</master_skills_quarantine_guardrail>
```

---

## 17. Scope Attribution Validation

> **Implementation Target:** Add to [job-history-creation.md](phases/phase-1/job-history-creation.md).

### Specific Guardrail: The "Individual vs. Team" Boundary
Prevents claiming team/organizational achievements as individual accomplishments.

**Instruction Text:**
```xml
<scope_attribution_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Verify that claimed achievements match the user's actual scope of control.
  </instruction>
  
  <attribution_rules>
    <rule id="team_achievement_markers">
      IF bullet uses "Led", "Managed", "Coordinated", "Oversaw":
        VALID: Individual can claim this if they have leadership scope
        CHECK: Does position have team_scope.direct_reports > 0 OR team_scope.team_size > 0?
        IF NO team scope: FLAG as "Leadership claim without team scope evidence"
    </rule>
    
    <rule id="organizational_results">
      IF bullet claims company-wide metrics (e.g., "Increased company revenue by $5M"):
        VERIFY: User's role level justifies this claim
        IF role = Individual Contributor AND impact = company-wide:
          FLAG as "Overstated scope - change to 'Contributed to' or specify personal portion"
    </rule>
    
    <rule id="collaborative_work">
      IF job_history shows "honest_limitations" about limited autonomy:
        ENSURE bullets use collaborative language ("Contributed to", "Supported", "Assisted in")
        NOT ownership language ("Built", "Launched", "Delivered")
    </rule>
  </attribution_rules>
</scope_attribution_guardrail>
```

---

## 18. Cross-Phase Job History Consistency

> **Implementation Target:** Add to [workflow-router.md](phases/phase-3/workflow-router.md) (primary) and [entry-router.md](phases/phase-1/entry-router.md) (secondary).

### Specific Guardrail: The "No History Drift" Validator
Ensures job history doesn't change between phases without user input.

**Instruction Text:**
```xml
<cross_phase_consistency_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    Job history generated in Phase 1 is immutable unless user explicitly updates it.
  </instruction>
  
  <phase_transition_validation>
    <phase_1_to_phase_2>
      WHEN: User requests bullet optimization (Phase 2)
      CHECK: Reference job history, do NOT modify it
      RULE: If bullet mentions skills not in job history, ask user to confirm before adding
    </phase_1_to_phase_2>
    
    <phase_1_to_phase_3>
      WHEN: User requests JD comparison (Phase 3)
      CHECK: Pull job history as-is for evidence matching
      RULE: Do NOT add new positions or skills to job history during Phase 3
      EXCEPTION: User explicitly says "I also have experience with X" - then offer to update
    </phase_1_to_phase_3>
  </phase_transition_validation>
  
  <drift_detection>
    IF Phase 3 bullets mention skills not in Phase 1 job history:
      STOP and ask: "I don't see [skill] in your job history. Should I add it to [Position N]?"
      WAIT for user confirmation before proceeding
  </drift_detection>
</cross_phase_consistency_guardrail>
```

---

## 19. Fit Assessment Score Consistency

> **Implementation Target:** Add to [fit-thresholds.md](core/fit-thresholds.md).

### Specific Guardrail: The "Score Justification" Requirement
Ensures fit percentages match the described gaps.

**Instruction Text:**
```xml
<fit_score_consistency_guardrail>
  <priority>MODERATE</priority>
  <instruction>
    Fit assessment score must be mathematically consistent with identified gaps.
  </instruction>
  
  <consistency_check>
    AFTER calculating preliminary fit score:
      1. Count total JD requirements (N_total)
      2. Count matched requirements (N_matched)
      3. Calculate: expected_score = (N_matched / N_total) * 100
      4. Compare to stated fit score
      
      IF |expected_score - stated_score| > 10%:
        FLAG as "Score-gap mismatch"
        RECALCULATE using proper weighting (Required: 1.5x, Preferred: 1.0x)
  </consistency_check>
  
  <score_to_action_validation>
    IF fit_score >= 90% BUT gaps section shows 3+ critical missing requirements:
      FLAG as "Score too high for number of critical gaps"
      
    IF fit_score < 75% BUT gaps section shows only 1-2 minor missing skills:
      FLAG as "Score too low for minor gaps"
  </score_to_action_validation>
</fit_score_consistency_guardrail>
```

---

## 20. Acronym Expansion Enforcement

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) within `<critical_formatting_rules>` section (separate from the existing `<quality_assurance_rules>` section at lines 11-50).

### Specific Guardrail: The "First-Use Spell-Out" Rule
Enforces that acronyms are spelled out on first use, especially for non-standard terms.

**Instruction Text:**
```xml
<acronym_expansion_guardrail>
  <priority>MODERATE</priority>
  <instruction>
    Industry-standard acronyms (AWS, SQL, API) can be used as-is.
    Domain-specific or ambiguous acronyms must be spelled out on first use.
  </instruction>
  
  <standard_acronyms_allowed>
    AWS, SQL, API, REST, JSON, XML, HTML, CSS, CI/CD, DevOps, SaaS, PaaS,
    ATS, KPI, ROI, SLA, ETL, GDPR, HIPAA, SOC, NIST
  </standard_acronyms_allowed>
  
  <expansion_required>
    FOR acronyms NOT in standard list:
      - First mention: "Federal Information Security Management Act (FISMA)"
      - Subsequent: "FISMA"
      
    EXCEPTION: If acronym appears in JD without expansion, match JD format
  </expansion_required>
  
  <validation>
    SCAN all bullets for uppercase 2-5 letter sequences
    IF sequence NOT in standard_acronyms_allowed:
      IF first occurrence in resume:
        FLAG: "Acronym '[ABC]' should be spelled out on first use"
  </validation>
</acronym_expansion_guardrail>
```

---

## 21. Limitation-to-Bullet Cross-Check

> **Implementation Target:** Add to [evidence-matching.md](phases/phase-2/evidence-matching.md) (primary) and [incremental-updates.md](phases/phase-3/incremental-updates.md) (secondary).

### Specific Guardrail: The "Don't Contradict Yourself" Validator
Ensures bullets don't recommend skills for positions where user stated limitations.

**Instruction Text:**
```xml
<limitation_bullet_cross_check_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    During Phase 3 bullet generation, check honest_limitations BEFORE recommending bullets for each position.
  </instruction>
  
  <validation_logic>
    WHEN generating bullets for Position N in Phase 3:
      1. Load position[N].honest_limitations
      2. Extract JD requirements
      3. FOR EACH JD requirement:
           IF requirement mentions skill/tool in honest_limitations:
             DO NOT generate bullet for Position N using this requirement
             ADD to gap analysis: "Position [N] limited: [limitation text]"
  </validation_logic>
  
  <example_scenario>
    JD requires: "Python, AWS, Docker"
    Position 2 honest_limitations: "Limited Python exposure (used only for scripts)"
    
    CORRECT behavior:
      - Generate bullets for Positions 1, 3, 4 using Python if evidenced
      - SKIP Python bullets for Position 2
      - OR use hedged language: "Supported Python script development"
      
    INCORRECT behavior:
      - Generate "Built Python applications" for Position 2 (contradicts limitation)
  </example_scenario>
</limitation_bullet_cross_check_guardrail>
```

---

## Summary of Fourth-Pass Additions

These 7 additional guardrails address **overlooked enforcement gaps**:

1. **Phrase Repetition Enforcement (#15)**: Automated scanner for 3+ word sequences appearing >2 times
2. **Master Skills Quarantine (#16)**: Prevents generic skill inventory from contaminating position-specific bullets
3. **Scope Attribution (#17)**: Validates individual vs. team/org achievement claims
4. **Cross-Phase Consistency (#18)**: Prevents job history drift between Phase 1→2→3
5. **Fit Score Consistency (#19)**: Ensures percentage scores match identified gaps
6. **Acronym Expansion (#20)**: Enforces spell-out rules for non-standard acronyms
7. **Limitation-to-Bullet Cross-Check (#21)**: Prevents generating bullets that contradict stated limitations

**Key Insight**: These guardrails focus on **consistency enforcement across time** (cross-phase), **attribution accuracy** (team vs. individual), and **automated detection** for rules that were stated but not enforced.

# Part 5: Additional Guardrail Suggestions (Fifth Pass)

This pass focuses on **output format enforcement**, **user state management**, and **conversation flow consistency**.

## 22. Em-Dash Character Validation

> **Implementation Target:** Add to [format-rules.md](core/format-rules.md) within **EXISTING** `<quality_assurance_rules>` section (lines 11-50) as automated enforcement for the existing `no_em_dashes` rule in `<critical_formatting_rules>`. **Do not create a new section.**

### Specific Guardrail: The "No Em-Dash" Scanner
The rule exists but has no automated enforcement mechanism.

**Instruction Text:**
```xml
<em_dash_validation_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Scan ALL output text for em-dash characters (—) before presenting to user.
  </instruction>
  
  <detection_and_correction>
    SCAN final output for Unicode character U+2014 (—)
    
    IF em-dash found:
      FOR EACH occurrence:
        REPLACE with hyphen (-) OR rephrase sentence
        
    COMMON PATTERNS TO FIX:
      - "experience — including" → "experience, including" OR "experience - including"
      - "skills—Python" → "skills: Python" OR "skills - Python"
      - "2020—2023" → "2020-2023"
  </detection_and_correction>
  
  <also_check>
    - En-dash (–) U+2013: Replace with hyphen for ranges
    - Curly quotes (" ") U+201C/U+201D: Replace with straight quotes
    - Curly apostrophe (') U+2019: Replace with straight apostrophe
  </also_check>
</em_dash_validation_guardrail>
```

---

## 23. User State Persistence Validation

> **Implementation Target:** Add to [workflow-router.md](phases/phase-3/workflow-router.md) (primary) and [entry-router.md](phases/phase-1/entry-router.md) (secondary). Add state tracking to the Context State Schema section.

### Specific Guardrail: The "Remember User Context" Check
Ensures location preferences and other user-stated constraints are consistently applied.

**Instruction Text:**
```xml
<user_state_persistence_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    User-stated preferences (location, remote preference, target roles) must be retained and applied across all phases.
  </instruction>
  
  <state_to_track>
    - user.location_preference: "Remote only", "Hybrid OK", "On-site OK"
    - user.current_location: State/City
    - user.target_role_level: "IC", "Lead", "Manager", "Director"
    - user.industry_focus: List of preferred industries
    - user.years_of_experience: Calculated from job history
  </state_to_track>
  
  <validation_at_each_phase>
    PHASE 1: Extract and store user state from resume/conversation
    PHASE 2: Reference user state when suggesting bullet alternatives
    PHASE 3: Apply user state to JD fit assessment (location blocking, role level match)
    
    IF user state is unknown AND required for decision:
      ASK before proceeding: "Are you open to on-site roles, or seeking remote only?"
  </validation_at_each_phase>
  
  <consistency_check>
    IF Phase 3 recommends role that conflicts with Phase 1 user state:
      FLAG as "Recommendation conflicts with user preferences"
      DO NOT proceed without acknowledgment
  </consistency_check>
</user_state_persistence_guardrail>
```

---

## 24. Alternatives Presentation Consistency (Enhanced)

> **Implementation Target:** Add to [evidence-matching.md](phases/phase-2/evidence-matching.md) (primary) and [verb-categories.md](core/verb-categories.md) (secondary). This replaces simple alternative generation with context-aware filtering.

### Specific Guardrail: Context-Aware Alternative Filtering
Ensures alternatives adhere to verb diversity rules and avoid recommending saturated categories.

**Instruction Text:**
```xml
<alternatives_presentation_guardrail>
  <priority>HIGH</priority>
  <instruction>
    When optimizing bullets, present at least 2 alternatives that respect existing verb category usage.
  </instruction>
  
  <step_1_build_category_inventory>
    BEFORE generating alternatives, calculate:
      - global_category_counts = {Built: N, Lead: N, Managed: N, Improved: N, Collaborate: N}
      - position_category_usage = {Position1: [categories used], Position2: [...], ...}
      - saturation_threshold = (total_bullets / 5) + 1  <!-- Approx 27% per category -->
  </step_1_build_category_inventory>
  
  <step_2_identify_unavailable_categories>
    unavailable_categories = []
    
    FOR EACH category in global_category_counts:
      IF count >= saturation_threshold:
        ADD to unavailable_categories
        REASON: "Approaching 40% skew threshold"
        
    FOR current_position:
      FOR EACH category already used in this position:
        ADD to unavailable_categories (for THIS position only)
        REASON: "Already used in this position"
  </step_2_identify_unavailable_categories>
  
  <step_3_generate_from_available_pool>
    available_categories = ALL_CATEGORIES - unavailable_categories
    
    <!-- LOOP PREVENTION: Escape hatch when all saturated -->
    IF available_categories.length == 0:
      WARN: "All categories at saturation - using least-used category"
      available_categories = [category with lowest global count]
      
    PRIMARY: Best natural fit from available_categories
    ALTERNATIVE 1: Next best fit from available_categories
    ALTERNATIVE 2 (optional): Third option OR different focus (outcome vs action)
  </step_3_generate_from_available_pool>
  
  <validation>
    IF output contains only 1 bullet version per input:
      FLAG as "Missing alternative angles" and REGENERATE
  </validation>
</alternatives_presentation_guardrail>
```

### Sub-Guardrails for #24

```xml
<alternatives_sub_guardrails>
  
  <sub_guardrail id="24A" name="underused_category_promotion">
    <priority>MODERATE</priority>
    <instruction>
      If any category has 0 uses across all bullets and we're generating Alternative 2,
      force-include an option using the underused category.
    </instruction>
    <loop_risk>LOW - additive only, does not block other options</loop_risk>
  </sub_guardrail>
  
  <sub_guardrail id="24B" name="same_position_history_check">
    <priority>HIGH</priority>
    <instruction>
      Before suggesting a category for Position N, verify Position N doesn't already
      have an accepted bullet using that category.
    </instruction>
    <loop_risk>LOW - read-only check, no writes until user accepts</loop_risk>
  </sub_guardrail>
  
  <sub_guardrail id="24C" name="jd_alignment_tiebreaker">
    <priority>MODERATE</priority>
    <instruction>
      When 2+ categories are equally "available", prefer the one that matches JD keywords.
      Example: JD mentions "led" 5 times → prefer Lead category over Managed.
    </instruction>
    <loop_risk>NONE - selection logic only, no state changes</loop_risk>
  </sub_guardrail>
  
  <sub_guardrail id="24D" name="saturation_warning_message">
    <priority>LOW</priority>
    <instruction>
      When a category is deprioritized due to saturation, include informational note:
      "Note: 'Built' verbs have been used 4 times; consider 'Led' or 'Improved' for variety."
    </instruction>
    <loop_risk>NONE - informational only, no logic changes</loop_risk>
  </sub_guardrail>
  
</alternatives_sub_guardrails>
```

### Loop Prevention Principles for #24

```xml
<loop_prevention_principles>
  <principle id="soft_limits">
    Use SOFT constraints (deprioritize) not HARD blocks for global category counts.
    Position-level: Hard constraint (never repeat within position)
    Global-level: Soft constraint (deprioritize, don't block entirely)
  </principle>
  
  <principle id="escape_hatch">
    If ALL categories are "unavailable", fall back to least-used category.
    Never return "no valid alternatives" error.
  </principle>
  
  <principle id="one_way_data_flow">
    Alternatives guardrail READS verb inventory but does NOT WRITE to it.
    Writing only occurs when user ACCEPTS a recommendation.
  </principle>
  
  <principle id="no_premature_counting">
    Do NOT count alternatives as "used" before user selection.
    Only accepted bullets update the category inventory.
  </principle>
</loop_prevention_principles>
```

### Anti-Patterns to Avoid

| Anti-Pattern | Why It Causes Loops |
|--------------|---------------------|
| Hard blocking categories after N uses | Could result in "no valid alternatives" error |
| Auto-regeneration when alternatives don't meet diversity | Creates feedback loop with quality gate |
| Counting alternatives before user accepts | Depletes inventory before selections made |

---

## 25. User Confirmation Tracking

> **Implementation Target:** Add to [workflow-router.md](phases/phase-3/workflow-router.md) (primary) and [entry-router.md](phases/phase-1/entry-router.md) (secondary). Add tracking state to the Context State Schema.

### Specific Guardrail: The "Don't Ask Twice" Memory
Prevents repeatedly asking user the same clarifying question.

**Instruction Text:**
```xml
<confirmation_tracking_guardrail>
  <priority>MODERATE</priority>
  <instruction>
    Track user confirmations within session to avoid redundant questions.
  </instruction>
  
  <tracking_logic>
    MAINTAIN list: confirmed_skills = []
    
    WHEN user confirms experience:
      ADD to confirmed_skills: {skill: "Python", position: "all", confirmed_at: timestamp}
      
    BEFORE asking "Do you have experience with [X]?":
      CHECK: Is [X] in confirmed_skills?
      IF YES: Skip question, use confirmed experience
      IF NO: Ask user
  </tracking_logic>
  
  <session_scope>
    confirmed_skills persists within conversation session
    RESET on: new conversation, explicit "start fresh" command
  </session_scope>
  
  <anti_pattern_detection>
    IF same question asked 2+ times in session:
      FLAG as "Duplicate clarification request"
      CHECK confirmation_tracking for existing answer
  </anti_pattern_detection>
</confirmation_tracking_guardrail>
```

---

## 26. Output Structure Consistency

> **Implementation Target:** Add to [LLM_GENERATION_INSTRUCTIONS.md](templates/LLM_GENERATION_INSTRUCTIONS.md). Add phase-specific output templates as new sections.

### Specific Guardrail: The "Template Adherence" Validator
Ensures all outputs follow expected structure patterns.

**Instruction Text:**
```xml
<output_structure_consistency_guardrail>
  <priority>HIGH</priority>
  <instruction>
    All phase outputs must follow their defined structure templates.
  </instruction>
  
  <phase_3_bullet_output_template>
    REQUIRED SECTIONS (in order):
      1. JD Summary (company, role, key requirements)
      2. Fit Assessment (score, match breakdown)
      3. Gap Analysis (if score < 90%)
      4. Professional Summary (customized for JD)
      5. Position Bullets (reverse chronological)
      6. Keyword Coverage Report (if keywords provided)
      7. Metadata (character counts, verb distribution)
      8. Grammar Check Reminder
      
    IF any section missing:
      FLAG as "Incomplete output structure"
      ADD missing section before presenting
  </phase_3_bullet_output_template>
  
  <plain_text_export_template>
    REQUIRED ELEMENTS:
      - Professional Summary (no markdown)
      - Positions with headers (Title | Company | Dates)
      - Bullets with • character
      - Metadata block at bottom
      
    FORBIDDEN ELEMENTS:
      - Markdown formatting (**, _, #)
      - Code blocks
      - Escaped characters (\~)
  </plain_text_export_template>
</output_structure_consistency_guardrail>
```

---

## 27. Graceful Input Type Detection

> **Implementation Target:** Add to [workflow-router.md](phases/phase-3/workflow-router.md) (primary) and [entry-router.md](phases/phase-1/entry-router.md) (secondary). Enhance the JD Validation Heuristics section.

### Specific Guardrail: The "What Did You Give Me?" Validator
Improves handling of ambiguous user inputs.

**Instruction Text:**
```xml
<input_type_detection_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Before processing user input, classify input type with confidence score.
  </instruction>
  
  <classification_rules>
    <type id="resume">
      INDICATORS: Multiple positions, dates, bullet points, education section
      CONFIDENCE: HIGH if 3+ positions detected
    </type>
    
    <type id="job_description">
      INDICATORS: "About the role", "Requirements", "Qualifications", company name + job title
      CONFIDENCE: HIGH if requirements section detected
    </type>
    
    <type id="bullet_points">
      INDICATORS: 1-5 isolated bullet points, no position context
      CONFIDENCE: HIGH if starts with action verb, no date range
    </type>
    
    <type id="keyword_list">
      INDICATORS: Comma-separated skills, no sentences
      CONFIDENCE: HIGH if >5 items, mostly single words/short phrases
    </type>
  </classification_rules>
  
  <ambiguity_handling>
    IF confidence < 80% for all types:
      ASK: "I received your input but want to confirm - is this a [most likely type] or something else?"
      WAIT for confirmation before proceeding
      
    IF input contains BOTH JD and keywords:
      PARSE separately, apply keyword_input_handling rules
  </ambiguity_handling>
</input_type_detection_guardrail>
```

---

## Summary of Fifth-Pass Additions

These 6 additional guardrails address **user experience consistency**:

1. **Em-Dash Validation (#22)**: Automated scanner for forbidden Unicode characters
2. **User State Persistence (#23)**: Location/role preferences tracked across phases
3. **Alternatives Presentation (#24)**: Ensures bullet optimization offers multiple angles
4. **Confirmation Tracking (#25)**: Prevents asking same clarifying question twice
5. **Output Structure Consistency (#26)**: Template adherence for all phase outputs
6. **Input Type Detection (#27)**: Confidence-based classification of user inputs

**Key Insight**: These guardrails focus on **conversation quality** and **format consistency** - ensuring the system behaves predictably and respects user context throughout the session.

---

# Guardrail Summary (All Passes)

| Pass | Focus Area | Guardrails Added |
|------|-----------|------------------|
| 1 | Data Integrity | #1-4: Metric traceability, chronological order, summary abstraction, metric compatibility |
| 2 | Data Safety | #5-7: Limitation enforcement, data loss prevention, skill classification |
| 3 | Quantitative Enforcement | #8-14: Character limits, verb diversity, keyword density, plausibility, recency, reconciliation, failure handling |
| 4 | Cross-Phase Consistency | #15-21: Phrase repetition, master skills quarantine, scope attribution, phase consistency, fit scores, acronyms, limitations |
| 5 | User Experience | #22-27: Em-dash validation, user state, alternatives, confirmation tracking, output structure, input detection |

**Total: 27 Guardrails**

---

> [!NOTE]
> **Condensation Rule:** A high-level implementation of ALL 27 guardrails should also be added to:
> - [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md) within `<quality_assurance_rules>` section (lines 997-1320)
> - [quick-start-phase.md](quick-start-phase.md) within `<quality_assurance_rules>` section (lines 373-507)
> 
> Both files also share `<position_ordering>` sections that should include Guardrail #2 (Chronological Integrity):
> - PROJECT-INSTRUCTIONS.md lines 1363-1366
> - quick-start-phase.md lines 550-553





# --- FILE: docs/plans/v6.3.0-change-audit-report.md ---


# v6.3.0 Guardrails Implementation - Change Audit Report

**Generated:** 2026-01-03 13:33
**Purpose:** Audit Gemini's guardrail implementation to verify no content was removed or summarized incorrectly

---

## Executive Summary

### Issue #1: File Naming
- **Old file:** `v6.3-adding_guardrails.md` (should be deleted)
- **New file:** `v6.3.0-adding_guardrails.md` (canonical version)
- **Status:** Both files exist locally with **identical content** (44,152 bytes each)
- **Action Required:** Delete `v6.3-adding_guardrails.md`

### Issue #2: Content Change Analysis
After comparing the committed version (HEAD) with local changes, I found the following:

| Category | Finding | Risk Level |
|----------|---------|------------|
| Absolute Path Fixes | 29 file paths converted from `file:///Users/mkaplan/...` to relative paths | ✅ CORRECT - No content loss |
| Guardrail Rewrites | 3 guardrails have **modified XML content** | ⚠️ REVIEW REQUIRED |
| New Content | 27 guardrails added to `PROJECT-INSTRUCTIONS.md` and `quick-start-phase.md` | ✅ ADDITIONS ONLY |

---

## Detailed Findings

### A. Absolute Path Conversions (✅ Safe - No Content Impact)

The following changes ONLY convert absolute paths to relative paths. **No content was removed.**

| File | Lines Changed | Type |
|------|---------------|------|
| `phases/phase-2/evidence-matching.md` | 5 lines | Path fixes only |
| `phases/phase-3/workflow-router.md` | 4 lines | Path fixes only |
| `phases/phase-3/incremental-updates.md` | 3 lines | Path fixes only |
| `phases/phase-4/summary-generation.md` | 3 lines | Path fixes only |
| `phases/phase-1/jd-parsing.md` | 2 lines | Path fixes only |
| `phases/phase-1/job-history-creation.md` | 3 lines | Path fixes only |
| `core/verb-categories.md` | 3 lines | Path fixes only |
| `docs/plans/v6.3-adding_guardrails.md` | ~20 lines | Path fixes only |

**Example of path fix (no content impact):**
```diff
- > **Implementation Target:** Add to [evidence-matching.md](file:///Users/mkaplan/Documents/GitHub/optimize-my-resume/phases/phase-2/evidence-matching.md)
+ > **Implementation Target:** Add to [evidence-matching.md](phases/phase-2/evidence-matching.md)
```

---

### B. Guardrail Content Modifications (⚠️ Review Required)

The following guardrails have **substantive content changes** beyond path fixes:

#### 1. Guardrail #6: Data Loss Prevention (incremental-updates.md)

**BEFORE (Committed Version):**
```xml
<data_loss_prevention_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    Ensure that adding or editing a position does not overwrite or delete unrelated existing data.
  </instruction>
  
  <validation_logic>
    BEFORE saving finalized job history:
    1. LOAD original file.
    2. PERFORM 'Integrity Check':
       - count_before = total_positions
       - count_after = (total_positions + 1) [for Add] OR (total_positions) [for Edit]
       - IF count_after is unexpected:
         ABORT save.
         RE-SYNC with original file and RETRY update logic.
    3. SEARCH for "Placeholder" text or empty [brackets] in fields that were NOT part of the current update.
       IF found:
         BLOCK save and restore from backup.
  </validation_logic>
</data_loss_prevention_guardrail>
```

**AFTER (Local Version):**
```xml
<data_loss_prevention_protocol>
  <trigger>When executing /update-history or modifying existing positions</trigger>
  <verification_step>
    Compare the "Item Count" of the original vs. the new draft.
    
    Rule:
    - New `core_responsibilities` count >= Original count (unless deletion explicitly requested).
    - New `key_achievements` count >= Original count.
    
    IF New count < Original count:
      STOP and verify: "Did you intend to remove [Missing Item]?"
  </verification_step>
</data_loss_prevention_protocol>
```

**Analysis:**
| Aspect | Original | New | Impact |
|--------|----------|-----|--------|
| Priority Tag | ✅ CRITICAL | ❌ REMOVED | Missing priority marker |
| Instruction | Generic | More specific trigger | ✅ Improved clarity |
| Validation Logic | 3-step process with backup | Simpler item count comparison | ⚠️ **SIMPLIFIED** - Lost backup/restore logic |
| Placeholder Detection | ✅ Present | ❌ REMOVED | ⚠️ **LOST** |

**VERDICT:** ⚠️ **CONTENT SIMPLIFIED** - The new version is cleaner but loses:
- Priority: CRITICAL tag
- Backup/restore logic
- Placeholder detection

---

#### 2. Guardrail #3: Professional Summary Separation → Abstraction (summary-generation.md)

**BEFORE (Committed Version):**
```xml
<summary_abstraction_guardrail>
  <priority>HIGH</priority>
  <instruction>
    Ensure the Professional Summary is a high-level abstraction and does not exactly duplicate the wording of specific resume bullets.
  </instruction>
  
  <validation_logic>
    BEFORE finalized output:
    1. Extract all generated summary sentences.
    2. COMPARE each sentence against all extracted resume bullets in <positions>.
    3. IF similarity (Levenshtein distance or semantic overlap) > 85%:
       - REWRITE the summary sentence to be broader.
       - Focus on the *aggregate* impact rather than the *specific* task.
  </validation_logic>
</summary_abstraction_guardrail>
```

**AFTER (Local Version):**
```xml
<summary_abstraction_guardrail>
  <instruction>
    The Professional Summary must function as an "Executive Synthesis," not a "Bullet Echo."
  </instruction>
  <constraints>
    - <constraint id="no_mirroring">No sentence in the summary can share more than 50% of its keywords with any single bullet point in the resume.</constraint>
    - <constraint id="synthesis_requirement">At least one sentence must synthesize metrics across multiple roles (e.g., "Led projects across [Industry A] and [Industry B], achieving [Cumulative Metric]").</constraint>
    - <constraint id="impact_first">Start sentences with the "Outcome" (The Why) rather than the "Action" (The How) to differentiate from bullets.</constraint>
  </constraints>
</summary_abstraction_guardrail>
```

**Analysis:**
| Aspect | Original | New | Impact |
|--------|----------|-----|--------|
| Priority Tag | ✅ HIGH | ❌ REMOVED | Missing priority marker |
| Similarity Threshold | 85% semantic overlap | 50% keyword match | ✅ Stricter (improved) |
| Validation Logic | Levenshtein distance algorithm | Keyword percentage | ⚠️ DIFFERENT approach |
| Synthesis Requirement | ❌ Not present | ✅ NEW | ✅ Added value |
| Impact-First Rule | ❌ Not present | ✅ NEW | ✅ Added value |

**VERDICT:** ⚠️ **MIXED** - The new version has MORE constraints but uses a DIFFERENT comparison method. The new version is arguably better, but the explicit "Levenshtein distance or semantic overlap" logic was replaced with simpler "keyword match."

---

#### 3. Guardrail #21: Skill Inventory Context → Limitation-to-Bullet Cross-Check (incremental-updates.md)

**BEFORE (Committed Version):**
```xml
<incremental_skill_context_check>
  <instruction>
    When updating a position, verify that newly added skills match the professional level and domain of that specific role.
  </instruction>
</incremental_skill_context_check>
```

**AFTER (Local Version):**
```xml
<limitation_bullet_cross_check_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    During Phase 3 bullet generation, check honest_limitations BEFORE recommending bullets for each position.
  </instruction>
  
  <validation_logic>
    WHEN generating bullets for Position N in Phase 3:
      1. Load position[N].honest_limitations
      2. Extract JD requirements
      3. FOR EACH JD requirement:
           IF requirement mentions skill/tool in honest_limitations:
             DO NOT generate bullet for Position N using this requirement
             ADD to gap analysis: "Position [N] limited: [limitation text]"
  </validation_logic>
</limitation_bullet_cross_check_guardrail>
```

**Analysis:**
| Aspect | Original | New | Impact |
|--------|----------|-----|--------|
| Priority Tag | ❌ Not present | ✅ CRITICAL | ✅ Added priority |
| Scope | Skill-role matching | Limitation enforcement | ⚠️ DIFFERENT purpose |
| Validation Logic | Generic | Detailed step-by-step | ✅ Much more specific |

**VERDICT:** ⚠️ **REPLACED WITH DIFFERENT GUARDRAIL** - The original was about skill-role matching; the new one is about limitation enforcement. These appear to be **two different guardrails that should BOTH exist.**

---

### C. Version Comment Update (incremental-updates.md)

**BEFORE:**
```markdown
**Version:** 1.1.0 <!-- v1.1.0 Change: Added Guardrails #6, #16, #21 -->
```

**AFTER:**
```markdown
**Version:** 1.1.0 <!-- v1.1.0 Change: Added Guardrails #6, #21 -->
```

**Impact:** Reference to Guardrail #16 was REMOVED from the version comment. This appears intentional if #16 was moved to a different file.

---

### D. New Content Added (✅ Safe - Additions Only)

The following files received **new content** with no removals:

| File | New Lines | Description |
|------|-----------|-------------|
| `PROJECT-INSTRUCTIONS.md` | +410 lines | Master Guardrail Checklist (27 guardrails) |
| `quick-start-phase.md` | +340 lines | Master Guardrail Checklist (27 guardrails) |

These are the full XML guardrails (IDs #1-#27) added as a comprehensive reference section.

---

## Recommendations

### Immediate Actions Required:

1. **Delete duplicate file:**
   ```bash
   rm docs/plans/v6.3-adding_guardrails.md
   ```

2. **Review Guardrail #6 modification:**
   - The new version is simpler but LOST backup/restore logic
   - **Decision needed:** Was the simplification intentional, or should the backup logic be restored?

3. **Review Guardrail #3 modification:**
   - The new version has MORE rules but uses a different comparison approach
   - **Decision needed:** Is "50% keyword match" sufficient, or should "85% semantic overlap" be retained?

4. **Review Guardrail #21 replacement:**
   - The original was about skill-role matching; the new one is about limitation enforcement
   - **Decision needed:** Should BOTH versions exist (as separate guardrails)?

### Questions for Review:

1. Was removing `<priority>` tags from some guardrails intentional?
2. Should the Levenshtein distance logic in Guardrail #3 be preserved alongside the new constraints?
3. Is the Guardrail #21 replacement correct, or should the skill-role matching logic be separate?

---

## Files Changed Summary

```
 15 files changed, 814 insertions(+), 193 deletions(-)
 
 PROJECT-INSTRUCTIONS.md       | +410 lines (guardrails added)
 quick-start-phase.md          | +340 lines (guardrails added)
 phases/phase-3/incremental-updates.md | 64 changes (including content modifications)
 phases/phase-4/summary-generation.md  | 81 changes (including content modifications)
 Other files                   | Path fixes only
```

---

*Report generated by Claude for user review before committing changes.*


# --- FILE: docs/plans/v6.3.1-address-instruction-gaps.md ---


# Implementation Plan: Fit Assessment Calibration Improvements

## Version: 6.3.1
## Date: January 4, 2026
## Priority: HIGH
## Estimated Complexity: Medium (instruction additions, no architectural changes)

---

## Problem Statement

Analysis of the same job description (Chainguard Senior PM role) produced dramatically different fit assessments:
- **Model A**: 52% fit (WEAK FIT - recommended not proceeding)
- **Model B**: 92% fit (EXCELLENT FIT - auto-proceeded to bullet generation)

Root cause: Current instructions lack guardrails for:
1. Portfolio/personal project weighting vs. professional experience
2. "Adjacent technical" definition boundaries
3. Context validation for keyword evidence (writing ABOUT vs. working WITH)
4. Industry context gaps (Government vs. B2B SaaS)
5. Role-type experience validation (BA/TW experience ≠ PM experience)

---

## Implementation Tasks

### Task 1: Add Portfolio Project Weighting Rules

**Location:** Insert after `<phase_3_pre_generation_assessment>` section, before `<phase_1_initial_fit_assessment>`

**Purpose:** Prevent personal/portfolio projects from being weighted equally to professional employment when assessing role-specific experience requirements.

```xml
<portfolio_project_weighting>
  <version>1.0</version>
  <priority>HIGH</priority>
  
  <definition>
    Portfolio projects include:
    - Personal GitHub repositories
    - Side projects and hobby work
    - Open-source contributions (unless paid/sponsored)
    - Self-directed learning projects
    - Freelance work without formal employment relationship
    - Positions marked as "Personal Project" or "Portfolio" in job history
  </definition>
  
  <weighting_rules>
    <rule id="skills_only">
      Portfolio projects count toward "technical skills demonstrated" category ONLY.
      They do NOT count toward:
      - Years of professional experience in a role type (PM, Engineer, etc.)
      - Customer-facing product management experience
      - B2B/B2C/Enterprise sales cycle experience
      - Revenue or P&L responsibility
      - Team leadership or people management experience
      - Industry-specific experience (SaaS, FinTech, Healthcare, etc.)
    </rule>
    
    <rule id="recency_discount">
      When calculating fit scores, portfolio projects receive 50% weight compared 
      to equivalent professional experience for skill matching.
      
      Example:
      - Professional role with "workflow automation": 100% skill credit
      - Portfolio project with "workflow automation": 50% skill credit
    </rule>
    
    <rule id="scope_limitations">
      Portfolio projects cannot demonstrate:
      - Cross-functional leadership (no real org to navigate)
      - Stakeholder management at scale (self-directed ≠ org politics)
      - Production system ownership (personal repos ≠ enterprise systems)
      - Customer success metrics (no paying customers unless proven)
      
      Exception: If portfolio project has documented external users, paying 
      customers, or organizational adoption, treat as professional experience.
    </rule>
  </weighting_rules>
  
  <pm_role_specific_rules>
    <rule id="pm_experience_validation">
      For Product Manager roles, the following MUST come from professional employment:
      - Product roadmap ownership
      - Customer discovery and research
      - Feature prioritization with stakeholders
      - Go-to-market collaboration
      - Success metrics ownership (retention, revenue, adoption)
      
      Building a personal tool (even a sophisticated one) does NOT equal PM experience.
      Managing your own project backlog ≠ Managing a product for customers.
    </rule>
  </pm_role_specific_rules>
  
  <examples>
    <example type="incorrect_assessment">
      Job History: "Built multi-agent AI system with 47 releases in personal GitHub repo"
      JD Requirement: "3+ years Product Management experience"
      
      ❌ WRONG: "Direct match - managed product releases"
      ✅ CORRECT: "Portfolio project demonstrates technical skills and release 
         discipline, but does not count toward PM experience requirement. 
         PM Experience: 0 years."
    </example>
    
    <example type="incorrect_assessment">
      Job History: "Created documentation system with 15,000+ lines across 25 files"
      JD Requirement: "Experience driving product strategy and roadmaps"
      
      ❌ WRONG: "Direct match - drove documentation strategy and roadmap"
      ✅ CORRECT: "Portfolio project shows planning ability, but personal project 
         roadmaps ≠ customer-facing product roadmaps with revenue implications."
    </example>
    
    <example type="correct_assessment">
      Job History: "Open-source project with 500+ GitHub stars and 50+ contributors"
      JD Requirement: "Experience leading cross-functional teams"
      
      ✅ CORRECT: "Open-source leadership with external contributors demonstrates 
         some cross-functional coordination. Partial credit (50%) for team leadership."
    </example>
  </examples>
</portfolio_project_weighting>
```

---

### Task 2: Add Adjacent Technical Area Definition

**Location:** Insert within `<phase_1_initial_fit_assessment>` after `<step number="1" name="extract_critical_requirements">`

**Purpose:** Provide clear boundaries for what constitutes "adjacent technical" experience when JDs use this phrase.

```xml
<adjacent_technical_definition>
  <version>1.0</version>
  <priority>HIGH</priority>
  
  <context>
    Many JDs include language like "technical background required" or "experience 
    in systems, networks, or adjacent technical areas." This section defines what 
    qualifies as "adjacent technical" vs. "technical-adjacent support roles."
  </context>
  
  <valid_adjacent_technical_roles>
    <description>
      Roles where the person BUILDS, OPERATES, or ENGINEERS technical systems:
    </description>
    <examples>
      - Site Reliability Engineering (SRE)
      - DevOps / Platform Engineering
      - Systems Administration
      - Network Engineering
      - Security Engineering / Security Operations
      - Data Engineering / Data Platform
      - Database Administration
      - Cloud Infrastructure Engineering
      - QA/Test Automation Engineering
      - Technical Support Engineering (Tier 3+)
      - Solutions Architecture
      - Technical Sales Engineering (with hands-on implementation)
    </examples>
  </valid_adjacent_technical_roles>
  
  <invalid_adjacent_technical_roles>
    <description>
      Roles that SUPPORT or DOCUMENT technical systems but don't build/operate them:
    </description>
    <examples>
      - Technical Writing (writes ABOUT systems, doesn't build them)
      - Business Analysis (gathers requirements, doesn't implement)
      - Project Management (coordinates technical work, doesn't do it)
      - IT Help Desk / Tier 1-2 Support (uses systems, doesn't engineer them)
      - SaaS Administration (configures tools, doesn't build infrastructure)
      - Scrum Master / Agile Coach (facilitates, doesn't build)
      - Technical Recruiting (evaluates technical skills, doesn't have them)
      - Technical Training (teaches systems, may not engineer them)
    </examples>
  </invalid_adjacent_technical_roles>
  
  <distinction_rule>
    <rule priority="critical">
      "Working WITH technical systems" ≠ "Working IN/ON technical systems"
      
      - Working WITH: Uses technical systems as tools to accomplish non-technical goals
        Example: Using Jira to manage projects, administering Google Workspace
        
      - Working IN/ON: Builds, maintains, or operates technical infrastructure
        Example: Writing Terraform configs, managing Kubernetes clusters, building CI/CD pipelines
    </rule>
  </distinction_rule>
  
  <assessment_questions>
    <question id="1">Did this role require writing code that went to production?</question>
    <question id="2">Did this role require on-call/pager duty for system reliability?</question>
    <question id="3">Did this role require architecture decisions for scalability/performance?</question>
    <question id="4">Did this role require debugging production incidents at the infrastructure level?</question>
    <question id="5">Did this role require security hardening or vulnerability remediation?</question>
    
    <scoring>
      - 3+ "Yes" answers: Valid adjacent technical experience
      - 1-2 "Yes" answers: Partial technical exposure (flag as gap)
      - 0 "Yes" answers: Technical-adjacent support role (not "adjacent technical")
    </scoring>
  </assessment_questions>
  
  <examples>
    <example type="valid">
      Role: "Google Workspace Administrator supporting 10,000 users"
      Assessment Questions:
      - Production code? No (configuration, not code)
      - On-call duty? Possibly (for major outages)
      - Architecture decisions? No (SaaS platform)
      - Infrastructure debugging? No (SaaS platform)
      - Security hardening? Partial (policy configuration)
      
      Score: 0-1 "Yes" → Technical-adjacent support role
      Verdict: Does NOT qualify as "adjacent technical" for PM roles requiring 
               developer credibility
    </example>
    
    <example type="valid">
      Role: "DevOps Engineer managing CI/CD pipelines and Kubernetes clusters"
      Assessment Questions:
      - Production code? Yes (pipeline configs, scripts)
      - On-call duty? Yes
      - Architecture decisions? Yes
      - Infrastructure debugging? Yes
      - Security hardening? Yes
      
      Score: 5 "Yes" → Valid adjacent technical experience
      Verdict: Qualifies as "adjacent technical" for PM roles
    </example>
    
    <example type="edge_case">
      Role: "Technical Writer for cloud infrastructure documentation"
      Assessment Questions:
      - Production code? No
      - On-call duty? No
      - Architecture decisions? No (documents others' decisions)
      - Infrastructure debugging? No
      - Security hardening? No
      
      Score: 0 "Yes" → Technical-adjacent support role
      Verdict: Writing ABOUT Kubernetes ≠ Working WITH Kubernetes
               Does NOT qualify as "adjacent technical"
    </example>
  </examples>
</adjacent_technical_definition>
```

---

### Task 3: Add Keyword Context Validation Rules

**Location:** Insert within `<keyword_input_handling>` section, after `<process_if_keywords_with_jd>`

**Purpose:** Prevent false matches where someone documented/wrote about a technology but didn't actually work with it hands-on.

```xml
<keyword_context_validation>
  <version>1.0</version>
  <priority>CRITICAL</priority>
  
  <core_principle>
    Writing ABOUT a technology ≠ Working WITH that technology
    Documenting a system ≠ Operating that system
    Researching a tool ≠ Using that tool in production
  </core_principle>
  
  <validation_process>
    <step number="1">
      When matching a JD keyword to job history, identify the VERB CONTEXT:
      
      ✅ VALID action verbs (hands-on work):
      - Built, Developed, Implemented, Deployed, Configured
      - Managed, Administered, Operated, Maintained
      - Engineered, Architected, Designed (with implementation)
      - Debugged, Troubleshot, Resolved, Fixed
      - Migrated, Upgraded, Scaled, Optimized
      
      ❌ INVALID action verbs (support work):
      - Documented, Wrote about, Created documentation for
      - Researched, Evaluated, Assessed, Analyzed
      - Interviewed SMEs about, Gathered requirements for
      - Trained users on, Created training for
      - Observed, Shadowed, Learned about
    </step>
    
    <step number="2">
      Check the ROLE CONTEXT:
      
      If the job title is "Technical Writer," "Business Analyst," "Project Manager," 
      or similar support role, be SKEPTICAL of technology claims:
      
      - A Technical Writer who "worked with Kubernetes" likely DOCUMENTED Kubernetes,
        not OPERATED Kubernetes clusters
      - A BA who "worked with AWS" likely gathered REQUIREMENTS for AWS migration,
        not ARCHITECTED AWS infrastructure
    </step>
    
    <step number="3">
      Apply the "Interview Test":
      
      "If a hiring manager asked 'Tell me about your experience with [Technology X],'
      could this person speak to hands-on implementation details, or only high-level
      documentation/requirements?"
      
      - Hands-on: "I configured the ingress controllers and debugged networking issues"
      - Documentation: "I wrote the runbooks that explained how to configure ingress"
    </step>
  </validation_process>
  
  <evidence_tiers>
    <tier id="1" name="direct_evidence" weight="100%">
      <description>Hands-on implementation or operation</description>
      <indicators>
        - "Built [system] using [technology]"
        - "Managed [X] instances of [technology]"
        - "On-call for [system] incidents"
        - "Deployed to production using [technology]"
      </indicators>
    </tier>
    
    <tier id="2" name="supervised_exposure" weight="50%">
      <description>Worked alongside practitioners, had some hands-on exposure</description>
      <indicators>
        - "Tested [technology] in UAT environment"
        - "Configured [tool] settings under engineer guidance"
        - "Participated in [system] incident response"
        - "Assisted with [technology] migration"
      </indicators>
    </tier>
    
    <tier id="3" name="documentation_only" weight="0%">
      <description>Wrote about or documented technology without hands-on use</description>
      <indicators>
        - "Documented [technology] architecture"
        - "Created runbooks for [system]"
        - "Wrote CONOPS for [platform]"
        - "Gathered requirements for [technology] implementation"
        - "Interviewed engineers about [system]"
      </indicators>
    </tier>
  </evidence_tiers>
  
  <examples>
    <example type="false_positive_prevention">
      Job History Entry: "Authored NIST-compliant CONOPS for Space Force cloud initiatives on DoD PaaS infrastructure"
      JD Keyword: "Cloud-native development experience"
      
      Analysis:
      - Action verb: "Authored" → Documentation work
      - Role context: Technical Writer
      - Evidence tier: Tier 3 (documentation only)
      
      ❌ WRONG: "Match found - cloud-native experience from Space Force role"
      ✅ CORRECT: "No match - candidate documented cloud systems but did not 
         develop or operate them. Cloud-native development: NOT EVIDENCED."
    </example>
    
    <example type="false_positive_prevention">
      Job History Entry: "Created 5 user playbooks with annotated screenshots for ServiceNow HR"
      JD Keyword: "ServiceNow development experience"
      
      Analysis:
      - Action verb: "Created playbooks" → Documentation work
      - Role context: Technical Writer
      - Evidence tier: Tier 3 (documentation only)
      
      ❌ WRONG: "Match found - ServiceNow experience"
      ✅ CORRECT: "No match - candidate created end-user documentation for ServiceNow 
         but did not develop or configure the platform. ServiceNow development: NOT EVIDENCED."
    </example>
    
    <example type="valid_match">
      Job History Entry: "Built Power Automate workflows automating employee onboarding, eliminating 3 manual processes"
      JD Keyword: "Workflow automation experience"
      
      Analysis:
      - Action verb: "Built" → Hands-on implementation
      - Role context: Technical Writer (but implemented, not just documented)
      - Evidence tier: Tier 1 (direct evidence)
      
      ✅ CORRECT: "Match found - hands-on workflow automation using Power Automate"
    </example>
    
    <example type="partial_match">
      Job History Entry: "Tested and evaluated new Google Workspace features in UAT environment"
      JD Keyword: "Google Workspace administration"
      
      Analysis:
      - Action verb: "Tested and evaluated" → Supervised exposure
      - Role context: Administrator (legitimate admin work)
      - Evidence tier: Tier 2 (supervised exposure, 50% weight)
      
      ✅ CORRECT: "Partial match (50%) - UAT testing experience with Google Workspace, 
         but not primary administrator role"
    </example>
  </examples>
  
  <common_false_positive_patterns>
    <pattern id="1">
      Trap: Technical Writer lists technologies in "tools_technologies" section
      Reality: They documented these tools, didn't operate them
      Fix: Cross-reference with key_achievements - look for implementation verbs
    </pattern>
    
    <pattern id="2">
      Trap: BA lists platforms in "hard_skills_demonstrated"
      Reality: They gathered requirements FOR these platforms, didn't build ON them
      Fix: Check if any achievement shows hands-on work, not just requirements
    </pattern>
    
    <pattern id="3">
      Trap: PM lists engineering tools in skills
      Reality: They managed engineers who used these tools
      Fix: "Managed team using [tool]" ≠ "Used [tool]"
    </pattern>
  </common_false_positive_patterns>
</keyword_context_validation>
```

---

### Task 4: Add Industry Context Validation

**Location:** Insert after `<phase_1_initial_fit_assessment>` as a new validation step

**Purpose:** Flag significant gaps when candidate's industry background doesn't match JD industry context.

```xml
<industry_context_validation>
  <version>1.0</version>
  <priority>HIGH</priority>
  
  <purpose>
    Different industries have fundamentally different operating models, metrics, 
    sales cycles, and success criteria. Experience in one industry doesn't always 
    transfer to another, especially for customer-facing roles like PM.
  </purpose>
  
  <industry_categories>
    <category id="b2b_saas">
      <name>B2B SaaS / Enterprise Software</name>
      <characteristics>
        - Revenue metrics: ARR, MRR, churn, expansion revenue
        - Sales cycle: 30-180 days, multiple stakeholders
        - Success metrics: NPS, adoption, feature usage, retention
        - GTM: Product-led growth, sales-assisted, enterprise sales
        - Pricing: Subscription tiers, usage-based, enterprise contracts
      </characteristics>
      <indicators_in_jd>
        "SaaS", "subscription", "ARR", "churn", "customer success", 
        "product-led", "enterprise sales", "self-serve"
      </indicators_in_jd>
    </category>
    
    <category id="government_contracting">
      <name>Government / Federal Contracting</name>
      <characteristics>
        - Revenue metrics: Contract value, ceiling, period of performance
        - Sales cycle: 6-24 months, RFP/RFQ process
        - Success metrics: Compliance, deliverables, CPARS ratings
        - GTM: Capture management, teaming agreements, set-asides
        - Pricing: T&M, FFP, cost-plus, IDIQ
      </characteristics>
      <indicators_in_jd>
        "Federal", "government", "agency", "FedRAMP", "compliance", 
        "clearance", "contracting officer"
      </indicators_in_jd>
    </category>
    
    <category id="consumer">
      <name>B2C / Consumer Products</name>
      <characteristics>
        - Revenue metrics: DAU/MAU, conversion, LTV, CAC
        - Sales cycle: Instant to 7 days
        - Success metrics: Engagement, retention, virality
        - GTM: Marketing-led, viral loops, app store optimization
        - Pricing: Freemium, ads, in-app purchases
      </characteristics>
      <indicators_in_jd>
        "Consumer", "B2C", "users", "engagement", "viral", "app store"
      </indicators_in_jd>
    </category>
    
    <category id="startup">
      <name>Startup / Early-Stage</name>
      <characteristics>
        - Resource constraints: Do more with less
        - Velocity: Ship fast, iterate faster
        - Ambiguity: Undefined processes, wear many hats
        - Risk tolerance: High, fail fast mentality
      </characteristics>
      <indicators_in_jd>
        "Fast-paced", "startup", "early-stage", "Series A/B", 
        "ambiguity", "wear many hats", "scrappy"
      </indicators_in_jd>
    </category>
    
    <category id="enterprise">
      <name>Enterprise / Large Corporation</name>
      <characteristics>
        - Process: Defined workflows, change management
        - Scale: Large teams, matrix organizations
        - Risk tolerance: Low, extensive planning
        - Velocity: Slower, more deliberate
      </characteristics>
      <indicators_in_jd>
        "Fortune 500", "enterprise", "global", "matrix organization",
        "change management", "stakeholder alignment"
      </indicators_in_jd>
    </category>
  </industry_categories>
  
  <transferability_matrix>
    <description>
      How well does experience in Industry A transfer to Industry B?
      Scale: HIGH (80%+), MODERATE (50-79%), LOW (20-49%), MINIMAL (0-19%)
    </description>
    
    <from_government_contracting>
      <to category="b2b_saas">LOW (30%)</to>
      <to category="consumer">MINIMAL (15%)</to>
      <to category="startup">LOW (25%)</to>
      <to category="enterprise">MODERATE (60%)</to>
      <reasoning>
        Government contracting has longer cycles, compliance focus, and different 
        success metrics. Process discipline transfers to enterprise, but B2B SaaS 
        velocity and consumer metrics are foreign.
      </reasoning>
    </from_government_contracting>
    
    <from_b2b_saas>
      <to category="government_contracting">LOW (35%)</to>
      <to category="consumer">MODERATE (55%)</to>
      <to category="startup">HIGH (85%)</to>
      <to category="enterprise">HIGH (80%)</to>
    </from_b2b_saas>
    
    <from_consumer>
      <to category="government_contracting">MINIMAL (10%)</to>
      <to category="b2b_saas">MODERATE (50%)</to>
      <to category="startup">HIGH (85%)</to>
      <to category="enterprise">MODERATE (55%)</to>
    </from_consumer>
  </transferability_matrix>
  
  <assessment_process>
    <step number="1">
      Identify JD industry category from company description and job requirements.
      Look for indicators listed in each category.
    </step>
    
    <step number="2">
      Identify candidate's industry background from job history.
      Categorize each position by industry.
    </step>
    
    <step number="3">
      Calculate industry match:
      - If 50%+ of experience is in JD's industry: No penalty
      - If 25-49% of experience is in JD's industry: Moderate gap (-10 to -15 points)
      - If 0-24% of experience is in JD's industry: Significant gap (-20 to -30 points)
    </step>
    
    <step number="4">
      Apply transferability adjustment:
      Use transferability_matrix to adjust the gap penalty.
      Example: Government → B2B SaaS = LOW (30%) transferability
               Gap penalty remains high even with transferable skills.
    </step>
  </assessment_process>
  
  <examples>
    <example type="significant_gap">
      Candidate Background: 100% Federal Government Contracting (6 positions)
      JD Industry: B2B SaaS Startup (Chainguard - container security)
      
      Assessment:
      - Industry match: 0% (no B2B SaaS experience)
      - Transferability: LOW (30%) from Government → B2B SaaS
      - Gap penalty: -25 points
      
      Output: "⚠️ INDUSTRY GAP: Your background is 100% federal government 
      contracting. This role is at a B2B SaaS startup with different success 
      metrics (ARR, churn, product-led growth), sales cycles, and velocity 
      expectations. Industry transferability: LOW."
    </example>
    
    <example type="partial_match">
      Candidate Background: 60% B2B SaaS, 40% Enterprise
      JD Industry: B2B SaaS Startup
      
      Assessment:
      - Industry match: 60% (majority B2B SaaS)
      - Transferability: N/A (direct match)
      - Gap penalty: None
      
      Output: No industry gap flagged.
    </example>
    
    <example type="transferable">
      Candidate Background: 100% Enterprise Software
      JD Industry: B2B SaaS (growth stage)
      
      Assessment:
      - Industry match: 0% (no SaaS-specific experience)
      - Transferability: HIGH (80%) from Enterprise → B2B SaaS
      - Gap penalty: -5 points (minimal due to high transferability)
      
      Output: "ℹ️ INDUSTRY NOTE: Your background is enterprise software. 
      This transfers well to B2B SaaS, though you may need to adapt to 
      faster iteration cycles and product-led growth metrics."
    </example>
  </examples>
  
  <output_integration>
    <location>Include in preliminary fit assessment output</location>
    <format>
      Add "Industry Context" section to fit assessment:
      
      **Industry Context**
      - JD Industry: [Category]
      - Your Background: [Category breakdown]
      - Transferability: [HIGH/MODERATE/LOW/MINIMAL]
      - Impact on Fit Score: [+/- X points]
    </format>
  </output_integration>
</industry_context_validation>
```

---

### Task 5: Add Role-Type Experience Validation

**Location:** Insert within `<phase_3_pre_generation_assessment>` after `<step number="2" name="compare_against_job_history">`

**Purpose:** Prevent conflating different role types (e.g., treating BA experience as PM experience).

```xml
<role_type_experience_validation>
  <version>1.0</version>
  <priority>CRITICAL</priority>
  
  <purpose>
    Different role types (PM, BA, TW, Engineer) have distinct responsibilities and 
    career paths. Experience in one role type does NOT automatically qualify for 
    senior positions in another role type.
  </purpose>
  
  <role_type_definitions>
    <role_type id="product_manager">
      <titles>Product Manager, Product Owner, Group PM, Director of Product</titles>
      <core_responsibilities>
        - Product strategy and vision
        - Roadmap prioritization with business impact
        - Customer discovery and market research
        - Cross-functional leadership (Eng, Design, Marketing, Sales)
        - Success metrics ownership (revenue, adoption, retention)
        - Go-to-market collaboration
        - Pricing and packaging decisions
      </core_responsibilities>
      <does_not_include>
        - Project management (timeline/resource coordination)
        - Business analysis (requirements documentation)
        - Scrum master activities (ceremony facilitation)
        - Technical writing (documentation creation)
      </does_not_include>
    </role_type>
    
    <role_type id="business_analyst">
      <titles>Business Analyst, Systems Analyst, Requirements Analyst</titles>
      <core_responsibilities>
        - Requirements elicitation and documentation
        - Process analysis and optimization
        - User story creation and acceptance criteria
        - Gap analysis between current and future state
        - Stakeholder communication and alignment
        - UAT coordination and test case creation
      </core_responsibilities>
      <does_not_include>
        - Product vision/strategy ownership
        - Roadmap prioritization decisions
        - Revenue/business metrics ownership
        - Go-to-market strategy
      </does_not_include>
    </role_type>
    
    <role_type id="technical_writer">
      <titles>Technical Writer, Documentation Specialist, Content Developer</titles>
      <core_responsibilities>
        - Documentation creation and maintenance
        - Style guide development
        - Content audits and gap analysis
        - User-facing content (help docs, tutorials)
        - Internal documentation (runbooks, SOPs)
        - Information architecture
      </core_responsibilities>
      <does_not_include>
        - Product decisions
        - Requirements ownership
        - Engineering work
        - Customer-facing strategy
      </does_not_include>
    </role_type>
    
    <role_type id="project_manager">
      <titles>Project Manager, Program Manager, Delivery Manager</titles>
      <core_responsibilities>
        - Timeline and resource coordination
        - Risk management and mitigation
        - Status reporting and communication
        - Dependency management
        - Budget tracking
        - Stakeholder coordination
      </core_responsibilities>
      <does_not_include>
        - Product strategy decisions
        - Technical implementation
        - Requirements ownership
        - Success metrics definition
      </does_not_include>
    </role_type>
  </role_type_definitions>
  
  <transferability_rules>
    <rule id="ba_to_pm">
      <from>Business Analyst</from>
      <to>Product Manager</to>
      <transferability>MODERATE (50-60%)</transferability>
      <what_transfers>
        - Requirements elicitation skills
        - Stakeholder communication
        - User story writing
        - Process thinking
      </what_transfers>
      <what_doesnt_transfer>
        - Product vision/strategy experience
        - Revenue responsibility
        - Go-to-market experience
        - Roadmap prioritization at product level
      </what_doesnt_transfer>
      <typical_gap>
        BA with 5 years experience ≈ PM with 1-2 years experience
        (BA skills provide foundation but not PM-specific expertise)
      </typical_gap>
    </rule>
    
    <rule id="tw_to_pm">
      <from>Technical Writer</from>
      <to>Product Manager</to>
      <transferability>LOW (25-35%)</transferability>
      <what_transfers>
        - Communication skills
        - User empathy (from writing for users)
        - Attention to detail
        - Cross-functional collaboration
      </what_transfers>
      <what_doesnt_transfer>
        - Product strategy
        - Business metrics ownership
        - Technical credibility with engineers
        - Customer discovery
        - Roadmap prioritization
      </what_doesnt_transfer>
      <typical_gap>
        TW with 5 years experience does NOT qualify for Senior PM roles
        Would need PM-specific experience or Associate PM entry point
      </typical_gap>
    </rule>
    
    <rule id="engineer_to_pm">
      <from>Software Engineer</from>
      <to>Product Manager</to>
      <transferability>MODERATE-HIGH (60-75%)</transferability>
      <what_transfers>
        - Technical credibility
        - Understanding of engineering constraints
        - Systems thinking
        - Data analysis
      </what_transfers>
      <what_doesnt_transfer>
        - Customer discovery skills
        - Go-to-market experience
        - Business metrics focus
        - Cross-functional leadership beyond engineering
      </what_doesnt_transfer>
    </rule>
  </transferability_rules>
  
  <validation_process>
    <step number="1">
      Identify the JD's target role type from title and responsibilities.
    </step>
    
    <step number="2">
      Categorize each position in candidate's job history by role type.
    </step>
    
    <step number="3">
      Calculate role-type experience:
      - Direct experience: Years in exact role type
      - Transferable experience: Years in related roles × transferability %
      - Total equivalent: Direct + (Transferable × factor)
    </step>
    
    <step number="4">
      Compare to JD requirements:
      - "Senior" roles typically require 5+ years direct experience
      - "Mid-level" roles typically require 2-4 years direct experience
      - Entry/Associate roles may accept 0 years with transferable skills
    </step>
  </validation_process>
  
  <examples>
    <example type="insufficient_experience">
      JD: "Senior Product Manager" (implies 5+ years PM experience)
      
      Candidate History:
      - Technical Writer: 3 years
      - Business Analyst: 2 years
      - Google Workspace Admin: 2 years
      
      Calculation:
      - Direct PM experience: 0 years
      - BA → PM transfer: 2 years × 55% = 1.1 equivalent years
      - TW → PM transfer: 3 years × 30% = 0.9 equivalent years
      - Admin → PM transfer: 2 years × 15% = 0.3 equivalent years
      - Total equivalent: 2.3 years
      
      Assessment:
      ❌ "Senior PM requires ~5+ years PM experience. You have 0 years direct 
      PM experience and ~2.3 equivalent years from transferable roles. 
      This is a significant gap for a Senior-level position."
    </example>
    
    <example type="sufficient_experience">
      JD: "Product Manager" (mid-level, 2-4 years)
      
      Candidate History:
      - Associate PM: 1.5 years
      - Business Analyst: 3 years
      
      Calculation:
      - Direct PM experience: 1.5 years
      - BA → PM transfer: 3 years × 55% = 1.65 equivalent years
      - Total equivalent: 3.15 years
      
      Assessment:
      ✅ "Mid-level PM requires 2-4 years. You have 1.5 years direct PM 
      experience plus strong BA background. Total equivalent: ~3 years. 
      This meets the requirement."
    </example>
    
    <example type="role_confusion">
      JD: "Technical Product Manager" (requires technical depth + PM skills)
      
      Candidate History:
      - Technical Writer for DevOps teams: 4 years
      - BA for cloud migration: 2 years
      
      Trap: Candidate might claim "technical PM" fit because they wrote 
      technical documentation.
      
      Correct Assessment:
      - Direct PM experience: 0 years
      - Technical depth: LOW (documented technical systems, didn't build them)
      - "Technical PM" requires BOTH PM experience AND technical implementation
      
      ❌ "Technical PM requires both PM experience and hands-on technical work. 
      You have 0 years PM experience and your technical exposure is documentation-
      based, not implementation-based. This is a poor fit."
    </example>
  </examples>
  
  <output_format>
    Include in fit assessment:
    
    **Role-Type Analysis**
    - JD Role Type: [Product Manager / Business Analyst / etc.]
    - Seniority Level: [Senior / Mid / Entry] (requires ~X years)
    - Your Direct Experience: X years as [role type]
    - Transferable Experience: X equivalent years from [related roles]
    - Gap Assessment: [NONE / MODERATE / SIGNIFICANT]
  </output_format>
</role_type_experience_validation>
```

---

### Task 6: Update Fit Score Calculation

**Location:** Modify existing `<step number="3" name="calculate_preliminary_fit">` within `<phase_1_initial_fit_assessment>`

**Purpose:** Integrate new validation rules into the scoring methodology.

```xml
<step number="3" name="calculate_preliminary_fit">
  <scoring_methodology>
    <!-- Category-Level Weights (unchanged) -->
    <core_qualifications weight="50%">
      Required qualifications, years of experience, role type match, 
      work location/arrangement alignment
    </core_qualifications>
    <critical_requirements weight="30%">
      Domain expertise, platforms, industry-specific skills
    </critical_requirements>
    <preferred_qualifications weight="20%">
      Nice-to-have skills, bonus certifications
    </preferred_qualifications>
  </scoring_methodology>

  <!-- NEW: Validation Penalties -->
  <validation_penalties>
    <penalty id="portfolio_inflation">
      <trigger>Portfolio project experience counted toward role requirements</trigger>
      <adjustment>-15 to -25 points depending on weight given</adjustment>
      <message>"Portfolio projects provide skill evidence but don't count as 
      professional [role type] experience."</message>
    </penalty>
    
    <penalty id="adjacent_technical_misclassification">
      <trigger>Technical-adjacent role (TW, BA, PM) counted as "adjacent technical"</trigger>
      <adjustment>-10 to -20 points</adjustment>
      <message>"Writing ABOUT technical systems ≠ working IN technical systems."</message>
    </penalty>
    
    <penalty id="documentation_false_positive">
      <trigger>Documentation experience matched to hands-on technical requirement</trigger>
      <adjustment>-5 to -15 points per false match</adjustment>
      <message>"Documentation of [technology] ≠ hands-on [technology] experience."</message>
    </penalty>
    
    <penalty id="industry_mismatch">
      <trigger>Candidate industry doesn't match JD industry</trigger>
      <adjustment>See industry_context_validation transferability matrix</adjustment>
      <message>"Your [industry] background has [X%] transferability to [JD industry]."</message>
    </penalty>
    
    <penalty id="role_type_gap">
      <trigger>Insufficient direct experience in target role type</trigger>
      <adjustment>-10 to -30 points based on gap severity</adjustment>
      <message>"Senior [role] requires ~X years. You have Y direct + Z transferable."</message>
    </penalty>
  </validation_penalties>

  <!-- Updated Fit Thresholds (unchanged values, added context) -->
  <fit_thresholds>
    <excellent range="90-100%">
      Strong match after all validation penalties applied.
      Proceed automatically.
    </excellent>
    <good range="80-89%">
      Good match with minor gaps.
      FLAG gaps and ASK user before proceeding.
    </good>
    <weak range="75-79%">
      Weak match - validation penalties pushed score down.
      STOP with brief summary, recommend alternatives.
    </weak>
    <poor range="0-74%">
      Poor match - significant gaps in role type, industry, or technical depth.
      STOP with ultra-brief summary.
    </poor>
  </fit_thresholds>
  
  <!-- NEW: Score Calculation Order -->
  <calculation_order>
    <step order="1">Calculate raw score from requirements matching</step>
    <step order="2">Apply portfolio_project_weighting rules</step>
    <step order="3">Apply adjacent_technical_definition validation</step>
    <step order="4">Apply keyword_context_validation (remove false positives)</step>
    <step order="5">Apply industry_context_validation penalty</step>
    <step order="6">Apply role_type_experience_validation penalty</step>
    <step order="7">Final score = Raw score - All penalties</step>
  </calculation_order>
</step>
```

---

## Testing Checklist

After implementation, test with the Chainguard JD to verify:

- [ ] Portfolio project (Position 0) is NOT counted as PM experience
- [ ] Technical Writer roles are NOT counted as "adjacent technical"
- [ ] Documentation of cloud systems is NOT matched to "cloud-native development"
- [ ] Government contracting background is flagged as industry gap for B2B SaaS
- [ ] Role-type analysis shows 0 years PM experience
- [ ] Final fit score is in 45-60% range (WEAK/POOR fit)
- [ ] System recommends NOT proceeding with bullet generation

---

## Files to Modify

### Implementation Strategy

Following the established `/core/` architecture pattern, these validation rules should be created as modular core files, then embedded inline into the instruction files for standalone use.

---

### Phase 1: Create/Update Core Module Files

#### New Core Validation Modules (Create These)

| Task | Core File | Status | Purpose |
|------|-----------|--------|---------|
| **Task 1** | `core/portfolio-weighting.md` | ❌ **CREATE NEW** | Portfolio project weighting rules |
| **Task 2** | `core/adjacent-technical.md` | ❌ **CREATE NEW** | Adjacent technical role definitions |
| **Task 3** | `core/keyword-context.md` | ❌ **CREATE NEW** | Keyword context validation rules |
| **Task 4** | `core/industry-context.md` | ❌ **CREATE NEW** | Industry transferability matrix |
| **Task 5** | `core/role-type-validation.md` | ❌ **CREATE NEW** | Role-type experience validation |

**Action:** Create 5 new core module files using XML blocks from plan Tasks 1-5

---

#### Existing Core Module (Update)

| Task | Core File | Status | Update Required |
|------|-----------|--------|-----------------|
| **Task 6** | `core/fit-thresholds.md` | ⚠️ **UPDATE** | Add validation penalties and calculation order |

**Action:** Append new sections to existing `core/fit-thresholds.md`:
- Add `<validation_penalties>` section (from plan lines 916-947)
- Add `<calculation_order>` section (from plan lines 970-978)

**Location in file:** After line 86 (after existing `<skill_priority_scoring>` section)

---

### Phase 2: Embed Core Modules in Instruction Files

Both instruction files need inline copies of the core validation rules for standalone use.

#### 1. PROJECT-INSTRUCTIONS.md

**File:** `PROJECT-INSTRUCTIONS.md`  
**Status:** ✅ **ALL 6 TASKS ALREADY APPLIED**  
**Action:** ✅ **COMPLETE** - Verify inline embeddings match new core files

**Embedded Modules:**
- Lines 960-1049: Portfolio weighting (matches Task 1)
- Lines 1103-1217: Adjacent technical (matches Task 2)
- Lines 736-896: Keyword context (matches Task 3)
- Lines 1612-1810: Industry context (matches Task 4)
- Lines 1233-1478: Role-type validation (matches Task 5)
- Lines 1496-1539: Fit score calculation (matches Task 6)

---

#### 2. quick-start-phase.md

**File:** `quick-start-phase.md`  
**Status:** ❌ **0/6 TASKS APPLIED**  
**Action:** Embed all 6 core modules inline following implementation order

**Implementation Order:**
1. Insert Task 1 (from `core/portfolio-weighting.md`) after line 235
2. Insert Task 2 (from `core/adjacent-technical.md`) after line 263
3. Insert Task 4 (from `core/industry-context.md`) after line 319
4. Insert Task 5 (from `core/role-type-validation.md`) after line 271
5. Replace Task 6 (from `core/fit-thresholds.md`) at lines 273-295
6. Verify Task 3 (from `core/keyword-context.md`) at lines 152-182

**Embedding Format:**
```xml
<!-- v6.3.1: Embedded from core/portfolio-weighting.md v1.0 -->
<portfolio_project_weighting>
  ...
</portfolio_project_weighting>
```

---

### Phase Files: No Updates Required

**No phase files require updates** because:
- Fit assessment logic is intentionally kept inline in instruction files
- Phase files handle workflow orchestration, not validation rules
- `/phases/phase-1/` - Handles schemas and parsing only
- `/phases/phase-2/` - Handles evidence matching post-assessment
- `/phases/phase-3/` - Handles workflow routing only
- `/phases/phase-4/` - Handles summary generation post-assessment

---

### Architecture Pattern

```
/core/
  ├── portfolio-weighting.md      (NEW - Source of truth)
  ├── adjacent-technical.md        (NEW - Source of truth)
  ├── keyword-context.md           (NEW - Source of truth)
  ├── industry-context.md          (NEW - Source of truth)
  ├── role-type-validation.md      (NEW - Source of truth)
  └── fit-thresholds.md            (UPDATE - Add Task 6 sections)
         ↓
    [Embedded Inline]
         ↓
  ├── PROJECT-INSTRUCTIONS.md      (✅ Complete)
  └── quick-start-phase.md         (❌ Needs embedding)
```

**Why Hybrid Approach?**
- Core files = Single source of truth for documentation/reference
- Inline embedding = Instruction files work standalone without file dependencies
- Version comments = Track which core version is embedded

---

## Rollback Plan

If new rules are too restrictive:
1. Adjust transferability percentages upward
2. Reduce penalty point ranges
3. Add exceptions for specific scenarios

Keep original scoring logic commented out for easy comparison.

---

## Version History

- v1.3 (January 4, 2026): Restructured to prioritize `/core/` module architecture
  - Changed implementation strategy: Create core modules first, then embed inline
  - Specified 5 new core files to create: portfolio-weighting, adjacent-technical, keyword-context, industry-context, role-type-validation
  - Specified update to existing `core/fit-thresholds.md` for Task 6
  - Adopted hybrid approach: Core files = source of truth, instruction files = inline embeddings
  - Added version comment format for tracking embedded core module versions
  - Clarified phase files require no updates (workflow orchestration only)
- v1.2 (January 4, 2026): Enhanced "Files to Modify" section
  - Replaced vague references with detailed file-specific information
  - Added implementation order for quick-start-phase.md
  - Clarified why both instruction files need updates
  - Documented which files do NOT need updates and why
- v1.1 (January 4, 2026): Added "Implementation Status & File-Specific Instructions" section
  - Consolidated tracking for both PROJECT-INSTRUCTIONS.md and quick-start-phase.md
  - Documented that all 6 tasks already applied to PROJECT-INSTRUCTIONS.md (lines 736-1810)
  - Identified quick-start-phase.md requires all 6 tasks (0/6 applied)
  - Deleted helper files: v6.3.1-implementation-status.md, v6.3.1-quick-start-phase-updates.md
  - Added implementation checklist and file-specific line numbers
- v1.0 (January 4, 2026): Initial plan based on Haiku vs Gemini analysis

---

## Implementation Status & File-Specific Instructions

### Overview

This plan requires updates to **TWO** instruction files. Both files contain the same fit assessment logic and require identical updates.

### Required Files

#### 1. PROJECT-INSTRUCTIONS.md (Full Combined Instructions)

**File:** `PROJECT-INSTRUCTIONS.md`  
**Total Lines:** 2,839  
**Overall Status:** ✅ **ALL 6 TASKS APPLIED**

| Task | Location | Status | Lines |
|------|----------|--------|-------|
| **Task 1: Portfolio Project Weighting** | After `<phase_3_pre_generation_assessment>`, before `<purpose>` | ✅ **APPLIED** | 960-1049 |
| **Task 2: Adjacent Technical Definition** | After `<step number="1">` closes within `<phase_1_initial_fit_assessment>` | ✅ **APPLIED** | 1103-1217 |
| **Task 3: Keyword Context Validation** | Within `<keyword_input_handling>` after `<process_if_keywords_with_jd>` | ✅ **APPLIED** | 736-896 |
| **Task 4: Industry Context Validation** | After `<phase_1_initial_fit_assessment>` closes | ✅ **APPLIED** | 1612-1810 |
| **Task 5: Role-Type Experience Validation** | After `<step number="2">` closes within `<phase_1_initial_fit_assessment>` | ✅ **APPLIED** | 1233-1478 |
| **Task 6: Updated Fit Score Calculation** | Within `<step number="3" name="calculate_preliminary_fit">` | ✅ **APPLIED** | 1496-1539 |

**Action Required:** ✅ **COMPLETE - Verify implementation only**

---

#### 2. quick-start-phase.md (Single-File Quick-Start Version)

**File:** `quick-start-phase.md`  
**Total Lines:** 1,118  
**Overall Status:** ❌ **0/6 TASKS APPLIED**

| Task | Location | Status | Action Needed |
|------|----------|--------|---------------|
| **Task 1: Portfolio Project Weighting** | After `<phase_3_pre_generation_assessment>` (line 235), before `<purpose>` | ❌ **NOT APPLIED** | Insert XML from plan lines 34-123 |
| **Task 2: Adjacent Technical Definition** | After `<step number="1">` closes (after line 263) within `<phase_1_initial_fit_assessment>` | ❌ **NOT APPLIED** | Insert XML from plan lines 128-249 |
| **Task 3: Keyword Context Validation** | Within `<keyword_input_handling>` (line 152) after `<process_if_keywords_with_jd>` (line 182) | ❌ **NOT APPLIED** | Insert XML from plan lines 254-421 |
| **Task 4: Industry Context Validation** | After `<phase_1_initial_fit_assessment>` closes (line 319), before `<phase_2_gap_investigation>` (line 321) | ❌ **NOT APPLIED** | Insert XML from plan lines 426-631 |
| **Task 5: Role-Type Experience Validation** | After `<step number="2">` closes (after line 271) within `<phase_1_initial_fit_assessment>` | ❌ **NOT APPLIED** | Insert XML from plan lines 636-888 |
| **Task 6: Updated Fit Score Calculation** | REPLACE `<step number="3" name="calculate_preliminary_fit">` (lines 273-295) | ❌ **NOT APPLIED** | Replace with XML from plan lines 900-979 |

**Action Required:** ❌ **Apply all 6 tasks to quick-start-phase.md**

**Implementation Order for quick-start-phase.md:**
1. Insert Task 1 after line 235
2. Insert Task 2 after line 263 (after first `<step>` closes)
3. Insert Task 4 after line 319 (after `<phase_1_initial_fit_assessment>` closes)
4. Insert Task 5 after line 271 (after second `<step>` closes)
5. Replace Task 6 at lines 273-295 (modify existing `<step number="3">`)
6. **Note:** Task 3 already exists at correct location (lines 152-182 in quick-start-phase.md) - verify it matches plan

---

### Implementation Checklist

- [x] **PROJECT-INSTRUCTIONS.md** - All 6 tasks applied (verify only)
- [ ] **quick-start-phase.md** - Apply 6 tasks following order above
- [ ] Test with Chainguard JD (see Testing Checklist section above)
- [ ] Verify fit score drops to 45-60% range
- [ ] Confirm portfolio projects not counted as professional experience
- [ ] Confirm Technical Writer roles not counted as "adjacent technical"

---

### Notes

**Why Two Files?**
- `PROJECT-INSTRUCTIONS.md` = Full combined version for Claude Projects
- `quick-start-phase.md` = Single-file quick-start version for other LLMs

Both files contain identical fit assessment logic, so both require the same 6 updates for consistency.

**Modular `/phases/` Files:**
- Do NOT require updates - fit assessment logic is not modularized
- These files handle schemas, workflows, and post-assessment operations only


# --- FILE: docs/plans/v6.4.0-update-user-initial-prompt-plan.md ---


# Plan: Update Initial User Prompt with A/B/C/D/E Menu

## Current State
Your instructions currently have a small `<initial_user_prompt>` that only explains bullet optimization.

## What's Changing
Replace it with a comprehensive **entry point menu** that guides users based on **what they have**, not what they want to do.

---

## Step-by-Step Plan

### STEP 1: Locate Current Section to Replace

**In your project instructions, find:**
```xml
<initial_user_prompt>
<greeting>
Welcome to the Resume Bullet Optimizer!
</greeting>
...
</initial_user_prompt>
```

**This is at the very top (before `<proactive_job_summary_usage>`)**

---

### STEP 2: Structure of New Prompt

The new prompt has this structure:

```xml
<initial_user_prompt>
  
  <greeting>
    [Friendly welcome + what the system does]
  </greeting>
  
  <entry_point_menu>
    [The A/B/C/D/E options: "What do you have?"]
  </entry_point_menu>
  
  <option_a>
    [Resume file → comprehensive job summary]
  </option_a>
  
  <option_b>
    [Resume bullets → strengthen with metrics]
  </option_b>
  
  <option_c>
    [Job description → analyze fit]
  </option_c>
  
  <option_d>
    [Role from memory → build summary together]
  </option_d>
  
  <option_e>
    [Lost/confused → explain the system]
  </option_e>
  
  <global_promise>
    [Promise: we'll ask probing questions + offer to improve]
  </global_promise>
  
</initial_user_prompt>
```

---

### STEP 3: What to Keep from Old Prompt

**Keep the tone:**
- ✅ Crisp, practical, encouraging
- ✅ No fluff
- ✅ Honest about never fabricating metrics

**Remove:**
- ❌ The old "Step 1/Step 2/Step 3" workflow
- ❌ References to "optional context"
- ❌ The "ready?" prompt (replace with menu)

---

### STEP 4: New Content to Add

### **Greeting Section**

```xml
<greeting>
Welcome to Your Resume Optimizer

This tool helps you turn vague resume bullets into quantified, defensible 
achievements. We also create comprehensive job summaries and analyze job fit. 
Never fabricates numbers.

First, let me ask: what do you have right now?
</greeting>
```

### **Entry Point Menu**

```xml
<entry_point_menu>
Pick the option that best matches your situation (A, B, C, D, or E):

A) A resume file (PDF, Word, or text)
   
B) A specific resume bullet or few bullets

C) A job description from a posting

D) A role/job I worked on (from memory)

E) None of the above / I'm not sure
</entry_point_menu>
```

### **Option A**

```xml
<option_a_resume_file>
<trigger>User has a resume file</trigger>
<what_happens>
I'll analyze your resume and create a comprehensive job summary for each 
role. Along the way, I'll ask you probing questions to uncover hidden 
metrics, accomplishments, and impact you might not have even thought to 
include.

This summary becomes your reference document. Use it later to generate 
tailored resume bullets for any job application.

What to do: Paste your resume (or upload it), or tell me about a specific 
role you want to summarize.
</what_happens>
</option_a_resume_file>
```

### **Option B**

```xml
<option_b_resume_bullets>
<trigger>User has existing resume bullets</trigger>
<what_happens>
I'll analyze your bullets and ask you targeted questions to identify hidden 
metrics and improvement opportunities. Then I can rewrite them to be stronger. 
Just let me know if you'd like me to.

What to do: Paste the bullet(s) below, plus any context about the role or 
company (if helpful).
</what_happens>
</option_b_resume_bullets>
```

### **Option C**

```xml
<option_c_job_description>
<trigger>User has a job description</trigger>
<what_happens>
I'll analyze how well you fit this role before we optimize anything. 
This takes a few seconds and helps us focus on what matters most for 
this specific job.

To do a thorough analysis, I'll need your job history or details about 
relevant roles. If you already have a job summary on file, I'll use that.

What to do: Paste the job description below.
</what_happens>
</option_c_job_description>
```

### **Option D**

```xml
<option_d_role_from_memory>
<trigger>User wants to create a summary from scratch</trigger>
<what_happens>
Great! We'll build a comprehensive job summary together. I'll ask you 
detailed questions about:
- What you did
- How much/many
- How long it took
- Who you worked with
- What tools/technologies you used
- What outcomes happened

Don't worry if you don't remember everything—we'll work with what you know. 
This summary will be your reference for future job applications.

What to do: Tell me the job title, company, and when you worked there. 
Then we'll go from there.
</what_happens>
</option_d_role_from_memory>
```

### **Option E**

```xml
<option_e_confused>
<trigger>User isn't sure or none of the above fit</trigger>
<what_happens>
No problem! Here's how this system works:

1. START: You give me something (a resume, a bullet, a job description, 
   or just talk about a role)
   
2. ANALYZE: I ask you targeted questions to uncover details and metrics

3. IMPROVE: You decide if you want me to optimize/strengthen it

4. APPLY: Use the improved content for your job applications

The whole point: realistic, defensible achievements. No made-up numbers.

What would be most helpful for you right now?
- Analyze my resume
- Strengthen a resume bullet
- Check if I fit a job description
- Build a job summary from scratch
- Something else (tell me)
</what_happens>
</option_e_confused>
```

### **Global Promise (Add After All Options)**

```xml
<global_promise>
💡 Throughout this process:
- I'll ask clarifying questions to strengthen your content
- After any analysis, you'll see what can be improved
- I'll offer to help refine it—just let me know if you want me to
- You're in control: accept suggestions, modify, or skip

Ready? Pick your option above (A, B, C, D, or E) and paste what you have.
</global_promise>
```

---

## STEP 5: Integration Points

### **After User Chooses:**

The system should then route to the appropriate workflow:

```xml
<routing_logic>

IF user picks A (Resume):
  → Trigger job summary creation workflow
  → Reference <creating_job_summaries> section
  
IF user picks B (Bullets):
  → Trigger bullet optimization workflow
  → Use <core_process> section (parse, diagnose, ask questions)
  
IF user picks C (Job Description):
  → Trigger comparative JD analysis
  → Use <comparative_jd_analysis> section
  
IF user picks D (Role from memory):
  → Trigger job summary creation workflow
  → Start with probing questions
  
IF user picks E (Confused):
  → Show brief explanation
  → Ask them to pick from A-D
  
</routing_logic>
```

---

## STEP 6: What You Actually Do

### **In your project instructions, replace this:**

```xml
<initial_user_prompt>
<greeting>
Welcome to the Resume Bullet Optimizer!
</greeting>

<overview>
This tool helps you turn vague resume bullets into **quantified, defensible 
achievements**—never fabricating numbers.
</overview>

[... rest of old prompt ...]
</initial_user_prompt>
```

### **With the full new structure from STEP 4 above**

### **Keep this location (at the very top, before everything else)**

---

## STEP 7: No Changes Needed Elsewhere

✅ `<proactive_job_summary_usage>` — stays as is  
✅ `<comparative_jd_analysis>` — stays as is  
✅ `<quantify_my_resume_system_prompt>` — stays as is  

The new initial prompt just **routes users** to the right sections. It doesn't change the sections themselves.

---

## Summary of Changes

| What | Action |
|------|--------|
| **Location** | Top of instructions (before proactive_job_summary_usage) |
| **Replace** | Current `<initial_user_prompt>` section |
| **Structure** | Greeting + Menu (A/B/C/D/E) + Option details + Global promise |
| **Integration** | Routes to existing workflows (no new sections) |
| **Word count** | ~800 words (concise, scannable) |

---

## Next Step

Ready for me to:
1. Build the complete XML with all sections filled in?
2. Show you exactly what to copy/paste?
3. Something else?

# --- FILE: docs/plans/v6.5.0-complete_implementation_guide-claude.md ---


# v6.5.1 Implementation Guide
## Complete Surgical Integration Steps

**Version:** 6.5.1  
**Date:** January 2026  
**Status:** Ready for Integration  

---

## INTEGRATION CHECKLIST

### Phase A: Core Displays (Updates 1-3)
- [ ] Add `bullet_color_coding_rules` after `<action_verb_categories>`
- [ ] Add `bullet_metrics_detection_rules` 
- [ ] Add `bullet_display_and_grouping_rules`
- [ ] Verify all three work together in Phase 1 output

### Phase B: Analysis Features (Updates 4-6)
- [ ] Add `hiring_manager_perspective_rules`
- [ ] Add `job_history_summary_generation_rules`
- [ ] Add `job_history_export_functionality`
- [ ] Test job history auto-generation from resume bullets
- [ ] Test XML/Markdown/ZIP export workflows

### Phase C: Audit & Repair Systems (Updates 7-8)
- [ ] Add `per_bullet_audit_rules`
- [ ] Add `prioritized_repairs_summary_rules`
- [ ] Implement 3-row analysis table for every bullet
- [ ] Create recommendation box generation
- [ ] Build final repairs list aggregation

### Phase D: Guardrails & Validation (Update 9)
- [ ] Add `bullet_grouping_verification_guardrail` (#28)
- [ ] Update action verb categories with color-coding reference
- [ ] Update `automatic_plain_text_export` grouping format
- [ ] Add `metrics_presence_principle` to core principles

---

## KEY IMPLEMENTATION NOTES

### 1. Token Efficiency
- Audit display is "surgically integrated" - no bullet text duplication
- Reuse color-coding and metrics detection already performed
- Aggregate recommendations to avoid per-bullet repetition

### 2. Integration Points
- **Phase 1 Output:** Now includes hiring manager perspective + job summaries + audit tables
- **Phase 2 Bullets:** Maintain color-coding + metrics indicators
- **Phase 3 JD Match:** Apply same display rules

### 3. File Generation
- Auto-generate XML, Markdown, and ZIP on user click
- Use standardized filenames with date stamps
- Validate XML well-formedness before delivery

### 4. Quality Gates
- Per-bullet audit tables serve as quality validation
- Prioritized repairs list provides action roadmap
- Verdict summary enables quick user assessment

---

## SECTION-BY-SECTION INSTALLATION

### After `<action_verb_categories>` - INSERT:
```
bullet_color_coding_rules (UPDATE 1)
bullet_metrics_detection_rules (UPDATE 2)
bullet_display_and_grouping_rules (UPDATE 3)
```

### After `<bullet_display_and_grouping_rules>` - INSERT:
```
hiring_manager_perspective_rules (UPDATE 4)
job_history_summary_generation_rules (UPDATE 5)
job_history_export_functionality (UPDATE 6)
per_bullet_audit_rules (UPDATE 7)
prioritized_repairs_summary_rules (UPDATE 8)
```

### In `<phase_1_analysis_report_output>` - MODIFY:
- Update `report_structure` to reference new audit sections
- Add reference to `per_bullet_audit_rules` in position review section
- Add final "PRIORITIZED REPAIRS SUMMARY" section

### In `<system_guardrails>` - ADD:
- New guardrail #28 for `bullet_grouping_verification_guardrail`

### In `<action_verb_categories>` - ADD AT END:
- `color_coding_reference` subsection

### In `<core_principles>` - ADD:
- `metrics_presence_principle`

---

## TESTING CHECKLIST

### Color-Coding System
- [ ] Test detection of all 5 verb categories
- [ ] Verify correct color mapping (Blue/Orange/Purple/Green/Pink)
- [ ] Ensure display handles edge cases (unknown verbs)
- [ ] Validate output across all three phases

### Metrics Detection
- [ ] Test all 8 metric patterns (%, $, ~, x, ranges, time, volume, rankings)
- [ ] Verify ✓ and - indicators display correctly
- [ ] Check percentage reporting in position summaries
- [ ] Validate target guidance (70-80% coverage)

### Job History Auto-Generation
- [ ] Extract from resume bullets correctly
- [ ] Generate professional summaries (2-3 sentences)
- [ ] Classify skills (hard vs soft) accurately
- [ ] Calculate team scope from context
- [ ] Format XML with proper escaping
- [ ] Generate valid Markdown syntax
- [ ] Create ZIP archive correctly

### Per-Bullet Audit Tables
- [ ] Generate 3-row table for every bullet
- [ ] Metrics row shows correct status (Passed/Failed)
- [ ] Action Verb row detects redundancy across position
- [ ] Char Count row calculates accurately
- [ ] Recommendation boxes appear only when needed
- [ ] Severity prefixes ([⚠️ RISK], [🔧 TWEAK]) correct

### Prioritized Repairs Summary
- [ ] Executive summary appears first
- [ ] Counts calculated accurately by severity
- [ ] Verdict summary is concise and actionable
- [ ] Final repairs list groups by severity
- [ ] References to specific bullets ([P1-B4]) are correct
- [ ] Suggestions are specific and actionable

### Integration Points
- [ ] Phase 1 output includes all new sections in order
- [ ] Hiring manager perspective maintains position order
- [ ] Job history exports work in all three formats
- [ ] Color-coding applies to Phase 2 and 3 bullets
- [ ] Audit tables appear in all phases

---

## BACKWARD COMPATIBILITY

All updates are **backwards compatible** with v6.0-v6.4:
- Existing Phase 2 and Phase 3 workflows unaffected
- New features are additive (don't replace existing logic)
- Job history job history creation schema unchanged
- Entry point routing unaffected

---

## ROLLOUT TIMELINE

### Week 1: Core Display Features
- Implement Updates 1-3 (Color-coding, metrics, grouping)
- Test in Phase 1 output
- Validate across all three phases

### Week 2: Analysis Features
- Implement Updates 4-6 (HM perspective, job history, exports)
- Build auto-generation logic
- Test file generation

### Week 3: Audit & Repair Systems
- Implement Updates 7-8 (Per-bullet audit, repairs summary)
- Build recommendation aggregation
- Create verdict logic

### Week 4: Integration & Testing
- Implement Update 9 (Guardrails)
- End-to-end testing
- Refinement and optimization

---

## SUCCESS METRICS

✅ Phase 1 output includes ALL new features
✅ Job history auto-generates from resume analysis
✅ Every bullet has audit table + potential recommendations
✅ Repairs summary provides actionable roadmap
✅ All exports (XML/MD/ZIP) work without errors
✅ Color-coding applies consistently across phases
✅ Metrics detection catches 95%+ of quantified claims

---

## FILE ORGANIZATION

```
project_instructions/
├── optimize_my_resume_v6.5.1.xml
├── /updates/
│   ├── v6.5.1_updates.md (This document)
│   ├── UPDATE_1_color_coding.xml
│   ├── UPDATE_2_metrics_detection.xml
│   ├── UPDATE_3_bullet_grouping.xml
│   ├── UPDATE_4_hiring_manager.xml
│   ├── UPDATE_5_job_history.xml
│   ├── UPDATE_6_export_functionality.xml
│   ├── UPDATE_7_per_bullet_audit.xml
│   ├── UPDATE_8_repairs_summary.xml
│   └── UPDATE_9_guardrails.xml
└── /templates/
    ├── job_history_v2.0_template.xml
    ├── audit_table_template.html
    ├── repairs_summary_template.md
```

---

## SUPPORT & QUESTIONS

For implementation questions:
1. Refer to the specific UPDATE section
2. Check integration points in phase output structures
3. Review testing checklist for common issues
4. Validate against wireframe design in `Resume_Analyzer_Wireframe_Draft.md`

---

## VERSION HISTORY ENTRY

**v6.5.1 (January 2026)**
- Added per-bullet audit display rules with 3-row analysis tables
- Implemented prioritized repairs summary with severity levels (Blocker/Risk/Tweak)
- Integrated hiring manager perspective analysis with market-realistic title inference
- Added job history creation auto-generation during Phase 1 analysis
- Implemented bullet color-coding system (Blue/Orange/Purple/Green/Pink)
- Added metrics detection rules with visual indicators (✓/-)
- Created job history export functionality (XML/Markdown/ZIP formats)
- Added bullet display and grouping rules (reverse chronological order)
- New guardrail #28 for bullet grouping verification
- Total additions: 8 new instruction sections, 1 new guardrail, 3 modified existing sections

---

**Integration Status:** READY FOR IMPLEMENTATION  
**Estimated Implementation Time:** 3-4 weeks (phased approach)  
**Backward Compatibility:** 100% - All changes are additive

# --- FILE: docs/plans/v6.5.0-completely_implementation_plan-gemini.md ---


# Implementation Plan - Optimize-My-Resume System v6.5.0 (Cumulative)

## Goal
Implement the cumulative v6.5.0 updates, focusing on "Missing Analyzer Audit Elements" and the core system updates defined in `optimize_my_resume_v6_5_1_updates.md`. These changes enhance the resume analysis with visual indicators (color-coded verbs, metrics), detailed per-bullet auditing, and a new Hiring Manager perspective.

## User Review Required
> [!WARNING]
> **Project Instructions Update**: I will be inserting significant new logic blocks into `PROJECT-INSTRUCTIONS.md` and `quick-start-phase.md` to define the new Phase 1 report structure.

## Proposed Changes

### Core Documentation

#### [MODIFY] [PROJECT-INSTRUCTIONS.md](PROJECT-INSTRUCTIONS.md)
*   **Insert** `bullet_color_coding_rules` (Update 1)
*   **Insert** `bullet_metrics_detection_rules` (Update 2)
*   **Insert** `bullet_display_and_grouping_rules` (Update 3)
*   **Insert** `hiring_manager_perspective_rules` (Update 4)
*   **Insert** `job_history_summary_generation_rules` (Update 5)
*   **Insert** `job_history_export_functionality` (Update 6)
*   **Insert** `per_bullet_audit_rules` (Update 7)
*   **Insert** `prioritized_repairs_summary_rules` (Update 8)
*   **Update** `<phase id="1" ...>` to include the new reporting structure referencing these rules.
*   **Update** `<phase id="1" ...>` to include the new reporting structure referencing these rules.
*   **UPDATE:** Ensure the Phase 1 analyzer output explicitly wraps job history summaries in `<position_structure>` tags for each position.

#### [MODIFY] [PROJECT-INSTRUCTIONS.md - Guardrails & Principles](PROJECT-INSTRUCTIONS.md)
*   **Insert** `bullet_grouping_verification_guardrail` (Guardrail #28)
*   **Update** `automatic_plain_text_export` grouping format
*   **Add** `metrics_presence_principle` to `<core_principles>`

#### [MODIFY] [quick-start-phase.md](quick-start-phase.md)
*   Apply the same `INSERT` updates as above to ensure the "single-file" version is synchronized.

### Modular Files (If Applicable)
*   I will verify if `phases/phase-1/` files need corresponding updates, but the primary instruction is to update the single-file instructions which often override/consolidate modular files in this project structure.

## Verification Plan

### Automated Verification
*   **Syntax Check**: Ensure all new XML tags are properly closed in `PROJECT-INSTRUCTIONS.md`.

### Manual Verification
*   **User Action**: Run a "fresh" Phase 1 analysis using the updated instructions (by pasting them into a new chat or using the agent) to see the new "Hiring Manager Perspective" and "Per-Bullet Audit" tables.


# --- FILE: docs/plans/v6.5.0-optimize_my_resume_updates.md ---


# Optimize-My-Resume System v6.5.1 - Surgical Update Implementation

**Version:** 6.5.1  
**Date:** January 2026  
**Status:** Complete Surgical Integration Ready  

---

## Version History

### v6.5.1 (January 2026)
- Added per-bullet audit display rules with 3-row analysis tables
- Implemented prioritized repairs summary with severity levels
- Integrated hiring manager perspective analysis 
- Added job history creation auto-generation during Phase 1
- Implemented bullet color-coding system (Blue/Orange/Purple/Green/Pink)
- Added metrics detection rules with visual indicators
- Created job history export functionality (XML/Markdown/ZIP)
- Added bullet display and grouping rules

### v6.5.0 (January 2026)
- Created bullet color-coding rules
- Implemented bullet metrics detection
- Added hiring manager perspective analysis
- Created job history summary generation
- Added export functionality

### v6.4.x → v6.0.x
- [See original version history in base instructions]

---

## UPDATE 1: BULLET COLOR-CODING RULES

**Location:** After `<action_verb_categories>` and before `<critical_formatting_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- BULLET COLOR-CODING SYSTEM (v6.5.1)                                        -->
<!-- ========================================================================== -->

<bullet_color_coding_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1, Phase 2, Phase 3 - All bullet displays</applies_to>
  
  <purpose>
    Visually identify action verb categories by coloring the first word of each bullet.
    Enables quick visual assessment of verb diversity and achievement types.
  </purpose>

  <color_mapping>
    <category verb_name="Built" color="blue" hex="#3B82F6">
      <description>Creates new systems/products/processes</description>
      <verbs>built, developed, designed, launched, established, implemented, created, engineered, architected, pioneered</verbs>
    </category>
    
    <category verb_name="Lead" color="orange" hex="#FBBF24">
      <description>Drives initiatives, guides teams</description>
      <verbs>led, directed, spearheaded, drove, championed, headed, piloted, steered, mentored, coached</verbs>
    </category>
    
    <category verb_name="Managed" color="purple" hex="#A855F7">
      <description>Oversees resources, coordinates operations</description>
      <verbs>managed, supervised, coordinated, oversaw, administered, orchestrated, facilitated, organized, planned, prioritized</verbs>
    </category>
    
    <category verb_name="Improved" color="green" hex="#10B981">
      <description>Optimizes and enhances existing systems</description>
      <verbs>optimized, improved, streamlined, enhanced, transformed, upgraded, refined, boosted, increased, reduced</verbs>
    </category>
    
    <category verb_name="Collaborate" color="pink" hex="#EC4899">
      <description>Partners cross-functionally, works with teams</description>
      <verbs>collaborated, partnered, cooperated, coordinated, facilitated, liaised, worked with, teamed with, consulted, advised</verbs>
    </category>
  </color_mapping>

  <implementation_rules>
    <rule priority="critical">
      Extract the first word of each bullet (the action verb).
    </rule>
    
    <rule priority="critical">
      Match the first word against verb lists above (case-insensitive).
    </rule>
    
    <rule priority="critical">
      Apply the corresponding color to the first word ONLY.
    </rule>
    
    <rule priority="high">
      If verb is not found in any category, display in default color (white/gray).
    </rule>
    
    <rule priority="high">
      Color coding applies to visual display ONLY - does not change the actual bullet text.
    </rule>
  </implementation_rules>

  <example_output>
    [Built] a real-time analytics dashboard using React and PostgreSQL
    [Lead] cross-functional team of 8 engineers to launch Q4 roadmap
    [Managed] $2M annual budget and 12-person operations team
    [Improved] page load time from 3s to 0.8s using lazy loading
    [Collaborate] with design team to create user-centric UX patterns
  </example_output>
</bullet_color_coding_rules>
```

---

## UPDATE 2: BULLET METRICS DETECTION RULES

**Location:** After `<bullet_color_coding_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- BULLET METRICS DETECTION (v6.5.1)                                          -->
<!-- ========================================================================== -->

<bullet_metrics_detection_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1, Phase 2, Phase 3 - All bullet displays</applies_to>
  
  <purpose>
    Visually indicate whether each bullet contains quantified metrics.
    Helps users identify which bullets have impact evidence and which need strengthening.
  </purpose>

  <metric_types_recognized>
    <type pattern="\d+%">Percentages (e.g., "50%", "3.2%")</type>
    <type pattern="\$\d+">Currency (e.g., "$2M", "$500K", "$1.2B")</type>
    <type pattern="~\d+">Approximations (e.g., "~40", "~10%")</type>
    <type pattern="\d+x">Multipliers (e.g., "3x", "10x")</type>
    <type pattern="from \d+ to \d+">Ranges/improvements (e.g., "from 3s to 0.8s")</type>
    <type pattern="\d+ (seconds|minutes|hours|days|weeks|months|years)">Time-based (e.g., "3 days", "2 weeks")</type>
    <type pattern="\d+ (users|customers|clients|transactions|records|items|pages)">Volume-based (e.g., "500 users", "10K transactions")</type>
    <type pattern="(Top|First) \d+">Rankings (e.g., "Top 10", "First 5")</type>
  </metric_types_recognized>

  <detection_algorithm>
    1. Scan each bullet for any metric pattern above
    2. If ANY metric found: Mark bullet as "HAS METRICS" ✓
    3. If NO metrics found: Mark bullet as "NO METRICS" -
  </detection_algorithm>

  <display_format>
    When displaying bullets, add a metric indicator next to each bullet:
    
    ✓ (Green checkmark) = Bullet contains quantified metric(s)
    - (Gray dash) = Bullet lacks quantified metrics
  </display_format>

  <reporting_in_phase_1>
    In Phase 1 Resume Analysis Report, include summary per position:
    
    "Metrics Coverage: X/Y bullets have quantified impact (XX%)
     Target: 70-80% of bullets should contain metrics"
  </reporting_in_phase_1>
</bullet_metrics_detection_rules>
```

---

## UPDATE 3: BULLET DISPLAY AND GROUPING RULES

**Location:** After `<bullet_metrics_detection_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- BULLET DISPLAY AND GROUPING (v6.5.1)                                       -->
<!-- ========================================================================== -->

<bullet_display_and_grouping_rules>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1, Phase 2, Phase 3 - All bullet displays</applies_to>
  
  <purpose>
    Define standard format for displaying bullets across all phases.
    Ensures consistency: color-coded verbs + metrics detection + job title grouping.
  </purpose>

  <grouping_logic>
    <order>Reverse chronological (most recent job first)</order>
    <grouping_unit>By job title + company</grouping_unit>
    
    <position_header_format>
      [Job Title] at [Company] | [Start Date] - [End Date]
      Duration: [X years/months]
    </position_header_format>
  </grouping_logic>
  
  <bullet_display_within_position>
    For each bullet in the position:
    [METRIC_INDICATOR] [COLOR_CODED_VERB] [bullet text]
    
    Where:
    - METRIC_INDICATOR: ✓ (green) or - (gray) - placed at left
    - COLOR_CODED_VERB: First word colored per bullet_color_coding_rules
    - bullet text: remainder of the bullet
  </bullet_display_within_position>
  
  <position_summary>
    After all bullets for a position, display:
    - Total bullets in position: X
    - Bullets with metrics: X (XX%)
    - Verb category breakdown: Built (X), Lead (X), Managed (X), Improved (X), Collaborate (X)
  </position_summary>

  <reverse_chronological_verification>
    GUARDRAIL: Before displaying any position set, verify reverse chronological order.
    
    Sort positions by end_date DESCENDING (most recent first).
    If any position is out of order, flag and reorder before display.
  </reverse_chronological_verification>
</bullet_display_and_grouping_rules>
```

---

## UPDATE 4: HIRING MANAGER PERSPECTIVE ANALYSIS

**Location:** After `<bullet_display_and_grouping_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- HIRING MANAGER PERSPECTIVE ANALYSIS (v6.5.1)                               -->
<!-- ========================================================================== -->

<hiring_manager_perspective_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1 Resume Analysis only</applies_to>
  
  <purpose>
    Analyze resume as an external hiring manager or recruiter would.
    Ignore resume job titles and infer actual job title/role based on:
    - Core responsibilities and deliverables
    - Skills demonstrated through achievements
    - Industry context and company type
    - Seniority level implied by scope and impact
    - Career progression patterns
  </purpose>

  <analysis_methodology>
    <step number="1" name="context_gathering">
      For each position in the resume:
      - Read all bullets (both responsibilities and achievements)
      - Note the company type and industry
      - Identify scope (team size, budget, customer base, etc.)
      - Assess seniority level
      - Track patterns across positions
    </step>

    <step number="2" name="title_interpretation">
      Infer what the job title likely was, based on actual work.
      Use actual market job titles, not internal or creative titles.
      
      Examples of inference logic:
      - If bullets show: "Managed team", "Set roadmap", "Owned product decisions"
        → Likely: Product Manager, Product Owner
      - If bullets show: "Built systems", "Architected solutions"
        → Likely: Software Engineer, Technical Lead, Engineering Manager
      - If bullets show: "Wrote documentation", "Created user guides"
        → Likely: Technical Writer, Documentation Specialist
    </step>

    <step number="3" name="seniority_assessment">
      Determine seniority level based on:
      - Team leadership (0 = Individual contributor, 3+ = Team lead, 10+ = Manager+)
      - Budget responsibility ($0 = None, $100K+ = Budget owner, $1M+ = Executive)
      - Strategic vs. tactical work (Strategic = Senior, Tactical = Junior)
      - Cross-functional scope (Wide = Senior, Narrow = Junior)
      
      Adjust title with seniority level:
      - Junior/Entry: "Software Engineer", "Junior Developer"
      - Mid-level: "Senior Software Engineer", "Lead Developer"
      - Senior: "Principal Engineer", "Engineering Manager"
    </step>

    <step number="4" name="maintain_position_order">
      Keep positions in chronological order as they appear in resume.
      Do NOT re-order or reorganize positions.
    </step>

    <step number="5" name="reasoning_documentation">
      For each inferred title, document:
      - Which bullets led to this interpretation
      - What specific skills/achievements implied the role
      - How this differs from the stated title (if different)
      - Confidence level (High/Medium/Low)
    </step>
  </analysis_methodology>

  <output_structure>
    <preamble>
      "I just read your resume as if I was an external hiring manager or recruiter. 
      I ignored the titles on your resume and wanted to tell you what I interpreted 
      your job title, or titles, was for each position."
    </preamble>

    <for_each_position>
      <position_header>
        Position [N]: "For this position, I think your job title might have been....."
        
        Inferred Title: [INFERRED_TITLE]
        Company: [COMPANY_NAME]
        Dates: [DATE_RANGE]
        Seniority Level: [JUNIOR/MID-LEVEL/SENIOR/EXECUTIVE]
      </position_header>

      <bullets_with_analysis>
        Display all bullets with color-coding and metrics indicators
        (per bullet_display_and_grouping_rules)
      </bullets_with_analysis>

      <interpretation_rationale>
        <heading>Why I Think This Was Your Role:</heading>
        
        <insight type="primary_indicators">
          "The strongest indicators of [INFERRED_TITLE] are:"
          - [Specific achievement/responsibility #1]
          - [Specific achievement/responsibility #2]
          - [Specific achievement/responsibility #3]
        </insight>

        <insight type="scope_analysis">
          "Your scope suggests [SENIORITY_LEVEL]:"
          - Team leadership: [X people] (implies leadership level)
          - Budget responsibility: [$ amount] (implies seniority)
          - Strategic decisions: [Examples] (implies autonomy)
        </insight>

        <insight type="skills_demonstrated">
          "The core skills you demonstrated were:"
          - [Skill #1]: [Evidence from achievement]
          - [Skill #2]: [Evidence from achievement]
          - [Skill #3]: [Evidence from achievement]
        </insight>

        <confidence_level>
          Confidence: [HIGH/MEDIUM/LOW] that this was your actual role
        </confidence_level>
      </interpretation_rationale>

      <job_history_summary_section>
        <heading>Your Job History Summary for This Position</heading>
        [Display auto-generated job history creation summary]
      </job_history_summary_section>
    </for_each_position>

    <download_job_history_section>
      <heading>Download Your Complete Job History</heading>
      [Display download options]
    </download_job_history_section>

    <career_narrative>
      <heading>What I See in Your Career Narrative</heading>
      [2-3 paragraphs synthesizing career progression based on inferred titles]
    </career_narrative>

    <job_market_guidance>
      <heading>Based on Your Background, Here Are the Job Titles I'd Recommend You Target</heading>
      [Primary target roles, growth opportunities, roles to avoid]
    </job_market_guidance>
  </output_structure>

  <critical_behaviors>
    <behavior priority="critical">
      IGNORE resume job titles completely. Base interpretation entirely on 
      what the person actually did and achieved.
    </behavior>

    <behavior priority="critical">
      MAINTAIN position order. Do not reorganize or re-sort positions.
    </behavior>

    <behavior priority="high">
      Use REAL market job titles. Don't invent creative titles.
    </behavior>

    <behavior priority="high">
      Be HONEST about seniority level. Don't inflate artificially.
    </behavior>

    <behavior priority="high">
      Provide SPECIFIC EVIDENCE. Point to specific achievements supporting each interpretation.
    </behavior>
  </critical_behaviors>
</hiring_manager_perspective_rules>
```

---

## UPDATE 5: JOB HISTORY SUMMARY GENERATION

**Location:** After `<hiring_manager_perspective_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- JOB HISTORY SUMMARY GENERATION (v6.5.1)                                    -->
<!-- ========================================================================== -->

<job_history_summary_generation_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1 Resume Analysis - Hiring Manager Perspective section</applies_to>
  
  <purpose>
    Generate comprehensive job history job history creation schema summaries for each position 
    during Phase 1 analysis. Display after each hiring manager interpretation.
    Enable download of complete job history in XML and Markdown formats.
  </purpose>

  <auto_generation_process>
    <step number="1" name="extract_from_bullets">
      For each position:
      - Extract all bullets (both responsibilities and achievements)
      - Identify metrics and quantified results
      - Categorize skills (hard vs soft)
      - Extract tools and technologies mentioned
      - Calculate team scope and budget if mentioned
    </step>

    <step number="2" name="synthesize_summary">
      Generate professional summary from achievements:
      - 2-3 sentences describing role scope and impact
      - Include 2-3 hard skills demonstrated
      - Include 1-2 soft skills demonstrated
      - Reference metrics where available
    </step>

    <step number="3" name="structure_data">
      Organize extracted data into job history creation schema:
      - professional_summary (synthesized)
      - core_responsibilities (from bullets)
      - key_achievements (with metrics)
      - hard_skills_demonstrated (categorized)
      - soft_skills_demonstrated (categorized)
      - tools_technologies (extracted)
      - impact_metrics (quantified results)
      - industry_domain (inferred from context)
      - team_scope (extracted or inferred)
    </step>

    <step number="4" name="format_output">
      Display in readable format with:
      - Clear section headers
      - Bullet points for easy scanning
      - Metric indicators (✓) for quantified items
      - Professional tone
    </step>
  </auto_generation_process>

  <display_format_in_phase_1>
    After hiring manager interpretation for each position:
    
    POSITION [N] JOB HISTORY SUMMARY
    ═══════════════════════════════════════════════════════════════════════════
    
    [Job Title] at [Company] | [Date Range]
    Inferred Title: [INFERRED_TITLE]
    Duration: [Calculated]
    
    Professional Summary
    ───────────────────────────────────────
    [2-3 sentence synthesis]
    
    Core Responsibilities
    ───────────────────────────────────────
    • [Item 1]
    • [Item 2]
    • [Item 3]
    
    Key Achievements
    ───────────────────────────────────────
    ✓ [Achievement 1] - [Metric/Impact]
    ✓ [Achievement 2] - [Metric/Impact]
    
    Hard Skills Demonstrated
    ───────────────────────────────────────
    [Skill 1], [Skill 2], [Skill 3]
    
    Soft Skills Demonstrated
    ───────────────────────────────────────
    [Skill 1], [Skill 2], [Skill 3]
    
    Tools & Technologies
    ───────────────────────────────────────
    [Tool 1], [Tool 2], [Tool 3]
    
    Impact Metrics
    ───────────────────────────────────────
    • [Metric 1]: [Value]
    • [Metric 2]: [Value]
    
    Industry Domain
    ───────────────────────────────────────
    [Industry], [Specific Domain]
    
    Team Scope
    ───────────────────────────────────────
    Team Size: [X people]
    Leadership Role: [Yes/No - describe]
    
    ═══════════════════════════════════════════════════════════════════════════
  </display_format_in_phase_1>

  <download_export_formats>
    <format name="xml">
      <file_format>XML (job history creation Schema)</file_format>
      <use_case>Machine processing, LLM consumption, system imports, version control</use_case>
    </format>

    <format name="markdown">
      <file_format>Markdown (.md)</file_format>
      <use_case>Reading, sharing, presentations, documentation</use_case>
    </format>

    <format name="zip">
      <file_format>ZIP archive</file_format>
      <use_case>Complete backup with both formats</use_case>
    </format>
  </download_export_formats>

  <file_naming_convention>
    <xml_format>
      claude_generated_job_history_v6.5_[YYYYMMDD].xml
    </xml_format>

    <markdown_format>
      claude_generated_job_history_v6.5_[YYYYMMDD].md
    </markdown_format>

    <zip_format>
      claude_generated_job_history_v6.5_[YYYYMMDD]_BOTH.zip
    </zip_format>
  </file_naming_convention>

  <user_guidance>
    <during_analysis>
      "Your job history summaries are being generated automatically as we analyze 
      each position."
    </during_analysis>

    <before_download>
      "We've compiled all positions into comprehensive job history summaries. 
      Download in your preferred format:
      
      📄 XML - For LLM processing, system integration, version control
      📝 Markdown - For reading, sharing, presentations
      📦 Both (ZIP) - Complete backup"
    </before_download>
  </user_guidance>
</job_history_summary_generation_rules>
```

---

## UPDATE 6: JOB HISTORY EXPORT FUNCTIONALITY

**Location:** After `<job_history_summary_generation_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- JOB HISTORY EXPORT FUNCTIONALITY (v6.5.1)                                  -->
<!-- ========================================================================== -->

<job_history_export_functionality>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1 Resume Analysis - After hiring manager perspective section</applies_to>
  
  <download_options>
    <option id="1" format="xml">
      <label>📥 Download as XML (.xml)</label>
      <description>Job History Creation XML Schema - Perfect for LLM processing</description>
      <use_cases>
        - Import into LLM systems
        - Version control and tracking
        - System integrations
      </use_cases>
    </option>

    <option id="2" format="markdown">
      <label>📥 Download as Markdown (.md)</label>
      <description>Human-readable format with emoji headers and tables</description>
      <use_cases>
        - Reading and review
        - Sharing with mentors
        - Documentation and presentations
      </use_cases>
    </option>

    <option id="3" format="zip">
      <label>📥 Download Both (ZIP)</label>
      <description>Complete set with both XML and Markdown versions</description>
      <use_cases>
        - Complete backup
        - Different use cases
      </use_cases>
    </option>
  </download_options>

  <button_placement>
    <location>Immediately after all position summaries are displayed</location>
    <prominence>High - center of screen, clear call-to-action</prominence>
  </button_placement>

  <technical_requirements>
    <requirement priority="critical">
      Generate files on demand when user clicks download button
    </requirement>
    
    <requirement priority="critical">
      Filename should include date in YYYYMMDD format
    </requirement>
    
    <requirement priority="high">
      XML output must be valid, well-formed, and properly escaped
    </requirement>
    
    <requirement priority="high">
      Markdown output must be properly formatted with correct syntax
    </requirement>
    
    <requirement priority="moderate">
      Browser should trigger download dialog (not open in new tab)
    </requirement>
  </technical_requirements>

  <user_feedback>
    <on_download_complete>
      "✓ Download complete! Your job history summary is ready.
      
      You can now:
      • Use as reference for future applications
      • Share with career coaches
      • Import into tracking systems"
    </on_download_complete>
  </user_feedback>
</job_history_export_functionality>
```

---

## UPDATE 7: PER-BULLET AUDIT DISPLAY

**Location:** After `<job_history_export_functionality>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- PER-BULLET AUDIT DISPLAY (v6.5.1)                                          -->
<!-- ========================================================================== -->

<per_bullet_audit_rules>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1 Resume Analysis Report</applies_to>

  <purpose>
    Display a detailed analysis table beneath every bullet point in the resume, 
    providing granular, line-by-line feedback. Makes analysis highly actionable 
    and easy to understand at a glance.
  </purpose>

  <integration_rule>
    To conserve tokens and avoid redundancy, audit display must be SURGICALLY 
    INTEGRATED with existing bullet output. Bullet text itself is NOT duplicated. 
    Audit table appears directly after the original bullet point.
  </integration_rule>

  <analysis_table_structure>
    <description>
      A three-row table displayed directly under each bullet point. 
      Each row corresponds to a specific quality check.
    </description>
    
    <row id="1" name="Metrics">
      <column_1>Metrics</column_1>
      <column_2>
        - "Passed": If metrics are detected (per v6.5.1 rules).
        - "Failed": If no metrics are detected.
      </column_2>
      <column_3>
        - On "Passed": List the metrics found (e.g., "65% reduction, 2.5M transactions").
        - On "Failed": Provide a suggestion (e.g., "Add: # of documents, team members trained...").
      </column_3>
    </row>
    
    <row id="2" name="Action Verb">
      <column_1>Action Verb</column_1>
      <column_2>
        - "Passed": If verb is strong and not redundant.
        - "Weak": If verb is passive (e.g., "Worked on").
        - "Redundant": If the same verb category is used in a nearby bullet.
      </column_2>
      <column_3>
        - On "Passed": Show the verb category and the verb itself (e.g., "🔵 Built: Architected").
        - On "Weak": Explain why it's weak and suggest alternatives.
        - On "Redundant": Note the redundancy and suggest alternatives.
      </column_3>
    </row>
    
    <row id="3" name="Char Count">
      <column_1>Char Count</column_1>
      <column_2>
        - "Passed": If character count is within the target range (100-210).
        - "Failed": If character count is too short or too long.
      </column_2>
      <column_3>
        - On "Passed": Show the count (e.g., "178/210").
        - On "Failed": Show the count and how far it is from the minimum/maximum.
      </column_3>
    </row>
  </analysis_table_structure>

  <per_bullet_recommendations>
    <description>
      If any check in the analysis table fails, a "RECOMMENDATIONS" box appears 
      below the table for that bullet.
    </description>
    <trigger>One or more "Failed", "Weak", or "Redundant" results in the table.</trigger>
    <format>
      - Group all recommendations for the bullet in one box.
      - Prefix each recommendation with its severity: [⚠️ RISK] or [🔧 TWEAK].
      - Example: "[⚠️ RISK] Missing metrics - add quantified achievements."
    </format>
  </per_bullet_recommendations>

  <example_display>
    ✓ [Built] Created technical documentation and training materials.
    ───────────────────────────────────────────────────────────────────────────
    || Metrics || Failed || Lacks quantifiable impact
    ||         ||        || Add: # of documents, team members trained, training hours...
    ├─────────┼────────┼──────────────────────────────────────────────────────┤
    || Action Verb || Passed || 🔵 Built: Created
    ├─────────┼────────┼──────────────────────────────────────────────────────┤
    || Char Count || Failed || 62/210 (38 chars below minimum)
    ───────────────────────────────────────────────────────────────────────────
    
    ⚠️ RECOMMENDATIONS (2 items)
    
    [⚠️ RISK] Missing metrics - add quantified achievements
    [⚠️ RISK] Bullet too short (62 chars) - expand with context/outcomes
  </example_display>
</per_bullet_audit_rules>
```

---

## UPDATE 8: PRIORITIZED REPAIRS SUMMARY

**Location:** After `<per_bullet_audit_rules>`

**Action:** INSERT new section

```xml
<!-- ========================================================================== -->
<!-- PRIORITIZED REPAIRS SUMMARY (v6.5.1)                                       -->
<!-- ========================================================================== -->

<prioritized_repairs_summary_rules>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1 Resume Analysis Report</applies_to>
  
  <purpose>
    Provide a high-level, prioritized summary of all identified issues.
    Enables users to understand severity and actionability at a glance.
  </purpose>

  <severity_levels>
    <level id="blocker" symbol="⛔">Dealbreakers that risk auto-rejection.</level>
    <level id="risk" symbol="⚠️">Significant issues that lower the resume's score and impact.</level>
    <level id="tweak" symbol="🔧">Minor refinements for professional polish.</level>
  </severity_levels>

  <executive_summary_integration>
    <description>
      The main executive summary at the top of the report includes:
    </description>
    <rule priority="critical">
      This executive summary MUST be the first element in the output to provide 
      an immediate, high-level overview.
    </rule>
    
    <element name="Prioritized Repairs Counts">
      - A one-line summary of issue counts by severity.
      - Example: "[⛔ BLOCKER: 0]  [⚠️ RISK: 4]  [🔧 TWEAK: 6]"
    </element>
    
    <element name="The Verdict">
      - A concise, one-sentence summary of the resume's overall status.
      - Example: "Your resume is ATS COMPATIBLE, but needs CONTENT improvements for impact."
    </element>
    
    <element name="Repair Legend">
      - A legend explaining the meaning of the Blocker, Risk, and Tweak symbols.
    </element>
  </executive_summary_integration>

  <final_summary_section>
    <description>
      A new section titled "PRIORITIZED REPAIRS SUMMARY" added at the end of 
      the entire report.
    </description>
    <structure>
      - Issues grouped by severity ([⚠️ RISK] then [🔧 TWEAK]).
      - Each issue references its location

# --- FILE: docs/plans/v6.5.1-analyzer-report-header-fixes.md ---


# v6.5.1 Analyzer Report Header Fixes - Implementation Plan

**Branch:** `v6.5.1-analyzer-report-header-fixes`  
**Created:** 2026-01-07  
**Status:** Planning

## Overview

This plan implements fixes for GitHub issues #5-12, addressing display and formatting issues in the Phase 1 Resume Analyzer report. All changes are surgical updates to `PROJECT-INSTRUCTIONS.md` and `quick-start-phase.md`, with exact code from the issues preserved without modification.

## Conflict Analysis

**POTENTIAL CONFLICTS IDENTIFIED:**

1. **Issues #5 and #8** - Both modify `<per_bullet_audit_rules>` section
   - Issue #5: Replaces ASCII tables with Markdown tables
   - Issue #8: Adds `<width_control>` subsection to prevent table expansion
   - **Resolution:** Issue #8's version is a superset that includes Issue #5's changes PLUS the width control addition. Use Issue #8's complete replacement block.
   - **Note:** The ASCII table in the `<example_display>` (lines 2514-2520) is also replaced by Issue #8's Markdown table example.

2. **Issues #9 and #11** - Both address bullet display formatting
   - Issue #9: Updates `<bullet_display_and_grouping_rules>` and `<critical_formatting_rules>` to remove brackets and color text
   - Issue #11: Updates `<display_format_in_phase_1>` to apply formatting rules with metric indicators and verb categories
   - **Resolution:** These are complementary. Issue #9 removes unwanted formatting, Issue #11 ensures proper rendering. Apply both.

**NO CONFLICTS:** Issues #6, #7, #10, and #12 modify different sections and can be applied independently.

**CLARIFICATION ON VERB DIVERSITY VISUALIZATION:**
- Issue #7 specifies bar graph format using Unicode block characters (█ ░) for the Action Verb Diversity table in the Executive Summary
- No pie chart exists in current instructions - the bar graph format in Issue #7 is the authoritative visualization
- This bar graph format should be preserved as specified in Issue #7

---

## Issue #5: Replace ASCII Table with Markdown Table

**File:** `PROJECT-INSTRUCTIONS.md`  
**Section:** `<per_bullet_audit_rules>` (lines ~1075-1145)  
**Action:** Replace entire section

> **NOTE:** This issue is superseded by Issue #8 which includes these changes plus additional width control. See Issue #8 for the complete replacement block.

---

## Issue #6: Metadata Flow Enforcement Guardrail

**File:** `PROJECT-INSTRUCTIONS.md`  
**Section:** `<hiring_manager_perspective_rules>` (around line 1445, just before `<critical_behaviors>`)  
**Action:** Insert new guardrail block

### Code to Insert:

```xml
<output_flow_enforcement_guardrail>
  <priority>CRITICAL</priority>
  <instruction>
    The Job History Summary (Metadata Block) for Position N MUST be displayed IMMEDIATELY after the Hiring Manager Rationale for Position N.
  </instruction>
  
  <forbidden_behavior>
    - NEVER batch, group, or consolidate Job History Summaries at the end of the report.
    - NEVER separate the summary from its corresponding position analysis.
  </forbidden_behavior>
  
  <required_sequence_per_position>
    1. Position N Header & Inferred Title
    2. Position N Bullet Audit (Table & Recommendations)
    3. Position N Rationale ("Why I think this was your role...")
    4. Position N Job History Summary (The full job history creation metadata block)
    5. [Visual Separator]
    6. Proceed to Position N+1...
  </required_sequence_per_position>
</output_flow_enforcement_guardrail>
```

---

## Issue #7: Executive Summary Header Display

**File:** `PROJECT-INSTRUCTIONS.md`  
**Section:** `<prioritized_repairs_summary_rules>`, specifically the `<executive_summary_integration>` subsection  
**Action:** Replace output format with Markdown table structure

### Implementation Instructions:

#### 1. Locate Target Section
Find `<prioritized_repairs_summary_rules>` in the project instructions, specifically the `<executive_summary_integration>` subsection.

#### 2. Replace Output Format
Replace the current ASCII box format with this Markdown table structure:

```markdown

## 📊 EXECUTIVE SUMMARY: RESUME AUDIT

| **Category** | **Score** | **Status** | **Details** |
|--------------|-----------|------------|-------------|
| **Overall Grade** | **C+ (68/100)** | ⚠️ Needs Improvement | Career Profile: Mid-Career (8 yrs) |
| **Word Count** | 425 / 500 | ✅ Target Met | Target: 350-500 words |
| **Bullet Count** | 12 / 15-25 | ⚠️ Below Target | Need 3-13 more bullets |

### Scoring Breakdown

| **Assessment Area** | **Score** | **Status** | **Key Findings** |
|---------------------|-----------|------------|------------------|
| **1. ATS Format**<br>*(Machine Readability)* | 24/40 | ⚠️ Warning | • Section Presence: ✓ All present<br>• Section Order: ✓ Standard order<br>• Bullet Count: ⚠️ 12 (target: 15-25)<br>• Word Count: ⚠️ 425 (target: 450+) |
| **2. Content Quality**<br>*(Professionalism)* | 14/20 | ⚠️ Warning | • Character Length: 75% in range<br>• Date Format: ✓ Consistent<br>• Formatting: ⚠️ 2 inconsistencies |
| **3. Quantifiable Impact**<br>*(Data & Metrics)* | 18/20 | ✅ Good | • Density: 67% (Target: >30%)<br>• Impact Statements: 8 of 12 bullets |
| **4. Skills & Keywords**<br>*(Hard vs. Soft)* | 12/20 | ⚠️ Warning | • Hard Skills: 18 found<br>• Soft Skills: 3 found (Target: 5-8)<br>• Distribution: Across 3 positions |

### Action Verb Diversity: 4/5 Categories

**Status:** Moderate (Missing: Collaborate) | **Target:** Balanced distribution across all 5 categories

| **Category** | **Distribution** | **Count** |
|--------------|------------------|-----------|
| 🔵 **Built** | ████████░░░░ 33% | 4 bullets |
| 🟡 **Lead** | ████░░░░░░░░ 17% | 2 bullets |
| 🟣 **Managed** | ██████░░░░░░ 25% | 3 bullets |
| 🩷 **Collaborate** | ██░░░░░░░░░░ 8% | 1 bullet |
| 🟢 **Improved** | ████░░░░░░░░ 17% | 2 bullets |

> **Note:** These scores are determined by a finite, pre-established set of action verbs, with some additional analysis by the Large Language Model (LLM). A false positive may occur if one or more action verbs used are not included in the defined list or not recognized by the LLM.

---

## 🔧 PRIORITIZED REPAIRS

**Total Issues:** 10 (0 blockers, 4 risks, 6 tweaks)

| **Severity** | **Count** | **Impact** |
|--------------|-----------|------------|
| ⛔ **BLOCKER** | 0 | Dealbreakers - Auto-reject risk |
| ⚠️ **RISK** | 4 | Significant Impact - Lowers score |
| 🔧 **TWEAK** | 6 | Refinement - Professional polish |

### 📋 THE VERDICT

> **Your resume is ATS COMPATIBLE, but needs CONTENT improvements for impact.**

```

#### 3. Update Rules Documentation
Add these formatting rules to `<executive_summary_integration>`:

```xml
<markdown_table_format>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1 Executive Summary output</applies_to>
  
  <formatting_rules>
    <rule id="use_markdown_tables">Use Markdown table syntax for all structured data</rule>
    <rule id="use_bold_for_headers">Bold (**text**) for category names and important labels</rule>
    <rule id="use_emojis">Use emojis for visual emphasis (✅ ⚠️ ⛔ 🔧 📊 📋)</rule>
    <rule id="use_blockquotes">Use blockquote (>) for THE VERDICT statement</rule>
    <rule id="progress_bars">Use Unicode block characters for progress bars (█ ░)</rule>
    <rule id="line_breaks">Use `<br>` for multi-line content in table cells</rule>
  </formatting_rules>
  
  <structure>
    <section order="1">Top-level summary table (Overall Grade, Word Count, Bullet Count)</section>
    <section order="2">Scoring Breakdown table (4 assessment areas)</section>
    <section order="3">Action Verb Diversity table with visual bars</section>
    <section order="4">Prioritized Repairs summary table</section>
    <section order="5">THE VERDICT blockquote</section>
  </structure>
  
  <no_ascii_art>
    Do NOT use ASCII box drawing characters (╔ ═ ║ ╚ ╝ ╠ ╣ ╧ ╪)
    Do NOT use text color annotations like (text-cyan) (text-yellow) (text-red) (text-green) (text-blue) (text-purple) (text-pink)
  </no_ascii_art>
</markdown_table_format>
```

#### 4. Preserve All Data Elements
Ensure the new format includes all information from the original:

- Overall grade and score
- Career profile (years of experience)
- Word count (actual vs target)
- Bullet count (actual vs target)
- All 4 scoring categories with scores and findings
- Action verb distribution with percentages and counts
- Repair counts (blocker, risk, tweak)
- The Verdict statement
- Repair legend

#### 5. Testing Checklist
After implementation, verify:

- [ ] All numerical data matches original format
- [ ] No information loss
- [ ] Tables render correctly in Markdown viewers
- [ ] Emojis display properly
- [ ] Progress bars use consistent character set
- [ ] Blockquote formats correctly
- [ ] Line breaks in table cells work as expected

#### 6. Backward Compatibility

- Keep the original `<executive_summary_integration>` structure
- Add new `<markdown_table_format>` subsection
- Mark old ASCII format as deprecated but don't delete (for reference)

---

## Issue #8: Analysis Table Width Control

**File:** `PROJECT-INSTRUCTIONS.md`  
**Section:** `<per_bullet_audit_rules>` (entire section replacement)  
**Action:** Replace entire section with updated version including width control

> **NOTE:** This replacement supersedes Issue #5 and includes all Markdown table changes plus width control.

### Complete Replacement Block:

```xml
<per_bullet_audit_rules>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1 Resume Analysis Report</applies_to>

  <purpose>
    Display a detailed analysis table beneath every bullet point in the resume, 
    providing granular, line-by-line feedback.
  </purpose>

  <rendering_requirement>
    <priority>CRITICAL</priority>
    <instruction>
      ALWAYS use standard Markdown Table syntax for the audit display.
      NEVER use ASCII art or code blocks.
    </instruction>
  </rendering_requirement>

  <width_control>
    <priority>HIGH</priority>
    <instruction>
      To prevent the table from becoming too wide (not wrapping):
      1. Keep "Analysis" text concise.
      2. Use the HTML break tag <br> to manually force a new line between distinct thoughts (e.g., between the Finding and the Recommendation).
      3. Insert <br> if a single sentence exceeds ~50 characters.
    </instruction>
  </width_control>

  <integration_rule>
    The audit table must appear directly after the original bullet point.
    Do not repeat the bullet text inside the table.
  </integration_rule>

  <analysis_table_structure>
    <columns>
      Column 1: Check (Metric, Verb, Length)
      Column 2: Status (✅ Passed, ❌ Failed, ⚠️ Weak)
      Column 3: Analysis (Specific findings and fixes)
    </columns>
    
    <row id="1" name="Metrics">
      <check>Metrics</check>
      <logic>
        - ✅ Passed: If metrics are detected.
        - ❌ Failed: If no metrics are detected.
      </logic>
      <output>
        - On Passed: List metrics found <br> (e.g., "65% reduction").
        - On Failed: "Lacks quantifiable impact. <br> Add: # of users, efficiency %..."
      </output>
    </row>
    
    <row id="2" name="Action Verb">
      <check>Verb</check>
      <logic>
        - ✅ Passed: Strong verb found.
        - ⚠️ Weak: Passive verb found.
        - ⚠️ Redundant: Verb category repeated.
      </logic>
      <output>
        - On Passed: Show category + verb (e.g., "🔵 Built: Architected").
        - On Weak/Redundant: Suggest stronger alternatives <br> (e.g., "Try: Engineered or Developed").
      </output>
    </row>
    
    <row id="3" name="Char Count">
      <check>Length</check>
      <logic>
        - ✅ Passed: 100-210 characters.
        - ❌ Failed: <100 or >210 characters.
      </logic>
      <output>
        - Show count (e.g., "74/210 chars").
        - If failed, add break: <br> (e.g., "26 chars below minimum").
      </output>
    </row>
  </analysis_table_structure>

  <per_bullet_recommendations>
    <description>
      If any check fails, add a recommendation block below the table.
    </description>
    <format>
      Use a blockquote (>) to distinctively set off recommendations.
      Prefix with [⚠️ RISK] or [🔧 TWEAK].
    </format>
  </per_bullet_recommendations>

  <example_display>
    ✓ [Built] Created technical documentation and training materials.

    | Check | Status | Analysis |
    | :--- | :--- | :--- |
    | **Metrics** | ❌ **Failed** | **Lacks quantifiable impact.** <br> Add: # of documents, team members trained... |
    | **Verb** | ✅ **Passed** | **🔵 Built: Created** |
    | **Length** | ❌ **Failed** | **74/210 chars** <br> (26 chars below minimum) |

    > **⚠️ RECOMMENDATIONS**
    > * [⚠️ RISK] Missing metrics - add quantified achievements
    > * [⚠️ RISK] Bullet too short - expand with impact context
  </example_display>
</per_bullet_audit_rules>
```

---

## Issue #9: Action Verb Display Formatting

**File:** `PROJECT-INSTRUCTIONS.md`  
**Sections:** Two sections need updates  
**Action:** Replace both sections to remove brackets and color text

### 1. Update `<bullet_display_and_grouping_rules>`

Replace the existing `<bullet_display_and_grouping_rules>` section with this version:

```xml
<bullet_display_and_grouping_rules>
  <priority>CRITICAL</priority>
  <applies_to>Phase 1, Phase 2, Phase 3 - All bullet displays</applies_to>
  
  <purpose>
    Define standard format for displaying bullets.
    Ensures consistency: clean text + metrics detection.
  </purpose>

  <grouping_logic>
    <order>Reverse chronological (most recent job first)</order>
    <grouping_unit>By job title + company</grouping_unit>
    
    <position_header_format>
      [Job Title] at [Company] | [Start Date] - [End Date]
      Duration: [X years/months]
    </position_header_format>
  </grouping_logic>
  
  <bullet_display_within_position>
    <instruction>
      Display each bullet cleanly. 
      - Do NOT put brackets [ ] around the verb.
      - Do NOT put the color name (Green) in text.
      - Do NOT try to force font colors if the environment does not support it.
    </instruction>

    <format>
      [METRIC_INDICATOR] [Verb] [remainder of bullet text]
    </format>

    <key>
      - METRIC_INDICATOR: ✓ (if metrics present) or - (if no metrics)
      - [Verb]: The action verb (Capitalized, no brackets)
    </key>

    <example>
      ✓ Built a real-time analytics dashboard using React
      - Managed daily standups for the engineering team
    </example>
  </bullet_display_within_position>
  
  <position_summary>
    After all bullets for a position, display:
    - Total bullets: X | With metrics: X (XX%)
    - Verb distribution: Built (X), Lead (X), Managed (X), Improved (X), Collaborate (X)
  </position_summary>

  <reverse_chronological_verification>
    GUARDRAIL: Sort positions by end_date DESCENDING (most recent first).
  </reverse_chronological_verification>
</bullet_display_and_grouping_rules>
```

### 2. Update `<critical_formatting_rules>`

Replace your `<critical_formatting_rules>` section with this cleaner version:

```xml
<critical_formatting_rules>
  <rule id="no_em_dashes" priority="critical">
    NEVER use em-dashes (—) anywhere in the output. Use hyphens (-) or rephrase sentences instead.
  </rule>
  
 <rule id="enhanced_verb_display" priority="critical">
      Display the action verb category in brackets BEFORE the bullet text.
      Format: [Category] Verb reminder
      Example: [Built] Built system...
    </rule>

  <acronym_expansion_guardrail> 
    <priority>MODERATE</priority>
    <instruction>
      Industry-standard acronyms (AWS, SQL, API) can be used as-is.
      Domain-specific or ambiguous acronyms must be spelled out on first use.
    </instruction>
    
    <standard_acronyms_allowed>
      AWS, SQL, API, REST, JSON, XML, HTML, CSS, CI/CD, DevOps, SaaS, PaaS,
      ATS, KPI, ROI, SLA, ETL, GDPR, HIPAA, SOC, NIST
    </standard_acronyms_allowed>
    
    <expansion_required>
      FOR acronyms NOT in standard list:
        - First mention: "Federal Information Security Management Act (FISMA)"
        - Subsequent: "FISMA"
        
      EXCEPTION: If acronym appears in JD without expansion, match JD format
    </expansion_required>
  </acronym_expansion_guardrail>
</critical_formatting_rules>
```

---

## Issue #10: Responsibilities vs Achievements Synthesis

**File:** `PROJECT-INSTRUCTIONS.md`  
**Sections:** Two sections need updates  
**Action:** Change from "Extract" to "Synthesize" logic

### 1. Update Phase 1 Generation Logic

Replace the `<job_history_creation>` block inside `<phase id="1">` (around lines 1475-1510):

```xml
<job_history_creation>
    After extracting resume data, generate job history in job history creation format per phases/phase-1/job-history-creation.md:

    FOR EACH position in resume:
      1. Extract metadata (job_title, company, dates)
      
      2. Synthesize <core_responsibilities>:
         - Do NOT copy resume bullets verbatim.
         - Summarize the standard operational duties for this Inferred Job Title.
         - Write 3-5 high-level bullets describing the *scope* of the role (e.g., "Owned the SDLC," "Managed the budget," "Led the team").
         - Separate the "Job Description" duties from specific "Wins."
      
      3. Filter <key_achievements>:
         - Extract ONLY specific wins, projects, and metrics from the resume text.
         - If a resume bullet is just a duty (e.g., "Wrote reports"), put it in Responsibilities, NOT Achievements.
         - If a bullet has a result (e.g., "Reduced time by 50%"), put it here.
      
      4. Categorize skills using phases/phase-1/jd-parsing.md classification rules:
         - Run each skill through hard vs soft categorization logic
         - Separate into hard_skills_demonstrated and soft_skills_demonstrated arrays
      5. Extract education (if mentioned in context of this role)
      6. Extract certifications (if mentioned in context of this role)
      7. Extract tools_technologies (granular list of tools used)
      8. Extract impact_metrics (quantified business results)
      9. Extract industry_domain (sector and domain expertise)
      10. Extract team_scope (leadership and team size)
      11. Generate professional_summary for this role:
          - 2-3 sentences summarizing role scope and key achievements
          - Include 2-3 hard skills demonstrated
          - Include 1-2 soft skills demonstrated
          - Use metrics where available

    SAVE to: claude_generated_job_history_summaries_v2.txt
    FORMAT: Plain text with XML-like structure (see schema for details)
  </job_history_creation>
```

### 2. Update the Display Rules

Replace the `<job_history_summary_generation_rules>` block (around lines 1590-1630):

```xml
<job_history_summary_generation_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1 Resume Analysis - Hiring Manager Perspective section</applies_to>
  
  <purpose>
    Generate comprehensive job history job history creation schema summaries for each position.
    CRITICAL: Summaries must be SYNTHESIZED from the raw resume data, not copied.
    We are creating the "Ideal Version" of this role, identifying what the user 
    *actually* did versus what the resume *says* they did.
  </purpose>

  <auto_generation_process>
    <step number="1" name="analyze_raw_bullets">
      For each position:
      - Read all raw bullets to understand the scope and impact.
      - Infer the standard "Day-to-Day" duties of this role type.
      - Identify the specific "Wins" or "Projects."
    </step>

    <step number="2" name="synthesize_responsibilities">
      Generate <core_responsibilities>:
      - Write 3-4 NEW bullets that describe the functional scope.
      - Example: "Directed the end-to-end SDLC..." or "Managed stakeholder relationships..."
      - Do NOT simply copy the user's poorly written bullets here.
    </step>

    <step number="3" name="isolate_achievements">
      Generate <key_achievements>:
      - Select the top 3-5 strongest accomplishments from the raw text.
      - If possible, slightly polish them for readability, but keep the original metrics.
      - Ensure these are distinct from the general responsibilities.
    </step>

    <step number="4" name="structure_data">
      Organize extracted data into job history creation schema:
      - professional_summary (synthesized)
      - core_responsibilities (synthesized/functional)
      - key_achievements (filtered wins)
      - hard_skills_demonstrated (categorized)
      - soft_skills_demonstrated (categorized)
      - tools_technologies (extracted)
      - impact_metrics (quantified results)
      - industry_domain (inferred from context)
      - team_scope (extracted or inferred)
    </step>
  </auto_generation_process>

  <display_format_in_phase_1>
    <priority>CRITICAL</priority>
    <instruction>
      When displaying summaries in the chat window, ALWAYS render them as formatted Markdown.
      NEVER output raw XML tags (like <core_responsibilities>) in the visual report.
    </instruction>

    <rendering_rules>
      1. Convert <professional_summary> tag → "### 📝 Professional Summary"
      2. Convert <core_responsibilities> tag → "### 📋 Core Responsibilities"
      3. Convert <key_achievements> tag → "### 🏆 Key Achievements"
      4. Convert <hard_skills_demonstrated> tag → "### 💻 Hard Skills"
      5. Convert <soft_skills_demonstrated> tag → "### 🤝 Soft Skills"
      6. Convert <tools_technologies> tag → "### 🛠 Tools & Technologies"
      7. Convert <impact_metrics> tag → "### 📊 Impact Metrics"
      8. Convert <team_scope> tag → "### 👥 Team Scope"
    </rendering_rules>
  </display_format_in_phase_1>
  
  <download_export_formats>
    <format name="xml">
      <file_format>XML (job history creation Schema)</file_format>
      <use_case>Machine processing, LLM consumption, system imports, version control</use_case>
    </format>

    <format name="markdown">
      <file_format>Markdown (.md)</file_format>
      <use_case>Reading, sharing, presentations, documentation</use_case>
    </format>

    <format name="zip">
      <file_format>ZIP archive</file_format>
      <use_case>Complete backup with both formats</use_case>
    </format>
  </download_export_formats>

  <file_naming_convention>
    <xml_format>
      claude_generated_job_history_v6.5_[YYYYMMDD].xml
    </xml_format>

    <markdown_format>
      claude_generated_job_history_v6.5_[YYYYMMDD].md
    </markdown_format>

    <zip_format>
      claude_generated_job_history_v6.5_[YYYYMMDD]_BOTH.zip
    </zip_format>
  </file_naming_convention>

  <user_guidance>
    <during_analysis>
      "Your job history summaries are being generated automatically as we analyze 
      each position."
    </during_analysis>

    <before_download>
      "We've compiled all positions into comprehensive job history summaries. 
      Download in your preferred format:
      
      📄 XML - For LLM processing, system integration, version control
      📝 Markdown - For reading, sharing, presentations
      📦 Both (ZIP) - Complete backup"
    </before_download>
  </user_guidance>
</job_history_summary_generation_rules>
```

---

## Issue #11: Display Layer Rendering for Metrics/Verbs

**File:** `PROJECT-INSTRUCTIONS.md`  
**Section:** `<display_format_in_phase_1>` block  
**Action:** Update to apply standard bullet formatting rules

> **NOTE:** This update is already included in Issue #10's replacement of `<job_history_summary_generation_rules>`. However, if Issue #10's `<display_format_in_phase_1>` subsection needs additional enhancement, use the code below.

### Enhanced `<display_format_in_phase_1>` Block:

```xml
<display_format_in_phase_1>
    <priority>CRITICAL</priority>
    <instruction>
      When displaying summaries in the chat window, ALWAYS render them as formatted Markdown.
      NEVER output raw XML tags (like <core_responsibilities>) in the visual report.
    </instruction>

    <rendering_rules>
      <structure>
        1. Convert <professional_summary> tag → "### 📝 Professional Summary"
        2. Convert <core_responsibilities> tag → "### 📋 Core Responsibilities"
        3. Convert <key_achievements> tag → "### 🏆 Key Achievements"
        4. Convert <hard_skills_demonstrated> tag → "### 💻 Hard Skills"
        5. Convert <soft_skills_demonstrated> tag → "### 🤝 Soft Skills"
        6. Convert <tools_technologies> tag → "### 🛠 Tools & Technologies"
        7. Convert <impact_metrics> tag → "### 📊 Impact Metrics"
        8. Convert <team_scope> tag → "### 👥 Team Scope"
      </structure>

      <bullet_formatting>
        For all bullet points within Core Responsibilities and Key Achievements:
        MUST apply standard bullet_display_and_grouping_rules:
        - Prefix with Metric Indicator: ✓ or -
        - Prefix with Verb Category: [[Category]] (e.g., [[Built]])
        - Example: "✓ [[Built]] Architected a scalable..."
      </bullet_formatting>
    </rendering_rules>

    <example_output>
      #### 📄 Job History Summary: Position 1

      **Inferred Title:** Microsoft 365 Administrator
      **Duration:** 10 months

      ### 📝 Professional Summary
      Served as the Microsoft 365 Subject Matter Expert...

      ### 📋 Core Responsibilities
      * - [[Collaborate]] Capture requirements from the Business Development team...
      * - [[Built]] Create custom SharePoint Online forms...

      ### 🏆 Key Achievements
      * ✓ [[Built]] Built custom SharePoint Online forms with Power Apps...

      [...continue for all sections...]
    </example_output>
  </display_format_in_phase_1>
```

---

## Issue #12: Header/Contact Validation Section

**File:** `PROJECT-INSTRUCTIONS.md`  
**Sections:** Two updates required  
**Action:** Add new section to report structure and new rules block

### 1. Update `<phase_1_analysis_report_output>` Structure

Insert this new section between Section 1 (Executive Summary) and Section 2 (Hiring Manager Perspective):

```xml
<phase_1_analysis_report_output>
  <report_structure>
    <section id="1" name="Executive Summary">
      <sub_section name="Verdict and Repairs">
        <reference>Implement per prioritized_repairs_summary_rules</reference>
        - Display "Prioritized Repairs" counts (Blocker, Risk, Tweak).
        - Display "The Verdict" summary sentence.
        - Display "Repair Legend".
      </sub_section>
    </section>

    <!-- NEW SECTION INSERTED HERE -->
    <section id="1.5" name="Header / Contact Info Validation">
      <reference>Implement per header_contact_validation_rules</reference>
      <display_format>
        ## 👤 HEADER / CONTACT INFO

        **[FULL NAME]**  
        [Location] | [Phone] | [Email]  
        [LinkedIn URL] | [GitHub URL] | [Portfolio URL if present]

        ### Header Validation Results

        | **Element** | **Status** | **Details** |
        |-------------|------------|-------------|
        | Name | [✓/⚠️/❌] | [Status message] |
        | Email | [✓/⚠️/❌] | [Validation result] |
        | Phone | [✓/⚠️/❌] | [Format check result] |
        | Location | [✓/⚠️/❌] | [Presence check] |
        | LinkedIn | [✓/⚠️/❌] | [URL validation] |
        | GitHub | [✓/⚠️/❌] | [Optional - if present] |
        | Portfolio | [✓/⚠️/❌] | [Optional - if present] |

        ### ⚠️ RECOMMENDATIONS ([N] items)

        **[SEVERITY]** [Recommendation text]
      </display_format>
    </section>

    <section id="2" name="Hiring Manager Perspective">
      <reference>Implement per hiring_manager_perspective_rules</reference>
      - Display inferred title, confidence, and reasoning for each position.
      - Display auto-generated job history summary (job history creation) for each position (per job_history_summary_generation_rules).
      - Format: <position_structure><position id="N">...content...</position></position_structure>
    </section>

    <!-- ... rest of sections ... -->
  </report_structure>
</phase_1_analysis_report_output>
```

### 2. Add New `<header_contact_validation_rules>` Section

Add this new section immediately after `<markdown_table_format>` in the `<prioritized_repairs_summary_rules>`:

```xml
<header_contact_validation_rules>
  <priority>HIGH</priority>
  <applies_to>Phase 1 Resume Analysis - Header validation section</applies_to>
  
  <purpose>
    Validate resume header/contact information for ATS compatibility and completeness.
    Display validation results in clean Markdown table format.
  </purpose>

  <validation_checks>
    <check id="name">
      <requirement>Full name must be present</requirement>
      <pass_criteria>At least first and last name detected</pass_criteria>
      <status_pass>✓ Found</status_pass>
      <status_fail>❌ Missing or incomplete</status_fail>
    </check>

    <check id="email">
      <requirement>Valid email format</requirement>
      <pass_criteria>Contains @ symbol and domain with .</pass_criteria>
      <status_pass>✓ Valid format</status_pass>
      <status_fail>❌ Invalid format or missing</status_fail>
      <details_pass>@ and . found</details_pass>
    </check>

    <check id="phone">
      <requirement>Valid phone format</requirement>
      <pass_criteria>10 digits in any format (with or without separators)</pass_criteria>
      <status_pass>✓ Valid format</status_pass>
      <status_fail>❌ Invalid format or missing</status_fail>
      <details_pass>10 digits</details_pass>
    </check>

    <check id="location">
      <requirement>City and state/country present</requirement>
      <pass_criteria>At least city and state/country detected</pass_criteria>
      <status_pass>✓ Found</status_pass>
      <status_fail>❌ Missing or incomplete</status_fail>
    </check>

    <check id="linkedin">
      <requirement>LinkedIn profile URL</requirement>
      <pass_criteria>Valid linkedin.com URL format</pass_criteria>
      <status_pass>✓ Valid URL</status_pass>
      <status_fail>⚠️ Missing (recommended)</status_fail>
      <severity_if_missing>TWEAK</severity_if_missing>
    </check>

    <check id="github">
      <requirement>GitHub profile URL (optional for technical roles)</requirement>
      <pass_criteria>Valid github.com URL format</pass_criteria>
      <status_pass>✓ Found</status_pass>
      <status_fail>⚠️ Not present (optional)</status_fail>
      <severity_if_missing>TWEAK</severity_if_missing>
      <recommendation>Add GitHub profile if applying for technical roles</recommendation>
    </check>

    <check id="portfolio">
      <requirement>Portfolio/personal website URL (optional)</requirement>
      <pass_criteria>Valid URL format distinct from LinkedIn/GitHub</pass_criteria>
      <status_pass>✓ Found</status_pass>
      <status_fail>⚠️ Not present (optional)</status_fail>
      <severity_if_missing>TWEAK</severity_if_missing>
      <recommendation>Add distinct portfolio URL if applicable</recommendation>
    </check>
  </validation_checks>

  <markdown_output_format>
    <header_display>
      Display actual header information as formatted text (name in bold, contact info on separate lines)
    </header_display>

    <validation_table>
      Three-column table: Element | Status | Details
      - Element: Name of contact field
      - Status: ✓ (pass) or ⚠️ (warning) or ❌ (fail)
      - Details: Validation result message
    </validation_table>

    <recommendations_section>
      Only display if there are recommendations
      Format: **[SEVERITY]** [Recommendation text]
      Severity levels: [⛔ BLOCKER] [⚠️ RISK] [🔧 TWEAK]
    </recommendations_section>
  </markdown_output_format>

  <severity_assignment>
    <rule priority="critical">
      Missing name, email, phone, or location → ⛔ BLOCKER
      These are required for ATS systems
    </rule>

    <rule priority="high">
      Invalid format for email or phone → ⚠️ RISK
      May cause ATS parsing failures
    </rule>

    <rule priority="moderate">
      Missing LinkedIn, GitHub, or Portfolio → 🔧 TWEAK
      Recommended but not required
    </rule>
  </severity_assignment>

  <integration_with_executive_summary>
    Header validation issues should be counted in the Executive Summary repair totals:
    - Add BLOCKER count if name/email/phone/location missing
    - Add RISK count if email/phone format invalid
    - Add TWEAK count for missing optional fields (LinkedIn, GitHub, Portfolio)
  </integration_with_executive_summary>
</header_contact_validation_rules>
```

---

## Files Impacted

### Primary Files
1. **PROJECT-INSTRUCTIONS.md** - All 8 issues require updates to this file
2. **quick-start-phase.md** - May need corresponding updates (TBD after reviewing PROJECT-INSTRUCTIONS.md changes)

### Supporting Files (Potential)
- `phases/phase-1/job-history-creation.md` - May need alignment with Issue #10 synthesis logic
- Any other phase files that reference the updated sections

---

## Implementation Order

1. **Issue #8** (includes #5) - Per-bullet audit rules with Markdown tables and width control
2. **Issue #9** - Bullet display and critical formatting rules (remove brackets/colors)
3. **Issue #6** - Output flow enforcement guardrail
4. **Issue #7** - Executive Summary header display with Markdown tables
5. **Issue #10** - Responsibilities vs Achievements synthesis logic
6. **Issue #11** - Display layer rendering (verify if additional changes needed beyond #10)
7. **Issue #12** - Header/Contact validation section

---

## Verification Steps

After implementing all changes:

1. [ ] Verify all XML blocks are properly closed
2. [ ] Check for duplicate section names or IDs
3. [ ] Ensure no conflicts between updated sections
4. [ ] Validate that `quick-start-phase.md` references are still accurate
5. [ ] Test with sample resume to verify all display changes render correctly
6. [ ] Confirm Executive Summary displays with new Markdown table format
7. [ ] Verify per-bullet audit tables use Markdown and include width control
8. [ ] Check that action verbs display without brackets or color text
9. [ ] Validate that Job History Summaries appear immediately after each position
10. [ ] Confirm Header/Contact validation section appears after Executive Summary
11. [ ] Verify responsibilities are synthesized, not extracted verbatim
12. [ ] Check that display layer applies metric indicators and verb categories

---

## Notes

- All code blocks are taken directly from GitHub issues without modification
- Issue #8 supersedes Issue #5 (both modify same section, #8 is more complete)
- Issues #9 and #11 are complementary (work together)
- Issue #10 includes the display layer updates from Issue #11
- All changes maintain backward compatibility where possible
- Deprecated formats are marked but not deleted for reference

---

## Success Criteria

- [ ] All 8 issues (#5-12) implemented exactly as specified
- [ ] No code conflicts or duplicate implementations
- [ ] All XML blocks properly formatted and closed
- [ ] `PROJECT-INSTRUCTIONS.md` updated with all changes
- [ ] `quick-start-phase.md` updated if needed
- [ ] Plan reviewed and approved by user
- [ ] Ready for implementation phase
